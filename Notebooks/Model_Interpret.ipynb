{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Resale Value of Knives from a Texas Government Surplus Store\n",
    "\n",
    "## Using Machine Learning to Support an Ebay Store's Financial Success\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Model and Intepret Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Author:** Dylan Dey\n",
    "***\n",
    "\n",
    "# Overview\n",
    "[Texas State Surplus Store](https://www.tfc.texas.gov/divisions/supportserv/prog/statesurplus/)\n",
    "\n",
    "[What happens to all those items that get confiscated by the TSA? Some end up in a Texas store.](https://www.wfaa.com/article/news/local/what-happens-to-all-those-items-that-get-confiscated-by-the-tsa-some-end-up-in-a-texas-store/287-ba80dac3-d91a-4b28-952a-0aaf4f69ff95)\n",
    "\n",
    "[Texas Surplus Store PDF](https://www.tfc.texas.gov/divisions/supportserv/prog/statesurplus/State%20Surplus%20Brochure-one%20bar_rev%201-10-2022.pdf)\n",
    "\n",
    "![Texas State Surplus Store](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRYkwyu20VBuQ52PrXdVRaGRIIg9OPXJg86lA&usqp=CAU)\n",
    "\n",
    "\n",
    "\n",
    "Thousands of people make a living selling pre-owned items on sites like EBay. A good place to locate items for sale is the Texas Facilities Commission collects left behind possessions, salvage, and surplus from Texas state agencies such as DPS, TXDOT, TCEQ, and Texas Parks & Wildlife. Examples of commonly available items include vehicles, furniture, office equipment and supplies, small electronics, and heavy equipment. The goal of this project is to create a predictive model in order to determine the resale value of knives from the Texas State Surplus Store on eBay. Descriptive analysis of over 70K sold knives on eBay in the last 2 years will also be used to examine the profitability of investing in knives from the surplus store. \n",
    "\n",
    "\n",
    "# BUSINESS PROBLEM\n",
    "[Texas Dave's Knives](https://www.ebay.com/str/texasdave3/Knives/_i.html?store_cat=3393246519)\n",
    "\n",
    " My family has been running a resale shop and selling on Ebay and other sites for years and lately the business has picked up. We are interested in exploring if the most common item sold at the Texas Surplus Store, pocket knives, would be a safe investment. On the surface they seem great for reselling, as they are oftentimes collectible and small enough to be easily shipped. \n",
    "\n",
    "I have been experimenting with low cost used knives for resale but have not risked a large capital investment in the higher end items. Analyzing past listings on eBay for the top brands available at the Surplus Store could prove useful for gaining insight on whether a larger investment would pay off. Understanding the risks involved in investing capital into different brands of knives and their potential returns will help narrow down what brands to invest in and help reduce excess inventory.\n",
    "\n",
    "It has been very time consuming and inaccurate trying to find the correct value to list an item for on eBay. Currently when listing we try to identify the specific knife by Google search, and then try to find the same or similar items sold on Ebay or other sites. This “guess and check” method often results in inventory not moving due to overpricing or being sold at a price lower than its true potential profit. Building a model that predicts the value of a pocket knife on eBay could help to easily determine the correct value of the item before a listing is live on the website.\n",
    "\n",
    "\n",
    "\n",
    "# Data Understanding\n",
    "\n",
    "> There are <mark>eight buckets of presorted brand knives</mark> that I was interested in exploring from the Texas Surplus Store. The Eight Pocketknife brands and their associated cost at the Texas Surplus Store:\n",
    "\n",
    "<ul>\n",
    "  <li>Benchmade: \\$45.00</li>\n",
    "  <li>Buck: \\$20.00</li>\n",
    "  <li>Case/Casexx: \\$20.00</li>\n",
    "  <li>CRKT: \\$15.00</li>\n",
    "  <li>Kershaw: \\$15.00</li>\n",
    "  <li>SOG: \\$15.00</li>\n",
    "  <li>Spyderco: \\$30.00</li>\n",
    "  <li>Victorinox: \\$20.00</li>\n",
    "</ul>\n",
    "\n",
    "### Domain Understading: Cost Breakdown\n",
    "- padded envelopes: \\$0.50 per knife\n",
    "- flatrate shipping: \\$4.45 per knife\n",
    "- brand knife at surplus store: 15, 20, 30, or 45 dollars per knife\n",
    "- overhead expenses (gas, cleaning suplies, sharpening supplies, etc): \\$3.00\n",
    "- Ebay's comission, with 13\\% being a reasonable approximation\n",
    "\n",
    ">A majority of the data was scraped from eBays proprietary Terapeak webapp, as this data goes back 2 years as compared to the API listed data that only goes back 90 days. It is assumed a large enough amount of listed data should approximate sold data well enough to prove useful for this project. \n",
    "\n",
    "> The target feature for the model to predict is the total price (shipping included) that a knife should be listed on eBay. One model will be using titles and images in order to find potential listings that are undervalued and could be worth investing in. Another model will accept only images as input, as this is an input that can easily be obtained in person at the store. This model will use past sold data of knives on eBay in order to determine within an acceptable amount of error the price it will resale for on eBay (shipping included) using only an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd \n",
    "import  json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten, GRU\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helps see plots in readme\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definition\n",
    "\n",
    "Define functions to import and clean data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_iqr_filter(df):\n",
    "    \n",
    "    price_Q1 = df['converted_price'].quantile(0.25)\n",
    "    price_Q3 = df['converted_price'].quantile(0.75)\n",
    "    price_iqr = price_Q3 - price_Q1\n",
    "\n",
    "    profit_Q1 = df['profit'].quantile(0.25)\n",
    "    profit_Q3 = df['profit'].quantile(0.75)\n",
    "    profit_iqr = profit_Q3 - profit_Q1\n",
    "\n",
    "    ROI_Q1 = df['ROI'].quantile(0.25)\n",
    "    ROI_Q3 = df['ROI'].quantile(0.75)\n",
    "    ROI_iqr = ROI_Q3 - ROI_Q1\n",
    "\n",
    "    price_upper_limit = price_Q3 + (1.5 * price_iqr)\n",
    "    price_lower_limit = price_Q1 - (1.5 * price_iqr)\n",
    "\n",
    "    profit_upper_limit = profit_Q3 + (1.5 * profit_iqr)\n",
    "    profit_lower_limit = profit_Q1 - (1.5 * profit_iqr)\n",
    "\n",
    "    ROI_upper_limit = ROI_Q3 + (1.5 * ROI_iqr)\n",
    "    ROI_lower_limit = ROI_Q1 - (1.5 * ROI_iqr)\n",
    "    \n",
    "#     print(f'Brand: {df.brand[0]}')\n",
    "#     print(f'price upper limit: ${np.round(price_upper_limit,2)}')\n",
    "#     print(f'price lower limit: ${np.round(price_lower_limit,2)}')\n",
    "#     print('-----------------------------------')\n",
    "#     print(f'profit upper limit: ${np.round(profit_upper_limit,2)}')\n",
    "#     print(f'profit lower limit: ${np.round(profit_lower_limit,2)}')\n",
    "#     print('-----------------------------------')\n",
    "#     print(f'ROI upper limit: {np.round(ROI_upper_limit,2)}%')\n",
    "#     print(f'ROI lower limit: {np.round(ROI_lower_limit,2)}%')\n",
    "#     print('-----------------------------------')\n",
    "\n",
    "    \n",
    "    new_df = df[(df['converted_price'] < price_upper_limit) &\n",
    "                (df['converted_price'] > price_lower_limit) &\n",
    "                (df['profit'] < profit_upper_limit) &\n",
    "                (df['ROI'] > profit_lower_limit) &\n",
    "                (df['profit'] < ROI_upper_limit) &\n",
    "                (df['ROI'] > ROI_lower_limit)]\n",
    "    \n",
    "    return new_df\n",
    "#download jpg urls from dataFrame\n",
    "def download(row):\n",
    "    filename = os.path.join(root_folder, str(row.name) + im_extension)\n",
    "\n",
    "# create folder if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    url = row.Image\n",
    "#     print(f\"Downloading {url} to {filename}\")\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    except:\n",
    "        print(f'{filename} error')\n",
    "\n",
    "\n",
    "\n",
    "# This function removes noisy data\n",
    "#lots/sets/groups of knives can\n",
    "#confuse the model from predicting\n",
    "#the appropriate value of individual knives\n",
    "def data_cleaner(df):\n",
    "    lot = re.compile('(?<!-\\S)lot(?![^\\s.,:?!])')\n",
    "    group = re.compile('(group)')\n",
    "    is_set = re.compile('(?<!-\\S)set(?![^\\s.,?!])')\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    trim_list = [lot,group,is_set]\n",
    "    for item in trim_list:\n",
    "        df.loc[df['title'].apply(lambda x: re.search(item, x)).notnull(), 'trim'] = 1 \n",
    "    to_drop = df.loc[df['trim'] == 1].index\n",
    "    df.drop(to_drop, inplace=True)\n",
    "    df.drop('trim', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#take raw data and prepare it for modeling\n",
    "def prepare_listed(listed_data_df):\n",
    "    listed_used_knives = listed_data_df.loc[listed_data_df['condition'] != 1000.0]\n",
    "    listed_used_knives = data_cleaner(listed_used_knives.copy())\n",
    "    listed_used_knives.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return listed_used_knives\n",
    "\n",
    "#take raw data and prepare it for modeling\n",
    "def prepare_tera_df(df, x, overhead_cost=3):\n",
    "    df['price_in_US'] = df['price_in_US'].str.replace(\"$\", \"\")\n",
    "    df['price_in_US'] = df['price_in_US'].str.replace(\",\", \"\")\n",
    "    df['price_in_US'] = df['price_in_US'].apply(float)\n",
    "    \n",
    "    df['shipping_cost'] = df['shipping_cost'].str.replace(\"$\", \"\")\n",
    "    df['shipping_cost'] = df['shipping_cost'].str.replace(\",\", \"\")\n",
    "    df['shipping_cost'] = df['shipping_cost'].apply(float)\n",
    "    \n",
    "    df['brand'] = list(bucket_dict.keys())[x]\n",
    "    df['converted_price'] = (df['price_in_US'] + df['shipping_cost'])\n",
    "    df['cost'] = list(bucket_dict.values())[x] + overhead_cost + 4.95\n",
    "    df['profit'] = ((df['converted_price']*.87) -  df['cost'])\n",
    "    df['ROI'] = (df['profit']/ df['cost'])*100.0\n",
    "    \n",
    "    return df   \n",
    "\n",
    "\n",
    "def avg_word_len(x):\n",
    "    words = x.split()\n",
    "    word_len = 0\n",
    "    for word in words:\n",
    "        word_len += len(word)\n",
    "        \n",
    "    return word_len / len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code imports a variety of libraries and packages to help with data manipulation and analysis. It also defines a few functions to help with pagination, data preparation, and image download. The main logic of the code is in the knife_request() function which makes API calls to eBay using the ebaysdk.finding Connection function. The function prepares data, creates a new feature, and prepares the brands. The download() function downloads images from URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dylandey/Documents/GitHub/Neural_Network_Predicting_Reseller_Success_Ebay\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Finding API data\n",
    "df_bench = pd.read_csv(\"listed_data/df_bench.csv\")\n",
    "df_buck = pd.read_csv(\"listed_data/df_buck.csv\")\n",
    "df_case = pd.read_csv(\"listed_data/df_case.csv\")\n",
    "df_caseXX = pd.read_csv(\"listed_data/df_CaseXX.csv\")\n",
    "df_crkt = pd.read_csv(\"listed_data/df_crkt.csv\")\n",
    "df_kersh = pd.read_csv(\"listed_data/df_kershaw.csv\")\n",
    "df_sog = pd.read_csv(\"listed_data/df_sog.csv\")\n",
    "df_spyd = pd.read_csv(\"listed_data/df_spyderco.csv\")\n",
    "df_vict = pd.read_csv(\"listed_data/df_victorinox.csv\")\n",
    "\n",
    "\n",
    "#Load scraped terapeak sold data\n",
    "sold_bench = pd.read_csv(\"terapeak_data/bench_scraped2.csv\")\n",
    "sold_buck1 = pd.read_csv(\"terapeak_data/buck_scraped2.csv\")\n",
    "sold_buck2 = pd.read_csv(\"terapeak_data/buck_scraped2_reversed.csv\")\n",
    "sold_case = pd.read_csv(\"terapeak_data/case_scraped2.csv\")\n",
    "sold_caseXX1 = pd.read_csv(\"terapeak_data/caseXX_scraped2.csv\")\n",
    "sold_caseXX2 = pd.read_csv(\"terapeak_data/caseXX2_reversed.csv\")\n",
    "sold_crkt = pd.read_csv(\"terapeak_data/crkt_scraped.csv\")\n",
    "sold_kershaw1 = pd.read_csv(\"terapeak_data/kershaw_scraped2.csv\")\n",
    "sold_kershaw2 = pd.read_csv(\"terapeak_data/kershaw_scraped2_reversed.csv\")\n",
    "sold_sog = pd.read_csv(\"terapeak_data/SOG_scraped2.csv\")\n",
    "sold_spyd = pd.read_csv(\"terapeak_data/spyd_scraped2.csv\")\n",
    "sold_vict1 = pd.read_csv(\"terapeak_data/vict_scraped.csv\")\n",
    "sold_vict2 = pd.read_csv(\"terapeak_data/vict_reversed.csv\")\n",
    "\n",
    "sold_list = [sold_bench,sold_buck1,\n",
    "             sold_buck2,sold_case,\n",
    "             sold_caseXX1,sold_caseXX2,\n",
    "             sold_crkt,sold_kershaw1,\n",
    "             sold_kershaw2,sold_sog, \n",
    "             sold_spyd, sold_vict1,\n",
    "             sold_vict2]\n",
    "\n",
    "\n",
    "listed_df = pd.concat([df_bench,df_buck,\n",
    "                       df_case,df_caseXX,\n",
    "                       df_crkt,df_kersh,\n",
    "                       df_sog,df_spyd,\n",
    "                       df_vict])\n",
    "\n",
    "used_listed = prepare_listed(listed_df)\n",
    "\n",
    "bucket_dict = {'benchmade': 45.0,\n",
    "               'buck': 20.0,\n",
    "               'case': 20.0,\n",
    "               'crkt': 15.0,\n",
    "               'kershaw': 15.0,\n",
    "               'sog': 15.0,\n",
    "               'spyderco': 30.0,\n",
    "               'victorinox': 20.0\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "\n",
    "This code loads data from several CSV files into Pandas dataframes and prepares the data for analysis.\n",
    "\n",
    "1) The first block of code loads 9 dataframes of listed knife data (df_bench, df_buck, df_case, df_caseXX, df_crkt, df_kersh, df_sog, df_spyd, df_vict) from 9 corresponding CSV files.\n",
    "\n",
    "\n",
    "2) The second block of code loads 12 dataframes of sold knife data (sold_bench, sold_buck1, sold_buck2, sold_case, sold_caseXX1, sold_caseXX2, sold_crkt, sold_kershaw1, sold_kershaw2, sold_sog, sold_spyd, sold_vict1, sold_vict2) from 12 corresponding CSV files. All 12 dataframes are then combined into a list called sold_list.\n",
    "\n",
    "3) The code then concatenates the 9 listed knife dataframes into one dataframe called listed_df.\n",
    "\n",
    "4) The function prepare_listed is applied to the listed_df dataframe.\n",
    "\n",
    "5) The code then creates a dictionary called bucket_dict which maps knife brands to a price bucket.\n",
    "\n",
    "6) The next block of code renames the 'Text' and 'shipping_' columns in each of the 12 sold dataframes to 'title' and 'shipping_cost', respectively.\n",
    "\n",
    "7) The code then converts the 'date_sold' column in each of the 12 sold dataframes to a datetime type.\n",
    "\n",
    "8) The code then concatenates the two dataframes sold_buck1 and sold_buck2 into one dataframe called sold_buck. The same is done for sold_caseXX, sold_kershaw, and sold_vict.\n",
    "\n",
    "9) The prepare_tera_df function is applied to each of the 6 updated sold dataframes (sold_bench, sold_buck, sold_case, sold_caseXX, sold_crkt, sold_kershaw, sold_sog, sold_spyd, sold_vict) to remove characters from the price column and create new profit/ROI features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in sold_list:\n",
    "    dataframe.rename({'Text': 'title',\n",
    "                      'shipping_': 'shipping_cost'},\n",
    "                     axis=1, inplace=True)\n",
    "\n",
    "    dataframe['date_sold'] = pd.to_datetime(dataframe['date_sold'])\n",
    "\n",
    "#limited out at 10K columns while scraping. Combine dataframes that went over 10K.\n",
    "sold_buck = pd.concat([sold_buck1,sold_buck2])\n",
    "sold_caseXX = pd.concat([sold_caseXX1,sold_caseXX2])\n",
    "sold_kershaw = pd.concat([sold_kershaw1,sold_kershaw2])\n",
    "sold_vict = pd.concat([sold_vict1,sold_vict2])\n",
    "\n",
    "#apply function to remove characters from price\n",
    "#and create profit/ROI features\n",
    "sold_bench = prepare_tera_df(sold_bench, 0)\n",
    "sold_buck = prepare_tera_df(sold_buck, 1)\n",
    "sold_case = prepare_tera_df(sold_case, 2)\n",
    "sold_caseXX = prepare_tera_df(sold_caseXX, 2)\n",
    "sold_crkt = prepare_tera_df(sold_crkt, 3)\n",
    "sold_kershaw = prepare_tera_df(sold_kershaw, 4)\n",
    "sold_sog = prepare_tera_df(sold_sog, 5)\n",
    "sold_spyd = prepare_tera_df(sold_spyd, 6)\n",
    "sold_vict = prepare_tera_df(sold_vict, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase and strip titles and remove duplicates\n",
    "for dataframe in sold_list:\n",
    "    dataframe['title'] = dataframe['title'].str.lower()\n",
    "    dataframe['title'] = dataframe['title'].str.strip()\n",
    "    dataframe.drop_duplicates(\n",
    "        subset = ['date_sold','price_in_US', \n",
    "                  'shipping_cost'],\n",
    "        keep = 'last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_df = pd.concat([sold_bench, sold_buck,\n",
    "                     sold_case, sold_caseXX, \n",
    "                     sold_crkt, sold_kershaw,\n",
    "                     sold_sog, sold_spyd,\n",
    "                     sold_vict]) \n",
    "#remove lots\n",
    "sold_knives = data_cleaner(sold_df).copy()\n",
    "\n",
    "#combine data\n",
    "df = pd.concat([sold_knives,used_listed]).copy()\n",
    "df['Image'].fillna(df['pictureURLLarge'], inplace=True)\n",
    "\n",
    "#apply IQR filtering\n",
    "df = apply_iqr_filter(df).copy()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stopwords \n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#remove any special characters\n",
    "def remove_special_char(x):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', x)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(x):\n",
    "    x.translate(str.maketrans('', '', string.punctuation))\n",
    "    return x\n",
    "#apply above functions to dataframe\n",
    "def apply_text_prep(df):\n",
    "\n",
    "    df['title'] = df['title'].apply(remove_punctuations)\n",
    "    df['title'] = df['title'].apply(remove_special_char)\n",
    "    #A lot of the strings had duplicate phrases\n",
    "    #create a set on split strings in order to\n",
    "    #only get unique words in each title\n",
    "    df['title'] = df['title'].apply(lambda s: ' '.join(list(set(s.split()))))\n",
    "\n",
    "\n",
    "    df['title_len'] = df['title'].apply(lambda x: len(x))\n",
    "    df['word_count'] = df['title'].apply(lambda x: len(x.split()))\n",
    "    df['avg_word_len'] = df['title'].apply(lambda x: avg_word_len(x))\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    df['title_nostop'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
    "    \n",
    "    return df\n",
    "df = apply_text_prep(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Neural network with \"title\" column as input\n",
    "\n",
    ">A title is something that is essential when posting an item for sale on eBay. A lot of sellers use the same format for titles depending on the product. Titles on eBay are essentially a list of keywords in order to promote it higher in the algorathim. Each knife brand and model combination have features that are desirable to collectors that sellers want to put right up at the top of their listing. \n",
    "\n",
    ">Pricing a certain pocketknife correctly when listing it, however, is time consuming and requires scrolling through webpages trying to find the most similar knives and guessing what would be competitive while hoping that none of your filters reset or you didnt miss a cruicial one. Pricing the item correctly is very important. If you post the item for sale too low, it might sell quickly and avoid excess inventory piling up, but it is also leaving revenue on the table. Listing the knife too high would mean it may not move off the shelf at all. \n",
    "\n",
    ">Creating a model to predict the price to list a knife for sale and accurately determing it's true resale value can not only save time and make listing items more efficient, it can also optimize for an equilibrium between excess inventory and lost revenue. \n",
    "\n",
    ">A number of different vectorization methods and modeling was tested for this project. The appendix has some brief examples of training a Random Forest model with feature importances and TfIDF vectorization. This type of vectorization, like one-hot tend to be very sparse for NLP. An advantage over this type of reperesentation is Word-embeddings: a learned represntation for text where words that have similar meaning have similar representation. Word embeddings are dense, lower-dimensional and learned from the data.\n",
    "\n",
    ">Recurrent Neural Networks are a type of Neural Network in which the output from the previous step is fed as input to the current step, making it well suited for handling sequence data. \n",
    "\n",
    ">RNNs are particularly useful if the prediction has to be at word-level, as it stores the information for current feature as well neighboring features for prediction. A RNN maintains a memory based on history information. A simple RNN, however, has a \"short\" memory and can often lead into problems with vanishing gradients. LSTM were created to use gates in order to filter for feature importance in order to combat this problem. This makes them better at finding and exposing long range dependencies in data which is imperative for sentence structures.\n",
    "\n",
    ">LSTMs are a bit more complex than GRU, with 3 gates compared to 2 for the GRU. GRUs are relatively new compared to LSTMs and their performance is on par with them, but computationally more efficient (as pointed out, they have a less complex structure).\n",
    "\n",
    ">See below for model creation and hyperparameter tuning for different RNN architectures, inluding LSTMs and GRUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Word Count Distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEICAYAAAB1f3LfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAArSElEQVR4nO3de1SV9Z7H8TcidFBTDNKteyOaZ1tmLQUDMrObHoMz5aWxwukMrCIwRk+nqTUjOhUzx7NKW+NhrCaaIcrL0cg0hSYpvJU0iW6PKDJIbkyTLRdTHCTyhMgzfzA9S+Litu1mS35eaz1r7f17bt/f43Z/eC77efwAAxERkZ+ol68LEBGRnk1BIiIiHlGQiIiIRxQkIiLiEQWJiIh4REEiIiIeUZDIz1Z6ejqrVq3ydRles2DBArKysi7b8hoaGhgxYgQA77zzDosWLbpsy87MzOT555+/bMuTK4uCRLpNWloaH330UZu2Q4cOddj26KOPer2ea6+9loyMDL7++msaGhpwOp1kZGQQEhLi1fUmJiZSWFjY5TTbt2/n7NmznDlzhvr6evbs2cP8+fMJDAw0p3n55ZdJTk6+6Pq2b99OUlLSRae79tprOXLkyMU7cBEd9S81NZU//OEPHi9brkwKEuk2O3bsYOLEifTq1fqxGzx4MAEBAURGRrZps9vt7Nix45KW7e/vf0nTBwQEsHXrVsaMGUNsbCz9+/fnjjvu4NSpU0RHR1/Ssrxl3rx59O/fnyFDhvDcc88RHx/Ppk2bLvt6LnXbiXTE0KChO4aAgACjsbHRiIyMNADj4YcfNt5++23j008/bdPmdDoNwBgyZIiRm5trnDp1ynA6ncaTTz5pLis9Pd14//33jVWrVhn19fVGUlKSMXz4cOPTTz81zpw5YxQUFBivvfaasWrVqg5rSUpKMmpqaoy+fft2Wu9NN91kbN++3Th9+rRRWlpqPPjgg+a47du3G0lJSeb7xMREo7Cw0HxvGIYxZ84c49ChQ0ZdXZ3x+uuvm8s8e/as0dzcbDQ0NBinT5/ucN0/Xj5ghIWFGY2NjcZf/dVfmdvgh/5dc801xqpVq4yTJ08ap0+fNnbv3m0MGjTI+MMf/mA0NzcbZ8+eNRoaGozXXnvNrO/v/u7vjEOHDhlfffWV2TZy5EgDMN555x0jMzPTKCgoMM6cOWN8+umnxrBhwwzACA8PNwzDMPz9/dvV21n/3nnnHWPRokXm9E8++aThdDqNU6dOGbm5ucaQIUMuuu00XLmD9kik25w7d45du3Zx1113AXDXXXdRWFjI559/3qbth72Rd999F5fLxdChQ5k1axYvvfQS9913n7m86dOns27dOoKDg1m9ejVr1qzhz3/+M6GhoSxatIjExMROa5kyZQoff/wxjY2NHY7v3bs3H374IQUFBQwaNIjf/va3rF69mlGjRrnd3wceeICoqCjGjh3LI488wv333095eTlPPfUUO3fu5Nprr2XgwIFuL6+yspI9e/YwadKkduMSExMZMGAAYWFhhISE8NRTT3H27Fmef/55CgsLmTdvHtdeey2//e1vzXlmzJhBTEwMN998c4fre+yxx1i0aBGhoaHs27eP1atXX7RGd/p377338vLLL/PII48wZMgQvv76a3JyctpM09G2kyuXgkS61WeffWaGxqRJkygsLKSwsLBN22effYbNZuPOO+9k/vz5fP/99+zfv5+33nqLv/3bvzWXtXPnTnJzczEMg+uvv56oqCheeOEFmpqaKCws5MMPP+y0jpCQEKqrqzsdf/vtt9OvXz8WL17MuXPn2L59O//1X//F7Nmz3e7r4sWLqa+vp7Kyku3btzNu3Di35+1MVVUV1113Xbv2c+fOERISwi9/+UtaWlrYu3cvDQ0NXS7r5Zdf5vTp0/zlL3/pcPxHH31EYWEhTU1N/NM//RMTJkzAZrN53IfHHnuMt99+m+LiYpqamliwYAETJkwgPDzcnMYb2068R0Ei3WrHjh3ceeedBAcHc/3111NRUcEXX3zBHXfcQXBwMLfccgs7duxg6NCh1NXV8e2335rzfv3111itVvN9ZWWl+Xro0KGcPn2a7777rs30nTl16hRDhgzpdPzQoUOprKzEMIxO138xNTU15uvvvvuOfv36uT1vZ6xWK3V1de3aV61axSeffEJOTg7Hjx9nyZIl9O7du8tlXbj9Lja+sbGRuro6hg4d+tMKv8DQoUPb/Ns0NjZy6tSpNtvWG9tOvEdBIt1q586dDBgwgJSUFP77v/8baL3stKqqipSUFKqqqjh69Kj5l/eFXyDDhg3j+PHj5vsLv+Srq6sZOHAgffr0aTN9Z7Zs2cL999/fZvoLVVVVERYWhp+fX4frb2xsbDOvxWJxdxO0qftS2Gw2xo8f3+EVX83Nzfz+979nzJgx3HHHHTzwwAMkJCR0ub6L1REWFma+7tu3L9dddx1VVVXm4cDO+n+x5VZVVbXZ++jTpw8hISFt/m2lZ1GQSLf6y1/+wp49e3j22WfbfCF+/vnnPPvss+b5EZfLxRdffMHLL7/MNddcw6233kpSUlKnx+mPHTvGnj17+Jd/+RcCAgKYOHEiDz74YKd1rFq1isrKStavX8+NN96In58f1113HQsWLCAuLo5du3bR2NjIP/7jP9K7d2/uvvtuHnzwQfNY/r59+3jooYcICgpi5MiRbl1e+4Pa2lpsNhsBAQFuTR8UFMRdd91Fbm4uu3fv7vDKrXvuuYdbbrmFXr16cebMGc6dO8f58+fN9d1www1u1/eDX//610ycOJGAgAAWLVrErl27cLlcnDx5EpfLxW9+8xt69erF448/zsiRI93u35o1a3j88ccZO3YsgYGBvPTSS+zatavLPUi5silIpNt99tlnDB48mM8//9xsKywsZPDgwW0u+509ezbDhw+nqqqKDRs2kJ6ezpYtWzpd7t/8zd8QExNDXV0d6enprFy5stNpm5qamDJlCuXl5WzevJkzZ86we/duQkND2bVrF+fOnWPatGnExcVx8uRJ3njjDRISEvjyyy8ByMjIoKmpidraWlasWOHWiegfbNu2jf/5n/+hpqaGb775ptPpXn/9dc6cOUNtbS3/9m//xvr164mNje3wL36LxcK6des4c+YMBw8e5LPPPuNPf/oTAMuWLWPWrFnU1dWxbNkyt+tcs2YN6enp1NXVMX78eB577DFzXHJyMv/wD//AqVOnGDNmDF988YXb/du2bRsvvPAC69evp7q6mpEjRxIfH+92XXLl8aP18i0REZGfRHskIiLiEQWJiIh4REEiIiIeUZCIiIhHuv7F0s/QiRMndJmhiMglCg8PZ9CgQR2Ou+qC5OuvvyYqKsrXZYiI9CgOh6PTcTq0JSIiHlGQiIiIRxQkIiLiEQWJiIh4REEiIiIe8VqQ2Gw2tm3bRllZGaWlpTz99NMADBw4kIKCAg4dOkRBQQHBwcHmPGlpaTidTsrLy5k6darZHhkZSUlJCU6ns81N5wIDA8nJycHpdFJUVNTm1tQiItJ9vPIMX4vFYkRERBiA0a9fP+PLL780Ro8ebSxZssSYP3++ARjz5883Fi9ebADG6NGjjX379hmBgYHG8OHDjYqKCqNXr14GYOzatcu4/fbbDcDYtGmTERsbawBGamqqkZmZaQDGo48+auTk5Fy0LofD4fPnG2vQoEFDTxsu8t3ZPUVs3LjRmDJlilFeXm5YLBYDWsOmvLzcAIy0tDQjLS3NnP7jjz82br/9dsNisRgHDx402+Pj440333yzzTSA4e/vb3zzzTeebgwNGjRo0NDB0NV3Z7ecIwkPDyciIoJdu3YxePBg8zGaNTU15i8lrVZrm0d7ulwurFYrVqsVl8vVrv3H85w/f576+npCQkLarT85ORmHw4HD4SA0NNRr/RQRuRp5/Zftffv2Zf369TzzzDM0NDR0Ot2FjzT9gWEYnbZ3Nc+PZWVlkZWVBXT960yRq9XSAzt9st7nbp3gk/XK5eXVPZLevXuzfv16Vq9ezYYNG4DWx3D+8Hxni8XCiRMngNY9jQufEW2z2aiqqsLlcmGz2dq1/3gef39/BgwYQF1dnTe7JCIiP+LVIMnOzubgwYNkZGSYbXl5eSQmJgKQmJhIbm6u2R4fH09gYCDDhw/Hbreze/duampqaGhoICYmBoCEhIQ28/ywrFmzZrFt2zZvdkdERDrgtUNbEydOJCEhgZKSEoqLiwFYuHAhixcvZu3atSQlJXHs2DEefvhhAMrKyli7di1lZWU0Nzczd+5cWlpaAEhNTWX58uUEBQWRn59Pfn4+0BpUq1atwul0UldXp+c+i4j4wFX3zHaHw6G7/4r8iM6RyMV09d2pX7aLiIhHFCQiIuKRq+7BViJXKl8dXhLxlPZIRETEIwoSERHxiIJEREQ8oiARERGPKEhERMQjChIREfGIgkRERDyiIBEREY8oSERExCMKEhER8YiCREREPKIgERERjyhIRETEIwoSERHxiNeCJDs7m9raWg4cOGC25eTkUFxcTHFxMUeOHDEfwRseHs53331njsvMzDTniYyMpKSkBKfTybJly8z2wMBAcnJycDqdFBUVER4e7q2uiIhIF7wWJMuXLyc2NrZNW3x8PBEREURERLB+/Xo++OADc9zhw4fNcampqWZ7ZmYmKSkp2O127Ha7ucykpCROnz6N3W4nIyODJUuWeKsrIiLSBa8FSWFhIXV1dZ2Of+SRR3j33Xe7XIbFYqF///4UFRUBsHLlSmbMmAHA9OnTWbFiBQDr1q1j8uTJl6dwERG5JD45RzJp0iRqa2upqKgw20aMGMHevXv59NNPufPOOwGwWq24XC5zGpfLhdVqNcdVVlYCcP78eerr6wkJCelwfcnJyTgcDhwOB6Ghod7qlojIVcknj9qdPXt2m72R6upqhg0bRl1dHZGRkWzcuJExY8bg5+fXbl7DMAC6HPdjWVlZZGVlAeBwOC5HF0RE5P91e5D4+/vz0EMPMX78eLOtqanJPAy2d+9eDh8+zKhRo3C5XNhsNnM6m81GVVUV0Lp3EhYWxvHjx/H392fAgAFdHkoTERHv6PZDW1OmTKG8vJzjx4+bbaGhofTq1VrKiBEjsNvtfPXVV9TU1NDQ0EBMTAwACQkJ5ObmApCXl0diYiIAs2bNYtu2bd3cExERAS8GyZo1a9i5cyc33ngjlZWVPPHEE0DrlVs/Psl+1113UVJSwr59+1i3bh1PPfUUp0+fBiA1NZW33nqLiooKDh8+TH5+PtB6eXFISAhOp5Nnn32WtLQ0b3VFRES64Ad0fGLhZ8rhcBAVFeXrMkTaWXpgp69L6HbP3TrB1yWIm7r67tQv20VExCMKEhER8YiCREREPKIgERERjyhIRETEIwoSERHxiIJEREQ8oiARERGPKEhERMQjChIREfGIgkRERDyiIBEREY8oSERExCMKEhER8YiCREREPKIgERERjyhIRETEI14LkuzsbGprazlw4IDZlp6ejsvlori4mOLiYuLi4sxxaWlpOJ1OysvLmTp1qtkeGRlJSUkJTqeTZcuWme2BgYHk5OTgdDopKioiPDzcW10REZEueC1Ili9fTmxsbLv2jIwMIiIiiIiIMJ+/Pnr0aOLj4xkzZgyxsbG88cYb9OrVWlpmZiYpKSnY7Xbsdru5zKSkJE6fPo3dbicjI4MlS5Z4qysiItIFrwVJYWEhdXV1bk07ffp0cnJyaGpq4ujRo1RUVBAdHY3FYqF///4UFRUBsHLlSmbMmGHOs2LFCgDWrVvH5MmTvdIPERHpWrefI5k3bx779+8nOzub4OBgAKxWK5WVleY0LpcLq9WK1WrF5XK1a//xPOfPn6e+vp6QkJAO15mcnIzD4cDhcBAaGuqlnomIXJ26NUgyMzMZOXIk48aNo7q6mqVLlwLg5+fXblrDMDpt72qejmRlZREVFUVUVBQnT570pAsiIvIj3RokJ06coKWlBcMwyMrKIjo6Gmjd0wgLCzOns9lsVFVV4XK5sNls7dp/PI+/vz8DBgxw+1CaiIhcPt0aJBaLxXw9c+ZMSktLAcjLyyM+Pp7AwECGDx+O3W5n9+7d1NTU0NDQQExMDAAJCQnk5uaa8yQmJgIwa9Ystm3b1p1dERGR/9fbWwtes2YN99xzD6GhoVRWVpKens4999zDuHHjMAyDo0ePMmfOHADKyspYu3YtZWVlNDc3M3fuXFpaWgBITU1l+fLlBAUFkZ+fb17plZ2dzapVq3A6ndTV1REfH++troiISBf8gI5PLPxMORwOoqKifF2GSDtLD+z0dQnd7rlbJ/i6BHFTV9+d+mW7iIh4REEiIiIeUZCIiIhHFCQiIuIRBYmIiHhEQSIiIh5RkIiIiEcUJCIi4hEFiYiIeERBIiIiHlGQiIiIRxQkIiLiEQWJiIh4REEiIiIeUZCIiIhHFCQiIuIRBYmIiHjEa0GSnZ1NbW0tBw4cMNteeeUVDh48yP79+/nggw8YMGAAAOHh4Xz33XcUFxdTXFxMZmamOU9kZCQlJSU4nU6WLVtmtgcGBpKTk4PT6aSoqIjw8HBvdUVERLrgVpCMGTPmkhe8fPlyYmNj27Rt3ryZW265hbFjx3Lo0CEWLFhgjjt8+DARERFERESQmppqtmdmZpKSkoLdbsdut5vLTEpK4vTp09jtdjIyMliyZMkl1ygiIp5zK0jefPNNdu3aRWpqqrkXcTGFhYXU1dW1adu8eTPnz58HoKioCJvN1uUyLBYL/fv3p6ioCICVK1cyY8YMAKZPn86KFSsAWLduHZMnT3arLhERubx6uzPRpEmT+OUvf8kTTzzBnj172L17N++88w5btmz5ySt+4okneO+998z3I0aMYO/evZw5c4bnn3+ezz//HKvVisvlMqdxuVxYrVYArFYrlZWVAJw/f576+npCQkI4depUu3UlJyeTkpICQGho6E+uWbrX0gM7fbLe526d4JP1ivRUbgUJQEVFBc8//zx79uzh1VdfJSIiAj8/PxYuXMiGDRsuaaULFy6kubmZ1atXA1BdXc2wYcOoq6sjMjKSjRs3MmbMGPz8/NrNaxgGQJfjfiwrK4usrCwAHA7HJdUqIiJdc+vQ1q233sof//hHDh48yH333ceDDz7IzTffzH333UdGRsYlrTAhIYEHHniAxx57zGxramoyD4Pt3buXw4cPM2rUKFwuV5vDXzabjaqqKqB17yQsLAwAf39/BgwY0O5QmoiIeJ9bQfL666+zd+9exo4dy7x58yguLgZa9ySef/55t1d2//33M3/+fKZNm8bZs2fN9tDQUHr1ai1lxIgR2O12vvrqK2pqamhoaCAmJgZoDaHc3FwA8vLySExMBGDWrFls27bN7TpEROTycevQ1q9//WvOnj1LS0sL0HpY6Re/+AVnz57lT3/6U4fzrFmzhnvuuYfQ0FAqKytJT09nwYIFXHPNNWzevBloPeGemprKXXfdxe9//3uam5s5f/48Tz31FKdPnwYgNTWV5cuXExQURH5+Pvn5+UDr5cWrVq3C6XRSV1dHfHy8xxtDREQunR/Q8YmFC+zcuZMpU6bQ2NgIQN++fSkoKGDixIneru+yczgcREVF+boMccPVdrLdV/31JV3Y0HN09d3p1qGtX/ziF2aIADQ2NtKnT5/LU52IiPRobgVJY2MjERER5vvIyMg25zhEROTq5dY5kmeeeYb333/fvGJqyJAhPProo14tTEREega3gmTPnj3cdNNN3Hjjjfj5+VFeXk5zc7O3axMRkR7A7R8kRkVFMXz4cHr37m0e5lq1apXXChMRkZ7BrSBZuXIlI0eOZN++fea9sgzDUJCIiIh7QXLbbbdx8803e7sWERHpgdy6aqu0tBSLxeLtWkREpAdya48kNDSUsrIydu/ezffff2+2T58+3WuFiYhIz+BWkPzzP/+zl8sQEZGeyq0g2bFjB8OGDcNut7N161aCgoLw9/f3dm0iItIDuHWO5Mknn2TdunX8x3/8B9D6UKmNGzd6sy4REekh3AqSuXPnMnHiRM6cOQO0PuRq0KBBXi1MRER6BreC5Pvvv+fcuXPme39//06fRigiIlcXt4Lks88+Y8GCBQQFBTFlyhTef/99PvzwQ2/XJiIiPYBbQZKWlsY333zDgQMHmDNnDps2bbqkJyOKiMjPl1tXbRmGwVtvvcVbb73l7XpERKSHcWuP5KuvvuLw4cPthq5kZ2dTW1vLgQMHzLaBAwdSUFDAoUOHKCgoIDg42ByXlpaG0+mkvLycqVOnmu2RkZGUlJTgdDpZtmyZ2R4YGEhOTg5Op5OioiLCw8Pd7bOIiFxGbgXJbbfdRlRUFFFRUUyaNIlXX32102e1/2D58uXExsa2aUtLS2Pr1q2MGjWKrVu3kpaWBsDo0aOJj49nzJgxxMbG8sYbb9CrV2tpmZmZpKSkYLfbsdvt5jKTkpI4ffo0drudjIwMlixZcsmdFxERz7kVJHV1deZQVVXFsmXLuO+++7qcp7CwkLq6ujZt06dPZ8WKFQCsWLGCGTNmmO05OTk0NTVx9OhRKioqiI6OxmKx0L9/f4qKioDWuxBfOM8Py1q3bh2TJ092u9MiInL5uHWO5MLH7Pbq1YvbbruNa6+99pJXNnjwYGpqagCoqakxf4titVrNsABwuVxYrVbOnTuHy+Vq1/7DPJWVlQCcP3+e+vp6QkJCOHXqVLv1Jicnk5KSArTeN0xERC4ft4Jk6dKl5uvm5maOHj3KI488ctmK8PPza9dmGEan7V3N05GsrCyysrIAcDgcnpQqIiI/4laQXOwwlrtqa2uxWCzU1NRgsVg4ceIE0LqnERYWZk5ns9moqqrC5XJhs9natV84z/Hjx/H392fAgAHtDqWJiIj3uRUkf//3f9/l+IyMDLdWlpeXR2JiIkuWLCExMZHc3Fyzfc2aNfzxj39k6NCh2O12du/eTUtLCw0NDcTExLBr1y4SEhJ47bXX2iyrqKiIWbNmsW3bNrdqEBGRy8vtJyRGRUWRl5cHwIMPPsiOHTvMcxQdWbNmDffccw+hoaFUVlaSnp7O4sWLWbt2LUlJSRw7doyHH34YgLKyMtauXUtZWRnNzc3MnTuXlpYWAFJTU1m+fDlBQUHk5+eTn58PtF5evGrVKpxOJ3V1dcTHx3u0IURE5KfxAy5606xPPvmEv/7rv+bbb78FoF+/frz//vvExcV5u77LzuFwEBUV5esyxA1LD+z0yXqfu3WCT9brq/76kq+2tVy6rr473br8d9iwYTQ1NZnvm5qaGD58+GUpTkREeja3Dm2tWrWK3bt3s2HDBgzDYObMmaxcudLbtYmISA/gVpC89NJL5OfnM2nSJAAef/xx9u3b5826RESkh3Dr0BZAnz59OHPmDK+++ioul0uHtkREBHAzSF588UXmz5/PggULAAgICLjovbZEROTq4FaQzJw5k2nTptHY2AhAdXX1T7pFioiI/Py4FSQ/XLH1wy1I+vTp472KRESkR3ErSNauXcubb75JcHAwTz75JFu2bDHvXSUiIlc3t67aeu+997jppps4c+YMN954Iy+++CJbtmzxdm0iItIDuBUkGzdu5LbbblN4iIhIO24d2ioqKuK2227zdi0iItIDubVHcu+99/LUU09x9OhRGhsb8fPzwzAMxo4d6+36RETkCtdlkISFhVFZWdkjb84oIiLdo8sg2bhxI+PHj+fYsWOsW7eOWbNmdVddIiLSQ3R5juTCx9necMMNXi9GRER6ni6D5MJnoHf2PHQREbm6dXloa+zYsdTX1+Pn50dQUBD19fUA5sn2AQMGdEuRIt3panzAlIgnugyS3r3duqjrkowaNYr33nvPfH/DDTfw4osvEhwcTHJyMt988w0ACxcuNB+rm5aWRlJSEufPn+fpp5+moKAAgMjISPMxvJs2beJ3v/vdZa9XRLzHl6GtpzNePm7fRv5yOXToEBEREURERDB+/Hi+++47NmzYAEBGRoY57ocQGT16NPHx8YwZM4bY2FjeeOMNevVqLTszM5OUlBTsdjt2u53Y2Nju7o6IyFWv24PkQpMnT+bw4cMcO3as02mmT59OTk4OTU1NHD16lIqKCqKjo7FYLPTv35+ioiIAVq5cyYwZM7qpchER+YFPgyQ+Pp53333XfD9v3jz2799PdnY2wcHBAFitViorK81pXC4XVqsVq9WKy+Vq196R5ORkHA4HDoeD0NBQ73RGROQq5bMgCQgIYNq0abz//vtA62GqkSNHMm7cOKqrq1m6dCnQ9hLkHxiG0Wl7R7KysoiKiiIqKoqTJ09exl6IiIjPgiQuLo69e/dy4sQJAE6cOEFLSwuGYZCVlUV0dDTQuqcRFhZmzmez2aiqqsLlcmGz2dq1i4hI9/JZkMyePbvNYS2LxWK+njlzJqWlpQDk5eURHx9PYGAgw4cPx263s3v3bmpqamhoaCAmJgaAhIQEcnNzu7cTIiLi3k0bL7egoCB+9atfMWfOHLPtlVdeYdy4cRiGwdGjR81xZWVlrF27lrKyMpqbm5k7dy4tLS0ApKammpf/5ufnm1d6yeWj31SIyMX4AVfVT9YdDgdRUVG+LqPHUJDIz5V+R3Jpuvru9OlVWyIi0vMpSERExCMKEhER8YiCREREPKIgERERjyhIRETEIwoSERHxiIJEREQ8oiARERGPKEhERMQjChIREfGIgkRERDyiIBEREY8oSERExCMKEhER8YiCREREPKIgERERj/gkSI4cOUJJSQnFxcU4HA4ABg4cSEFBAYcOHaKgoIDg4GBz+rS0NJxOJ+Xl5UydOtVsj4yMpKSkBKfTybJly7q7GyIigg/3SO69914iIiLMRzempaWxdetWRo0axdatW0lLSwNg9OjRxMfHM2bMGGJjY3njjTfo1au17MzMTFJSUrDb7djtdmJjY33VHRGRq9YVc2hr+vTprFixAoAVK1YwY8YMsz0nJ4empiaOHj1KRUUF0dHRWCwW+vfvT1FREQArV6405xERke7jkyAxDIOCggL27NlDcnIyAIMHD6ampgaAmpoaBg0aBIDVaqWystKc1+VyYbVasVqtuFyudu0dSU5OxuFw4HA4CA0N9Va3RESuSr19sdKJEydSXV3N9ddfz+bNmykvL+90Wj8/v3ZthmF02t6RrKwssrKyAMxzMiIicnn4ZI+kuroagG+++YYNGzYQHR1NbW0tFosFAIvFwokTJ4DWPY2wsDBzXpvNRlVVFS6XC5vN1q5dRES6V7cHSZ8+fejXr5/5eurUqZSWlpKXl0diYiIAiYmJ5ObmApCXl0d8fDyBgYEMHz4cu93O7t27qampoaGhgZiYGAASEhLMeUREpPt0+6GtwYMHs2HDhtaV9+7NmjVr+OSTT3A4HKxdu5akpCSOHTvGww8/DEBZWRlr166lrKyM5uZm5s6dS0tLCwCpqaksX76coKAg8vPzyc/P7+7uiIhc9fyAjk8s/Ew5HA7zkmO5uKUHdvq6BBGveO7WCb4uoUfp6rvzirn8V0REeiYFiYiIeERBIiIiHlGQiIiIRxQkIiLiEQWJiIh4REEiIiIeUZCIiIhHFCQiIuIRBYmIiHhEQSIiIh5RkIiIiEcUJCIi4hEFiYiIeERBIiIiHlGQiIiIRxQkIiLikW4PEpvNxrZt2ygrK6O0tJSnn34agPT0dFwuF8XFxRQXFxMXF2fOk5aWhtPppLy8nKlTp5rtkZGRlJSU4HQ6WbZsWXd3RURE8MEz25ubm3nuuecoLi6mX79+/PnPf2bz5s0AZGRksHTp0jbTjx49mvj4eMaMGcPQoUPZsmULo0aNoqWlhczMTFJSUigqKmLTpk3Exsby8ccfd3eXRESuat2+R1JTU0NxcTEA3377LQcPHsRqtXY6/fTp08nJyaGpqYmjR49SUVFBdHQ0FouF/v37U1RUBMDKlSuZMWNGd3RBREQu4NNzJOHh4URERLBr1y4A5s2bx/79+8nOziY4OBgAq9VKZWWlOY/L5cJqtWK1WnG5XO3aO5KcnIzD4cDhcBAaGuq9DomIXIV8FiR9+/Zl/fr1PPPMMzQ0NJCZmcnIkSMZN24c1dXV5iEuPz+/dvMahtFpe0eysrKIiooiKiqKkydPXt6OiIhc5XwSJL1792b9+vWsXr2aDRs2AHDixAlaWlowDIOsrCyio6OB1j2NsLAwc16bzUZVVRUulwubzdauXUREupdPgiQ7O5uDBw+SkZFhtlksFvP1zJkzKS0tBSAvL4/4+HgCAwMZPnw4drud3bt3U1NTQ0NDAzExMQAkJCSQm5vbvR0REZHuv2pr4sSJJCQkUFJSYp50X7hwIbNnz2bcuHEYhsHRo0eZM2cOAGVlZaxdu5aysjKam5uZO3cuLS0tAKSmprJ8+XKCgoLIz88nPz+/u7sjInLV8wM6PrHwM+VwOIiKivJ1GT3G0gM7fV2CiFc8d+sEX5fQo3T13alftouIiEcUJCIi4hEFiYiIeERBIiIiHlGQiIiIR7r98l/5aXT1lIhcqbRHIiIiHlGQiIiIR3RoS0SuSr46XPxz/CGk9khERMQjChIREfGIgkRERDyiIBEREY8oSERExCMKEhER8YiCREREPKIgERERj/T4ILn//vspLy/H6XQyf/58X5cjInLV6dFB0qtXL/793/+duLg4br75ZmbPns3o0aN9XZaIyFWlR98iJTo6moqKCo4cOQJATk4O06dP5+DBg15Zn+7AKyLSXo8OEqvVSmVlpfne5XIRExPTbrrk5GRSUlIAuPHGG3E4HD9thX/5abNdqtDQUE6ePNk9K/OA6ry8ekqd0HNqvRLr7Oj750qs88fCw8O7HG/01GHWrFlGVlaW+f43v/mN8eqrr/q8Lk8Hh8Ph8xpUp+r8OdSqOrtn6NHnSFwuF2FhYeZ7m81GVVWVDysSEbn69OggcTgc2O12hg8fTkBAAPHx8eTl5fm6LBGRq0qPPkdy/vx55s2bxyeffIK/vz9vv/02ZWVlvi7LY//5n//p6xLcojovr55SJ/ScWlVn9/Cj9RiXiIjIT9KjD22JiIjvKUhERMQjChIfsNlsbNu2jbKyMkpLS3n66afbTXP33Xfzv//7vxQXF1NcXMwLL7zgg0pbHTlyhJKSEoqLizv9Dc6yZctwOp3s37+fiIiIbq4QRo0aZW6r4uJi6uvr+d3vftdmGl9t0+zsbGprazlw4IDZNnDgQAoKCjh06BAFBQUEBwd3OG933wKoo1pfeeUVDh48yP79+/nggw8YMGBAh/O68znxZp3p6em4XC7z3zcuLq7Debtzm3ZUZ05OjlnjkSNHKC4u7nDe7tyel4PPr0G+2gaLxWJEREQYgNGvXz/jyy+/NEaPHt1mmrvvvtv48MMPfV4rYBw5csQICQnpdHxcXJyxadMmAzBiYmKMoqIin9bbq1cvo7q62hg2bNgVsU0nTZpkREREGAcOHDDblixZYsyfP98AjPnz5xuLFy/usB8VFRXGiBEjjICAAGPfvn3tPifdUeuvfvUrw9/f3wCMxYsXd1irO58Tb9eZnp5uPPfccxf9bHTnNu2ozguHf/3XfzVeeOEFn29PTwftkfhATU2N+VfIt99+y8GDB7FarT6u6qebPn06K1euBGDXrl0EBwdjsVh8Vs/kyZM5fPgwx44d81kNFyosLKSurq5N2/Tp01mxYgUAK1asYMaMGe3mu/AWQOfOnTNvAdTdtW7evJnz588DUFRUhM1m82oN7uioTnd09za9WJ2PPPII7777rtfW310UJD4WHh5OREQEu3btajduwoQJ7Nu3j02bNnHzzTf7oLpWhmFQUFDAnj17SE5Obje+o1vV+DIY4+PjO/3PeaVs08GDB1NTUwO0/mExaNCgdtNcadsV4IknniA/P7/DcRf7nHSHefPmsX//frKzszs8XHglbdNJkyZRW1tLRUVFh+OvhO3prh79O5Kerm/fvqxfv55nnnmGhoaGNuP27t1LeHg4jY2NxMXFsXHjRkaNGuWTOidOnEh1dTXXX389mzdvpry8nMLCQnO8n59fu3kMw+jOEk0BAQFMmzaNBQsWtBt3JW1Td1xJ2xVg4cKFNDc3s3r16g7HX+xz4m2ZmZksWrQIwzBYtGgRS5cuJSkpqc00V9I2nT17dpd7I77enpdCeyQ+0rt3b9avX8/q1avZsGFDu/ENDQ00NjYCkJ+fT0BAACEhId1dJgDV1dUAfPPNN2zYsIHo6Og246+kW9XExcWxd+9eTpw40W7clbRNa2trzcN/Foulw3qvpO2akJDAAw88wGOPPdbpNBf7nHjbiRMnaGlpwTAMsrKyOlz/lbJN/f39eeihh3jvvfc6ncbX2/NSKEh8JDs7m4MHD5KRkdHh+MGDB5uvo6Ki6NWrF6dOnequ8kx9+vShX79+5uupU6dSWlraZpq8vDwSEhIAiImJob6+3jxs0926+ivvStmm0LrNEhMTAUhMTCQ3N7fdNFfKLYDuv/9+5s+fz7Rp0zh79myH07jzOfG2C8/LzZw5s8P1XynbdMqUKZSXl3P8+PEOx18J2/NS+fyM/9U2TJw40TAMw9i/f79RXFxsFBcXG3FxccacOXOMOXPmGIAxd+5co7S01Ni3b5+xc+dOY8KECT6pdcSIEca+ffuMffv2GaWlpcbChQsNoE2tgPH6668bFRUVRklJiTF+/Hif1BoUFGScPHnS6N+/v9l2JWzTNWvWGFVVVUZTU5NRWVlpPPHEE8Z1111nbNmyxTh06JCxZcsWY+DAgQZgDBkyxPjoo4/MeePi4owvv/zSqKioMLd9d9fqdDqNY8eOmZ/VzMzMdrV29jnpzjpXrlxplJSUGPv37zdyc3MNi8Xi823aUZ2A8c4777T5/+Pr7enpoFukiIiIR3RoS0REPKIgERERjyhIRETEIwoSERHxiIJEREQ8oiARERGPKEhERMQj/wcgGjIeXeIoPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['word_count'].plot(kind = 'hist', title = 'Word Count Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Avg_Word_len Distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['avg_word_len'].plot(kind='hist', bins = 50, title = 'Avg_Word_len Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['title_len'].plot(kind='hist', bins= 100,title = 'Title Length Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simpleRNN\n",
    "\n",
    "The mean max sequence for is not that long for eBay titles, thus a simpleRNN was tested to see if architecture with gates could be avoided to increase efficiency. Hyperparameter tuning is shown below. The best performing model had 100.00 units and dropout=0.4 in the RNN layer with a test MAE of 14.869. Different variations of max sequence length, vocab size, and number of embedding features was tested as well. Performed well but not as well as GRU model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df.loc[:, ['title_nostop', 'converted_price']]\n",
    "\n",
    "\n",
    "df_title.rename({'title_nostop': 'data',\n",
    "                 'converted_price': 'labels'},\n",
    "                axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76914 entries, 0 to 76913\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   data    76914 non-null  object \n",
      " 1   labels  76914 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_title.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.993376628442164"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title['labels'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and testing sets and the split the testing set to create equal size val and train sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_title['labels'] = (df_title['labels']/mean_price)\n",
    "y = df_title['labels'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_title['data'],\n",
    "                                                    y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, \n",
    "                                                y_test, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize vocab \n",
    "voc_size = 10000\n",
    "max_len = 10\n",
    "embedding_features = 300\n",
    "tokenizer = Tokenizer(num_words=voc_size, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train) \n",
    "sequences_val = tokenizer.texts_to_sequences(X_val)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add padding to ensure all inputs are the same size\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_val = pad_sequences(sequences_val, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_test = pad_sequences(sequences_test, maxlen=max_len, padding= 'post', truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Embedding(voc_size, embedding_features, input_length = max_len)) \n",
    "model.add(GRU(100,dropout=0.3))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile and fit\n",
    "model.compile(\n",
    "  loss='MSE',\n",
    "  optimizer='adam',\n",
    "  metrics=['mae']\n",
    ")\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "r = model.fit(\n",
    "  data_train,\n",
    "  y_train,\n",
    "  epochs=5,\n",
    "  validation_data=(data_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set values for hyperparamter testing of simpleRNN model\n",
    "HP_NUM_UNITS = hp.HParam('units', hp.Discrete([64,100,300,600]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2,0.4))\n",
    "\n",
    "\n",
    "METRIC_MAE = 'MAE'\n",
    "#set metrics\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT],\n",
    "        metrics=[hp.Metric(METRIC_MAE, display_name='MAE')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model for hyperparameter testing\n",
    "def train_test_model(hparams):\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(voc_size, embedding_features, input_length = max_len)) \n",
    "    model.add(SimpleRNN(hparams[HP_NUM_UNITS],dropout=(hparams[HP_DROPOUT])))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(\n",
    "      optimizer='Adam',\n",
    "      loss='MSE',\n",
    "      metrics=['MAE'],\n",
    "    )\n",
    "    model.fit(data_train, \n",
    "              y_train, \n",
    "              epochs=5,\n",
    "              validation_data=(data_val, y_val)\n",
    "             )\n",
    "    _, MSE = model.evaluate(data_test, y_test)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write files\n",
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        MSE = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_MAE, MSE, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run hyperparamter testing for simpleRNN Model\n",
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[simpleRNN Hyperparamter Optimization](https://tensorboard.dev/experiment/sngivEMGR2KSgnBDe3ncLQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU\n",
    "An alternative to creating a simpleRNN layer after embedding is to use a GRU layer. The architecture of this layer is more efficient than an LSTM, but it is similar in its ability to filter features by importance before continuing in the network. This ability helps to fight short term memory and vanishing gradients. This usually works well with smaller sample size than more robust LSTM models. However, for this project the GRU model performed the best with a test MAE of 14.28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize vocab \n",
    "voc_size = 30000\n",
    "max_len = 11\n",
    "embedding_features = 100\n",
    "tokenizer = Tokenizer(num_words=voc_size, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train) \n",
    "sequences_val = tokenizer.texts_to_sequences(X_val)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add padding to ensure all inputs are the same size\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_val = pad_sequences(sequences_val, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_test = pad_sequences(sequences_test, maxlen=max_len, padding= 'post', truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup units for hyperparameter testing\n",
    "HP_NUM_UNITS = hp.HParam('units', hp.Discrete([64,100,300,600]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2,0.4))\n",
    "\n",
    "\n",
    "METRIC_MAE = 'MAE'\n",
    "#log performance\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT],\n",
    "        metrics=[hp.Metric(METRIC_MAE, display_name='MAE')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model for hyperparameter testing\n",
    "def train_test_model(hparams):\n",
    "    model = models.Sequential()\n",
    "    model.add(Embedding(voc_size, embedding_features, input_length = max_len)) \n",
    "    model.add(GRU(hparams[HP_NUM_UNITS],dropout=(hparams[HP_DROPOUT])))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(\n",
    "      optimizer='Adam',\n",
    "      loss='MSE',\n",
    "      metrics=['MAE'],\n",
    "    )\n",
    "    model.fit(data_train, \n",
    "              y_train, \n",
    "              epochs=5,\n",
    "              validation_data=(data_val, y_val)\n",
    "             )\n",
    "    _, MSE = model.evaluate(data_test, y_test)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write files\n",
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        MSE = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_MAE, MSE, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run hyperparamter testing for GRU Model\n",
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GRU Hyperparameter tuning](https://tensorboard.dev/experiment/k0ny5jh6Tvm8OALWMwBkWQ/#hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize vocab \n",
    "voc_size = 30000\n",
    "max_len = 11\n",
    "embedding_features = 100\n",
    "tokenizer = Tokenizer(num_words=voc_size, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train) \n",
    "sequences_val = tokenizer.texts_to_sequences(X_val)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#add padding to ensure all inputs are the same size\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_val = pad_sequences(sequences_val, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_test = pad_sequences(sequences_test, maxlen=max_len, padding= 'post', truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 11, 100)           3000000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,060,701\n",
      "Trainable params: 3,060,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Embedding(voc_size, embedding_features, input_length = max_len)) \n",
    "model.add(GRU(100,dropout=0.4))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/5\n",
      "1683/1683 [==============================] - 41s 24ms/step - loss: 1088.0472 - mae: 22.9519 - val_loss: 553.6788 - val_mae: 16.2353\n",
      "Epoch 2/5\n",
      "1683/1683 [==============================] - 41s 24ms/step - loss: 466.1590 - mae: 14.8689 - val_loss: 457.7079 - val_mae: 14.7498\n",
      "Epoch 3/5\n",
      "1683/1683 [==============================] - 41s 24ms/step - loss: 356.8253 - mae: 12.7989 - val_loss: 446.2110 - val_mae: 14.2553\n",
      "Epoch 4/5\n",
      "1683/1683 [==============================] - 39s 23ms/step - loss: 301.8997 - mae: 11.6065 - val_loss: 451.4138 - val_mae: 14.0694\n",
      "Epoch 5/5\n",
      "1661/1683 [============================>.] - ETA: 0s - loss: 266.8204 - mae: 10.7925"
     ]
    }
   ],
   "source": [
    "# Compile and fit\n",
    "model.compile(\n",
    "  loss='MSE',\n",
    "  optimizer='adam',\n",
    "  metrics=['mae']\n",
    ")\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "r = model.fit(\n",
    "  data_train,\n",
    "  y_train,\n",
    "  epochs=5,\n",
    "  validation_data=(data_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Spyderco Mantra 3 Liner Lock Knife Black Carbon Fiber & G-10 S30V Steel C233CFP\"\n",
    "s1_p = 136.1\n",
    "s2 = \"Benchmade 556 Green 154cm Combo Blade Pardue Design\"\n",
    "s2_p = 71.95\n",
    "s3 = \"Case XX 6207 SS Mini Trapper Brown Peachseed Bone Pocket Knife Made in Usa\"\n",
    "s3_p = 51.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_string(s):\n",
    "    s = remove_special_char(s.lower())\n",
    "    s = remove_punctuations(s)\n",
    "    s = ' '.join(list(set(s.split())))\n",
    "    test = tokenizer.texts_to_sequences([s])\n",
    "    test2 = pad_sequences(test, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "    pred=model.predict(test2)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = test_single_string(s1)[0][0]\n",
    "pred2 = test_single_string(s2)[0][0]\n",
    "pred3 = test_single_string(s3)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sample1](images/RNN/randomSpyd.jpeg)\n",
    "![sample2](images/RNN/randomBench.jpeg)\n",
    "![sample3](images/RNN/randomCase.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True value: ${s1_p}, Predicted Value: ${pred1:.2f}, difference: ${pred1 - s1_p:.2f}')\n",
    "print(f'True value: ${s2_p}, Predicted Value: ${pred2:.2f} difference: ${pred2 - s2_p:.2f}')\n",
    "print(f'True value: ${s3_p}, Predicted Value: ${pred3:.2f} difference: ${pred3 - s3_p:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds =model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.reshape(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(data_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(12,8))\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.title(\"Loss vs val Loss for RNN model on titles (MSE)\", fontsize=15)\n",
    "plt.xlabel(\"epochs\", fontsize=15)\n",
    "plt.ylabel(\"loss (mean squared error)\", fontsize=15)\n",
    "plt.legend();\n",
    "plt.savefig('images/RNN/RNN_GRU_MSE1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(12,8))\n",
    "plt.plot(r.history['mae'], label='mae')\n",
    "plt.plot(r.history['val_mae'], label='val_mae')\n",
    "plt.title(\"Loss vs val Loss for RNN model on titles (MAE)\", fontsize=15)\n",
    "plt.xlabel(\"epochs\", fontsize=15)\n",
    "plt.ylabel(\"loss (mean absolute error)\", fontsize=15)\n",
    "plt.legend();\n",
    "plt.savefig('images/RNN/RNN_GRU_MAE1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,show_shapes=True, to_file='images/RNN/RNN_GRU1_arc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(test_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "string_score = f'\\nMAE on training set: ${test_mae:.2f}'\n",
    "string_score += f'\\nRMSE on training set: ${RMSE:.2f}'\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plt.scatter(y_test, preds)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\"red\")\n",
    "plt.text(3, 150, string_score)\n",
    "plt.title('RNN Model for Predicting Resale Value')\n",
    "plt.ylabel('Model predictions for Resale Value($US)')\n",
    "plt.xlabel('True Values for Resale Value($US)')\n",
    "plt.show();\n",
    "# plt.savefig('images/regression_GRU_relu1.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "ax = sns.regplot(x=y_test,y=preds,marker='.')\n",
    "plt.title('Regression Plot for RNN Model Performance on Predicting Resale Value',\n",
    "         fontsize=20)\n",
    "plt.ylabel('Model predictions for Resale Value($US)',\n",
    "          fontsize=18)\n",
    "plt.xlabel('True Values for Resale Value($US)',\n",
    "          fontsize=18)\n",
    "plt.xticks([20,40,\n",
    "            60,80,\n",
    "            100,120,\n",
    "            140,160],\n",
    "           ['$20.00','$40.00',\n",
    "            '$60.00','$80.00',\n",
    "            '$100.00','$120.00',\n",
    "            '$140.00','$160.00'],\n",
    "          fontsize=15)\n",
    "plt.yticks([20,40,\n",
    "            60,80,\n",
    "            100,120,\n",
    "            140],\n",
    "           ['$20.00','$40.00',\n",
    "            '$60.00','$80.00',\n",
    "            '$100.00','$120.00',\n",
    "            '$140.00'],\n",
    "          fontsize=15)\n",
    "plt.savefig('images/RNN/regPlot_GRU_performance.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df.loc[:, ['title_nostop', 'converted_price']]\n",
    "\n",
    "\n",
    "df_title.rename({'title_nostop': 'data',\n",
    "                 'converted_price': 'labels'},\n",
    "                axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_title['labels'] = (df_title['labels']/mean_price)\n",
    "Y = df_title['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, Ytrain, Ytest = train_test_split(df_title['data'],\n",
    "                                                    Y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(df_test, \n",
    "                                                Ytest, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentences to sequences\n",
    "MAX_VOCAB_SIZE = 30000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE) \n",
    "tokenizer.fit_on_texts(df_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(df_train) \n",
    "sequences_val = tokenizer.texts_to_sequences(X_val) \n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx)\n",
    "print('Found %s unique tokens.' % V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "data_train = pad_sequences(sequences_train)\n",
    "print('Shape of data train tensor:', data_train.shape)\n",
    "\n",
    "# get sequence length\n",
    "T = data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pad_sequences(sequences_val, maxlen=T)\n",
    "print('Shape of data test tensor:', X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pad_sequences(sequences_test, maxlen=T)\n",
    "print('Shape of data test tensor:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('units', hp.Discrete([16,32,64,100,300]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2,0.4))\n",
    "\n",
    "\n",
    "METRIC_MAE = 'MAE'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning2').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT],\n",
    "        metrics=[hp.Metric(METRIC_MAE, display_name='MAE')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 11\n",
    "\n",
    "def train_test_model(hparams):\n",
    "    i = Input(shape=(T,))\n",
    "    x = Embedding(V + 1, D)(i)\n",
    "    x = LSTM(hparams[HP_NUM_UNITS],dropout=(hparams[HP_DROPOUT]),return_sequences=True)(x) \n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    model = Model(i, x)\n",
    "    model.compile(\n",
    "      optimizer='Adam',\n",
    "      loss='MSE',\n",
    "      metrics=['MAE'],\n",
    "    )\n",
    "    model.fit(data_train, \n",
    "              y_train, \n",
    "              epochs=5,\n",
    "              validation_data=(data_val, y_val)\n",
    "             )\n",
    "    _, MSE = model.evaluate(data_test, y_test)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        MSE = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_MAE, MSE, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning2/' + run_name, hparams)\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LSTM Hyperparameter Tuning](https://tensorboard.dev/experiment/TmUjuPT7RGCVp0dZ2pwUPQ/)\n",
    "The Tensorboard above summarizes some hyperaparmeter optimization for the LSTM Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Recommendations\n",
    "<div class = \"alert alert-success\">\n",
    "    <p> Deploying use of the GRU Price Predictive Model while listing a knife for resale can not only save time for the lister but can also help optimize for the correct price to list the knife which can balance between listing the knife too low and losing potential revenue or pricing the knife to high and creating inventory that stagnates on the shelf. The model should help balance excess inventory costs for too high of prices vs loss revenue caused by pricing the item correctly. \n",
    "    \n",
    "Based on the statistics of the dataset, the range of knife prices on eBay is quite large, from 6.95 USD to 166.50 USD. The mean price of 49.99 USD and median price of 38.86 USD indicate that the prices are skewed towards the lower end, but with a standard deviation of 35.84 USD, there is still a significant spread of prices.\n",
    "\n",
    "The performance of the Recurrent Neural Network (RNN) can be evaluated by comparing its prediction error to the spread of prices in the dataset. With an absolute error of 14.28 USD, the RNN is able to accurately predict the price within a range of approximately 29.57 USD (14.28 USD * 2). This is relatively close to the range of prices in the 25th to 75th percentile (22.25 to 67.29 USD).\n",
    "\n",
    "Therefore, the performance of the RNN can be considered decent, especially given the large range of prices in the dataset.\n",
    "    \n",
    "**Summary: I reccomend deploying the Price Predicting Model before posting a pocket knife for sale on eBay.**\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regPlot GRU](https://github.com/ddey117/Neural_Network_Predicting_Reseller_Success_Ebay/blob/master/images/RNN/regPlot_GRU_performance.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "\n",
    "# We get to choose embedding dimensionality\n",
    "D = 100\n",
    "\n",
    "\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V + 1, D)(i)\n",
    "x = Conv1D(32, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dense(1, activation='linear')(x)\n",
    "\n",
    "model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit\n",
    "model.compile(\n",
    "  loss='MSE',\n",
    "  optimizer='adam',\n",
    "  metrics=['mae']\n",
    ")\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "r = model.fit(\n",
    "  data_train,\n",
    "  Ytrain,\n",
    "  epochs=5,\n",
    "  validation_data=(data_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss per iteration\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy per iteration\n",
    "plt.plot(r.history['loss'], label='MSE')\n",
    "plt.plot(r.history['val_loss'], label='val_MSE')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN using images as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs = df.drop(['title', 'url', \n",
    "                   'date_sold', 'profit',\n",
    "                   'ROI', 'brand', 'cost',\n",
    "                   'pictureURLLarge'],\n",
    "                     axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs.dropna(subset=['Image'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['file_index'] = df_imgs.index.values\n",
    "df_imgs['file_index'] = df_imgs['file_index'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['filename'] = df_imgs['file_index'] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(row):\n",
    "    filename = row.filepath\n",
    "\n",
    "# create folder if it doesn't exist\n",
    "#     os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    url = row.Image\n",
    "#     print(f\"Downloading {url} to {filename}\")\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    except:\n",
    "        print(f'{filename} error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'C:/Users/12108/Documents/GitHub/Neural_Network_Predicting_Reseller_Success_Ebay/nn_images/'\n",
    "df_imgs['filepath'] = root_folder + df_imgs['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['filepath'].sample(2).apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_imgs.apply(download, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All image files are stored locally for this project. The below markdown code is for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "img_list = os.listdir('C:/Users/12108/Documents/GitHub/Neural_Network_Predicting_Reseller_Success_Ebay/nn_images/')\n",
    "\n",
    "img_df = df_imgs.loc[df_imgs['filename'].isin(img_list)].copy()\n",
    "\n",
    "img_df.reset_index(drop=True, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "img_df.rename({'Image': 'data',\n",
    "               'converted_price': 'labels'},\n",
    "                axis=1, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df_train, df_test, Ytrain, Ytest = train_test_split(img_df, Y, test_size=0.20)\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.20)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df_train,\n",
    "directory= None,\n",
    "x_col=\"filepath\",\n",
    "y_col=\"labels\",\n",
    "subset=\"training\",\n",
    "batch_size=100,\n",
    "seed=55,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\")\n",
    "    \n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df_train,\n",
    "directory=None,\n",
    "x_col=\"filepath\",\n",
    "y_col=\"labels\",\n",
    "subset=\"validation\",\n",
    "batch_size=100,\n",
    "seed=55,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df_test,\n",
    "directory=None,\n",
    "x_col=\"filepath\",\n",
    "y_col=\"labels\",\n",
    "batch_size=100,\n",
    "seed=55,\n",
    "shuffle=False,\n",
    "class_mode=\"raw\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu',\n",
    "#                         input_shape=(256 ,256,  3)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "#                         input_shape=(256 ,256,  3)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# model.compile(loss='MSE',\n",
    "#               optimizer='Adam',\n",
    "#                metrics=['mae', 'mse'])\n",
    "\n",
    "# summary = model.fit(train_generator, epochs=3, validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('cnn_grayscale_relu1.h5',  compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file=\"images/CNN_architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "### Recurrent Neural Network (GRU)\n",
    "The performance of the Recurrent Neural Network (RNN) can be evaluated by comparing its prediction error to the spread of prices in the dataset. With an absolute error of 14.28 USD, the RNN is able to accurately predict the price within a range of approximately 29.57 USD (14.28 USD * 2). This is relatively close to the range of prices in the 25th to 75th percentile (22.25 to 67.29 USD). Therefore, the performance of the RNN can be considered decent, especially given the large range of prices in the dataset.\n",
    "\n",
    "**This model is recommend for use when listing a pocket knife on sale to help list it appropriately.**\n",
    "\n",
    "\n",
    "\n",
    "### Convoluted Neural Network on Grayscale Images\n",
    "\n",
    "- The MAE when testing the CNN was roughly \\\\$25.00. That is an error of plus or minus about 50\\% of the mean price of knives sold. Not acceptable yet as compared to the RNN with titles. Will address in future work.\n",
    "\n",
    "## Future Work\n",
    "- Expand data to include other products readily purchasable at the Surplus Store. \n",
    "\n",
    "- Attempt data augmentation on the CNN image network\n",
    "\n",
    "- Attempt to obtain more aspect data for sold knives. Some important aspect data is limited access to sellers who average a certain amount of money per month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "### CNN for titles on best brand of knife: Case Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_title['labels'] = (df_title['labels']/mean_price)\n",
    "y = df_title['labels'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_title['data'],\n",
    "                                                    y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, \n",
    "                                                y_test, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "#Vectorize vocab \n",
    "voc_size = 10000\n",
    "max_len = 10\n",
    "embedding_features = 300\n",
    "tokenizer = Tokenizer(num_words=voc_size, oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train) \n",
    "sequences_val = tokenizer.texts_to_sequences(X_val)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#add padding to ensure all inputs are the same size\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_val = pad_sequences(sequences_val, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "data_test = pad_sequences(sequences_test, maxlen=max_len, padding= 'post', truncating = 'post')\n",
    "\n",
    "data_train.shape\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Embedding(voc_size, embedding_features, input_length = max_len)) \n",
    "model.add(GRU(100,dropout=0.3))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.summary()\n",
    "\n",
    "# Compile and fit\n",
    "model.compile(\n",
    "  loss='MSE',\n",
    "  optimizer='adam',\n",
    "  metrics=['mae']\n",
    ")\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "r = model.fit(\n",
    "  data_train,\n",
    "  y_train,\n",
    "  epochs=5,\n",
    "  validation_data=(data_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with TFIDF vectorization and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_title['labels'] = (df_title['labels']/mean_price)\n",
    "Y = df_title['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title['data'].sample(10).apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, Ytrain, Ytest = train_test_split(df_title['data'],\n",
    "                                                    Y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=51)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val, X_test, Y_val, Y_test = train_test_split(df_test, \n",
    "#                                                 Ytest, \n",
    "#                                                 test_size=0.5, \n",
    "#                                                 random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(df_train)\n",
    "X_train_vec = tfidf_vectorizer.transform(df_train)\n",
    "x_test_vec = tfidf_vectorizer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(verbose=3, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train_vec,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = Ytest\n",
    "y_pred = rf_model.predict(x_test_vec)\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_true, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_true, y_pred))\n",
    "print('Root Mean Squared Error (RMSE):', metrics.mean_squared_error(y_true, y_pred, squared=False))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_true, y_pred))\n",
    "print('Max Error:', metrics.max_error(y_true, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_true, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_true, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_true, y_pred))\n",
    "print('Mean Poisson Deviance:', metrics.mean_poisson_deviance(y_true, y_pred))\n",
    "print('Mean Gamma Deviance:', metrics.mean_gamma_deviance(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf_vectorizer.get_feature_names()\n",
    "fi = rf_model.feature_importances_\n",
    "importance = [(features[i], fi[i]) for i in range(0,2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_title['labels'] = (df_title['labels']/mean_price)\n",
    "Y = df_title['labels'].values\n",
    "\n",
    "df_title['data'].sample(10).apply(print)\n",
    "\n",
    "df_train, df_test, Ytrain, Ytest = train_test_split(df_title['data'],\n",
    "                                                    Y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=51)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_val, X_test, Y_val, Y_test = train_test_split(df_test, \n",
    "#                                                 Ytest, \n",
    "#                                                 test_size=0.5, \n",
    "#                                                 random_state=51)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(df_train)\n",
    "X_train_vec = tfidf_vectorizer.transform(df_train)\n",
    "x_test_vec = tfidf_vectorizer.transform(df_test)\n",
    "\n",
    "X_train_vec.get_shape()\n",
    "\n",
    "tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(verbose=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train_vec,Ytrain)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_true = Ytest\n",
    "y_pred = rf_model.predict(x_test_vec)\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_true, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_true, y_pred))\n",
    "print('Root Mean Squared Error (RMSE):', metrics.mean_squared_error(y_true, y_pred, squared=False))\n",
    "print('Explained Variance Score:', metrics.explained_variance_score(y_true, y_pred))\n",
    "print('Max Error:', metrics.max_error(y_true, y_pred))\n",
    "print('Mean Squared Log Error:', metrics.mean_squared_log_error(y_true, y_pred))\n",
    "print('Median Absolute Error:', metrics.median_absolute_error(y_true, y_pred))\n",
    "print('R^2:', metrics.r2_score(y_true, y_pred))\n",
    "print('Mean Poisson Deviance:', metrics.mean_poisson_deviance(y_true, y_pred))\n",
    "print('Mean Gamma Deviance:', metrics.mean_gamma_deviance(y_true, y_pred))\n",
    "\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "fi = rf_model.feature_importances_\n",
    "importance = [(features[i], fi[i]) for i in range(0,2000)]\n",
    "\n",
    "importance[:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
