{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eBay Finding API (Traditonal not RESTful)- findItemsAdvanced Call\n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "Lorem Khaled Ipsum is a major key to success. They key is to have every key, the key to open every door. They key is to have every key, the key to open every door. The key is to enjoy life, because they don’t want you to enjoy life. I promise you, they don’t want you to jetski, they don’t want you to smile. Special cloth alert. You smart, you loyal, you a genius. They will try to close the door on you, just open it. Always remember in the jungle there’s a lot of they in there, after you overcome they, you will make it to paradise.retrieve a full results set from the Yelp API.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Congratulations, you played yourself. Eliptical talk. The key to success is to keep your head above the water, never give up. Give thanks to the most high. Surround yourself with angels, positive energy, beautiful people, beautiful souls, clean heart, angel. Another one. A major key, never panic. Don’t panic, when it gets crazy and rough, don’t panic, stay calm. The key is to drink coconut, fresh coconut, trust me. Let me be clear, you have to make it through the jungle to make it to paradise, that’s the key, Lion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Query Yelp for All Businesses in a Category and Analyze the Results\n",
    "\n",
    "![restaurant counter with pizza](images/restaurant_counter.jpg)\n",
    "\n",
    "Photo by <a href=\"https://unsplash.com/@jordanmadrid?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Jordan Madrid</a> on <a href=\"/s/photos/pizza-restaurant?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "You've now worked with some API calls, but we have yet to see how to retrieve a more complete dataset in a programmatic manner. In this lab, you will write a query of businesses on Yelp, then use *pagination* to retrieve all possible results for that query. Then you will create a summary of your findings, including a Folium map of the geographic locations of those businesses.\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "Returning to the Yelp API, the [documentation](https://www.yelp.com/developers/documentation/v3/business_search) also provides us details regarding the **API limits**. These often include details about the number of requests a user is allowed to make within a specified time limit and the maximum number of results to be returned. In this case, we are told that any request has a **maximum of 50 results per request** and defaults to 20. Furthermore, any search will be limited to a **total of 1000 results**. To retrieve all 1000 of these results, we would have to page through the results piece by piece, retrieving 50 at a time. Processes such as these are often referred to as pagination.\n",
    "\n",
    "Also, be mindful of the **API** ***rate*** **limits**. You can only make **5000 requests per day** and are also can make requests too fast. Start prototyping small before running a loop that could be faulty. You can also use `time.sleep(n)` to add delays. For more details see https://www.yelp.com/developers/documentation/v3/rate_limiting.\n",
    "\n",
    "In this lab, you will define a search and then paginate over the results to retrieve all of the results. You'll then parse these responses as a list of dictionaries (for further exploration) and create a map using Folium to visualize the results geographically.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "#### 1. Make the Initial Request\n",
    "\n",
    "Start by filling in your API key to make the initial request to the business search API. Investigate the structure of the response you get back and start figuring out how you will extract the relevant information.\n",
    "\n",
    "#### 2. Add Pagination\n",
    "\n",
    "Using loops and functions, collect the maximum number of results for your query from the API.\n",
    "\n",
    "#### 3. Perform Exploratory Analysis\n",
    "\n",
    "Interpret visualizations related to the price range, average rating, and number of reviews for all query results.\n",
    "\n",
    "#### 4. Create a Folium Map\n",
    "\n",
    "Using latitude and longitude data, plot the query results on an interactive map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make the Initial Request\n",
    "\n",
    "### Querying\n",
    "\n",
    "Start by making an initial request to the Yelp API. Your search must include at least 2 parameters: **term** and **location**. For example, you might search for pizza restaurants in NYC. The term and location is up to you but make the request below.\n",
    "\n",
    "Use the `requests` library ([documentation here](https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request)).\n",
    "\n",
    "You'll also need an API key from Yelp. If you haven't done this already, go to the Yelp [Manage App page](https://www.yelp.com/developers/v3/manage_app) and create a new app (after making an account if you haven't already)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dylandey/Desktop/ebay_project/dsc-5-capstone-project\n",
      "Python 3.8.5\r\n"
     ]
    }
   ],
   "source": [
    "import xmltodict, json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"ebay_api_key.env\") #hide production key in environment file\n",
    "print(os.getcwd())\n",
    "!python3 --version\n",
    "\n",
    "\n",
    "APP_ID = os.getenv(\"EBAY_PROD_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL \n",
    "HTTP call url to send the Production Client API. The Payload will modify the url below with a ? followed by an % and key value pairs. This is the most common and recommended way that ebay suggests users to send a request to the Finding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://svcs.ebay.com/services/search/FindingService/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP Headers\n",
    "Required headers to return a 200 response code. The top header is AuthnAuth security. As there is no need for a user token and the only interface is with my app, the only security required is for the app. The second row is the call be sent to the Finding API, findItemsAdvanced. ## THIS SHOULD BE A LINK DOG.   The third formats the respons as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"X-EBAY-SOA-SECURITY-APPNAME\": APP_ID, #production client_id\n",
    "           \"X-EBAY-SOA-OPERATION-NAME\": \"findItemsAdvanced\", #call_id\n",
    "           \"X-EBAY-API-RESPONSE-ENCODING\": \"JSON\" #format respons as JSON\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Payload\n",
    "Modifies HTTP call. Search for knife in the Collectible-Modern-Factory-Manufactured-Folding-Knives that is of the Used Condition. This request returns 100 pages on page 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_G = {\"keywords\":\"knife\", #knife in search bar\n",
    "             \"categoryId\":\"48818\", #Collectible-Modern-Factory-Manufactured-Folding-Knives\n",
    "             \"itemFilter.name\":\"Condition\",\n",
    "             \"itemFilter.value\":\"Used\",\n",
    "             \"aspectFilter.aspectName\": \"Brand\",\n",
    "             \"aspectFilter.aspectValueName\": \"Gerber\",\n",
    "             \"paginationInput.entriesPerPage\":100,\n",
    "             \"paginationInput.pageNumber\":1\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request\n",
    "send HTTP request to ebay Fiding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://svcs.ebay.com/services/search/FindingService/v1?keywords=knife&categoryId=48818&itemFilter.name=Condition&itemFilter.value=Used&aspectFilter.aspectName=Brand&aspectFilter.aspectValueName=Gerber&paginationInput.entriesPerPage=100&paginationInput.pageNumber=1\n"
     ]
    }
   ],
   "source": [
    "r_gerb = requests.get(url, headers=headers, params=payload_G)\n",
    "print(r_gerb.url)\n",
    "json_dict_gerb = xmltodict.parse(r_gerb.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerb_list_of_dicts = json_dict_gerb['findItemsAdvancedResponse']['searchResult']['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['itemId', 'title', 'globalId', 'primaryCategory', 'galleryURL', 'viewItemURL', 'autoPay', 'postalCode', 'location', 'country', 'shippingInfo', 'sellingStatus', 'listingInfo', 'returnsAccepted', 'condition', 'isMultiVariationListing', 'topRatedListing'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerb_list_of_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of dictionaries and prepares it\n",
    "    for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a new list to hold results\n",
    "    results = []\n",
    "    \n",
    "    for business_data in data_list:\n",
    "    \n",
    "        # Make a new dictionary to hold prepared data for this business\n",
    "        prepared_data = {}\n",
    "        \n",
    "        # Extract name, review_count, rating, and price key-value pairs\n",
    "        # from business_data and add to prepared_data\n",
    "        # If a key is not present in business_data, add it to prepared_data\n",
    "        # with an associated value of None\n",
    "        \n",
    "        keys = ['itemId', 'title', 'galleryURL', \n",
    "        'viewItemURL', 'postalCode', 'location', \n",
    "        'country', 'shippingInfo', 'sellingStatus', \n",
    "        'listingInfo', 'returnsAccepted', 'condition',\n",
    "       ]\n",
    "        \n",
    "        for key in keys:\n",
    "            prepared_data[key] = business_data.get(key, None)\n",
    "    \n",
    "       \n",
    "        # Add to list if all values are present\n",
    "        if all(prepared_data.values()):\n",
    "            results.append(prepared_data)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_gerber = prepare_data(gerb_data_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_pages = json_dict_gerb['findItemsAdvancedResponse']['paginationOutput']['totalPages']\n",
    "total_pages = int(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f12ea40e2379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Get the list of businesses from the response_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mknives_data_list_of_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_dict_gerb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'findItemsAdvancedResponse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'searchResult'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Call the prepare_data function to get a list of processed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'item'"
     ]
    }
   ],
   "source": [
    "# Create an empty list for the full prepared dataset\n",
    "gerb_dataset = []\n",
    "\n",
    "for page in range(5, 20):\n",
    "    # Add or update the \"offset\" key-value pair in url_params\n",
    "    payload_G[\"paginationInput.pageNumber\"] = page\n",
    "    \n",
    "    # Make the query and get the response\n",
    "    r_gerb = requests.get(url, headers=headers, params=payload_G)\n",
    "    \n",
    "    # Get the response body in JSON format\n",
    "    json_dict_gerb = xmltodict.parse(r_gerb.text)\n",
    "    \n",
    "    # Get the list of businesses from the response_json\n",
    "    knives_data_list_of_dicts = json_dict_gerb['findItemsAdvancedResponse']['searchResult']['item']\n",
    "    \n",
    "    # Call the prepare_data function to get a list of processed data\n",
    "    prepared_knives = prepare_data(knives_data_list_of_dicts)\n",
    "    \n",
    "    # Extend full_dataset with this list (don't append, or you'll get\n",
    "    # a list of lists instead of a flat list)\n",
    "    gerb_dataset.extend(prepared_knives)\n",
    "\n",
    "# Check the length of the full dataset. It will be up to `total`,\n",
    "# potentially less if there were missing values\n",
    "len(gerb_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(full_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"full_dataset2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create row for converted Price of Knives in US dollars\n",
    "price_list = []\n",
    "for row in full_dataset2:\n",
    "    price_list.append(row['sellingStatus']['convertedCurrentPrice']['#text'])\n",
    "    \n",
    "#Create row  for Condition of Knife (should be used)    \n",
    "condition_list = []\n",
    "for row in full_dataset2:\n",
    "    condition_list.append(row['condition']['conditionDisplayName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"price_in_US\"] = price_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"condition\"] = condition_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"full_dataset.csv2\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
