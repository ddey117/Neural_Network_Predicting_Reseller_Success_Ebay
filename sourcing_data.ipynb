{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Resale Value of Knives from a Texas Government Surplus Store\n",
    "## Using Machine Learning to Support an Ebay Store's Financial Success\n",
    "\n",
    "### Data Obtainment Notebook\n",
    "\n",
    "\n",
    "This notebook displays the code used to collect and process data from eBay using two of eBay's public APIs and scraping from their proprietary webabb \"Terapeak\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebaysdk.finding import Connection\n",
    "import requests\n",
    "from ebaysdk.shopping import Connection as Shopping\n",
    "import pandas as pd \n",
    "import  json\n",
    "import numpy as np\n",
    "import re\n",
    "# import preprocess_ddey117 as pp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import ast\n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is a helper function created for the \"knife_request\" below. \n",
    "#It unpacks some of the nested data from eBay API calls \n",
    "#It also creates the new feature \"converted_price\"\n",
    "#\"converted_price\" is the price of the item for sale plus shipping cost.\n",
    "def prepare_df(df):\n",
    "    price_list = []\n",
    "    ship_price_list = []\n",
    "    condition_list = []\n",
    "    condition = None\n",
    "    for row in full_dataset:\n",
    "        listed_price = float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "        price_list.append(listed_price)\n",
    "     \n",
    "        try:\n",
    "            listed_ship_price = float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "            ship_price_list.append(listed_ship_price)\n",
    "        except: \n",
    "            listed_ship_price = 0\n",
    "            ship_price_list.append(listed_ship_price)\n",
    "\n",
    "        try:\n",
    "            condition = float(row['condition']['conditionId'])\n",
    "            condition_list.append(condition)\n",
    "        except: \n",
    "            conditon = 0\n",
    "            condition_list.append(condition)\n",
    "\n",
    "    df['shipping_cost'] = ship_price_list\n",
    "    df['price_in_US'] = price_list\n",
    "    df['condition'] = condition_list\n",
    "    \n",
    "    #create new feature 'converted price'\n",
    "    df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "    df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#dictionary for preparing brands\n",
    "bucket_dict = {'benchmade': 45.0,\n",
    "               'buck': 20.0,\n",
    "               'case': 20.0,\n",
    "               'crkt': 15.0,\n",
    "               'kershaw': 15.0,\n",
    "               'sog': 15.0,\n",
    "               'spyderco': 30.0,\n",
    "               'victorinox': 20.0\n",
    "              }\n",
    "\n",
    "#a helper function used with knife_request \n",
    "#it is used to create new columns of interest\n",
    "#the brand of knife from the API call\n",
    "#the cost of the knife from the Surplus Store\n",
    "#profit for reselling a used surplus knife on eBay\n",
    "#Return on Investment for reselling the knife\n",
    "#All columns in US dollars\n",
    "def prepare_brands(df, bucket_dict_position, overhead_cost=3):\n",
    "\n",
    "    df.title = df.title.apply(str.lower)\n",
    " \n",
    "    #remove special characters\n",
    "#     df.title.apply(pp.remove_special_chars)\n",
    "    df['brand'] = str(list(bucket_dict.keys())[bucket_dict_position])\n",
    "    df['cost'] = float(list(bucket_dict.values())[bucket_dict_position])\n",
    "    df['profit'] = ((df['converted_price']*.87) -  df['cost'] - overhead_cost)\n",
    "    df['ROI'] = (df['profit']/( df['cost'] + overhead_cost))*100.0\n",
    "    \n",
    "    return df\n",
    "# Help organize paginated data from API calls\n",
    "def prepare_data(data_list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of dictionaries and prepares it\n",
    "    for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a new list to hold results\n",
    "    results = []\n",
    "    \n",
    "    for business_data in data_list:\n",
    "    \n",
    "        # Make a new dictionary to hold prepared data for this business\n",
    "        prepared_data = {}\n",
    "        \n",
    "        # Extract name, review_count, rating, and price key-value pairs\n",
    "        # from business_data and add to prepared_data\n",
    "        # If a key is not present in business_data, add it to prepared_data\n",
    "        # with an associated value of None\n",
    "        \n",
    "        keys = ['itemId', 'title', 'galleryURL', \n",
    "                'viewItemURL', 'autoPay', 'postalCode', \n",
    "                'sellingStatus', 'shippingInfo', 'listingInfo',\n",
    "                'returnsAccepted', 'condition', 'topRatedListing',\n",
    "                'galleryPlusPictureURL','pictureURLLarge', \n",
    "                'pictureURLSuperSize']\n",
    "        \n",
    "        for key in keys:\n",
    "            prepared_data[key] = business_data.get(key, None)\n",
    "            results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "        # Add to list if all values are present\n",
    "#         if all(prepared_data.values()):\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "    \n",
    "    return results\n",
    "#main function for making findingAPI calls to eBay\n",
    "def knife_request(Brand, dict_pos):\n",
    "    api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "    #first request gets number of pages from paginationOutput of first page \n",
    "    request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': 1\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "    #     request['paginationInput']['pageNumber'] = page\n",
    "\n",
    "    response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "\n",
    "    response_pages = response.dict()\n",
    "\n",
    "    full_dataset = []\n",
    "    \n",
    "    total_pages = int(response_pages['paginationOutput']['totalPages'])\n",
    "\n",
    "    if total_pages > 100:\n",
    "        pages_to_request = 100\n",
    "        \n",
    "    else:\n",
    "        pages_to_request = total_pages - 1\n",
    "        #subtract number of pages by one to avoid errors\n",
    "        \n",
    "    #Loop through available pages\n",
    "    for page in range(1, pages_to_request):\n",
    "        # Add or update the \"offset\" key-value pair in url_params\n",
    "\n",
    "        # Make the query and get the response\n",
    "\n",
    "        api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "        request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': page\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "        response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "        #save the response as a json dict\n",
    "        response_dict = response.dict()\n",
    "\n",
    "\n",
    "        #index dict to appropriate index\n",
    "        results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "        # Call the prepare_data function to get a list of processed data\n",
    "        prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "        # Extend full_dataset with this list (don't append, or you'll get\n",
    "        # a list of lists instead of a flat list)\n",
    "        full_dataset.extend(prepared_knives)\n",
    "\n",
    "    # Check the length of the full dataset. It will be up to `total`,\n",
    "    # potentially less if there were missing values\n",
    "    display(len(full_dataset))\n",
    "    \n",
    "    df = pd.DataFrame(full_dataset)\n",
    "    \n",
    "    df = prepare_df(df)\n",
    "    \n",
    "    df = prepare_brands(df, dict_pos)\n",
    "    \n",
    "    return df\n",
    "#Used to prepare data from eBays shopping API\n",
    "#Shopping API used to collect more detailed info\n",
    "#about individual knives\n",
    "def prepare_dataIds(data_list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of dictionaries and prepares it\n",
    "    for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a new list to hold results\n",
    "    results = []\n",
    "    \n",
    "    for business_data in data_list:\n",
    "    \n",
    "        # Make a new dictionary to hold prepared data for this business\n",
    "        prepared_data = {}\n",
    "        \n",
    "        # Extract name, review_count, rating, and price key-value pairs\n",
    "        # from business_data and add to prepared_data\n",
    "        # If a key is not present in business_data, add it to prepared_data\n",
    "        # with an associated value of None\n",
    "        \n",
    "        keys = ['ItemID','GalleryURL','PictureURL',\n",
    "                'Location','ConvertedCurrentPrice',\n",
    "                'Title','ItemSpecifics', \n",
    "                'Country','ConditionID']\n",
    "        \n",
    "        for key in keys:\n",
    "            prepared_data[key] = business_data.get(key, None)\n",
    "            results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "        # Add to list if all values are present\n",
    "#         if all(prepared_data.values()):\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "    \n",
    "    return results\n",
    "#Shopping api accepts a max of 20 itemIDs\n",
    "#this function was created to automate\n",
    "#making API calls in 20 unique itemId chuncks\n",
    "def process_list(my_list):\n",
    " \n",
    "    api = Shopping(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "    request = {\n",
    "               'itemID': my_list,\n",
    "               'IncludeSelector': 'ItemSpecifics'\n",
    "              }\n",
    "    response = api.execute('GetMultipleItems', request)\n",
    "\n",
    "    \n",
    "\n",
    "    #save the response as a json dict\n",
    "    response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "    #index dict to appropriate index\n",
    "    results_list_of_dicts = response_dict['Item']\n",
    "\n",
    "    # Call the prepare_data function to get a list of processed data\n",
    "    prepared_knives = prepare_dataIds(results_list_of_dicts)\n",
    "\n",
    "    # Extend full_dataset with this list (don't append, or you'll get\n",
    "    # a list of lists instead of a flat list)\n",
    "    full_dataset.extend(prepared_knives)\n",
    "    \n",
    "    return full_dataset\n",
    "\n",
    "bucket_dict = {'benchmade': 45.0,\n",
    "               'buck': 20.0,\n",
    "               'case': 20.0,\n",
    "               'crkt': 15.0,\n",
    "               'kershaw': 15.0,\n",
    "               'sog': 15.0,\n",
    "               'spyderco': 30.0,\n",
    "               'victorinox': 20.0\n",
    "              }\n",
    "#special function for reformatting terapeak scraped data\n",
    "#x = position of bucket_dictionary\n",
    "def prepare_tera_df(df, x, overhead_cost=3):\n",
    "    df['price_in_US'] = df['price_in_US'].str.replace(\"$\", \"\")\n",
    "    df['price_in_US'] = df['price_in_US'].str.replace(\",\", \"\")\n",
    "    df['price_in_US'] = df['price_in_US'].apply(float)\n",
    "    \n",
    "    df['shipping_cost'] = df['shipping_cost'].str.replace(\"$\", \"\")\n",
    "    df['shipping_cost'] = df['shipping_cost'].str.replace(\",\", \"\")\n",
    "    df['shipping_cost'] = df['shipping_cost'].apply(float)\n",
    "    \n",
    "    df['converted_price'] = (df['price_in_US'] + df['shipping_cost'])\n",
    "    \n",
    "    df['profit'] = ((df['converted_price']*.87) - list(bucket_dict.values())[x] - overhead_cost)\n",
    "    df['ROI'] = (df['profit']/(list(bucket_dict.values())[x]))*100.0\n",
    "    \n",
    "    df['brand'] = list(bucket_dict.keys())[x]\n",
    "    df['cost'] = list(bucket_dict.values())[x]\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# helper function with \"transform_item_specifics\"\n",
    "def fix(col):\n",
    "    dd = dict()\n",
    "    for d in col:\n",
    "        values = list(d.values())\n",
    "        if len(values) == 2:\n",
    "            dd[values[0]] = values[1]\n",
    "    return dd\n",
    "\n",
    "#function for extracted item Specifics from Shopping API data\n",
    "def transform_item_specifics(df, perc=65.0):\n",
    "\n",
    "    df.dropna(subset=['ItemSpecifics'], inplace=True)\n",
    "    df['ItemSpecifics'] = df['ItemSpecifics'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['item_list'] = df['ItemSpecifics'].apply(lambda x: x['NameValueList'])\n",
    "\n",
    "    df['ItemSpecifics'] = df['ItemSpecifics'].apply(lambda x: [x['NameValueList']] if isinstance(x['NameValueList'], dict) else x['NameValueList'])\n",
    "\n",
    "    df['ItemSpecifics'] = df['ItemSpecifics'].apply(fix)\n",
    "\n",
    "    df = pd.json_normalize(df['ItemSpecifics'])\n",
    "\n",
    "    min_count =  int(((100-perc)/100)*df.shape[0] + 1)\n",
    "    mod_df = df.dropna(axis=1, \n",
    "                       thresh=min_count)\n",
    "\n",
    "    return mod_df\n",
    "\n",
    "# This function removes noisy data\n",
    "#lots/sets/groups of knives can\n",
    "#confuse the model from predicting\n",
    "#the appropriate value of individual knives\n",
    "def data_cleaner(df):\n",
    "    lot = re.compile('(?<!-\\S)lot(?![^\\s.,:?!])')\n",
    "    group = re.compile('(group)')\n",
    "    is_set = re.compile('(?<!-\\S)set(?![^\\s.,?!])')\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    trim_list = [lot,group,is_set]\n",
    "    for item in trim_list:\n",
    "        df.loc[df['title'].apply(lambda x: re.search(item, x)).notnull(), 'trim'] = 1 \n",
    "    to_drop = df.loc[df['trim'] == 1].index\n",
    "    df.drop(to_drop, inplace=True)\n",
    "    df.drop('trim', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benchmade': 45.0,\n",
       " 'buck': 20.0,\n",
       " 'case': 20.0,\n",
       " 'crkt': 15.0,\n",
       " 'kershaw': 15.0,\n",
       " 'sog': 15.0,\n",
       " 'spyderco': 30.0,\n",
       " 'victorinox': 20.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning of API calls for listed data. To be merged with item specific data using ebay itemIds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Understading: Cost Breakdown\n",
    "- padded envelopes: \\$0.50 per knife\n",
    "- flatrate shipping: \\$4.45 per knife\n",
    "- brand knife at surplus store: 15, 20, 30, or 45 dollars per knife\n",
    "- overhead expenses (gas, cleaning suplies, sharpening supplies, etc): $3\n",
    "- Ebay's comission, with 13\\% being a reasonable approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listed Data\n",
    "\n",
    "Running functions to call the Finding API and return datasets for cat () knives for sale listed on ebay in the last 90 days. (explain how ebay rules work)\n",
    "\n",
    "```\n",
    "bench_df = knife_request('Benchmade', 0)\n",
    "buck_df = knife_request('Buck', 1)\n",
    "case_df = knife_request('Case', 2)\n",
    "df_caseXX = knife_request('Case XX', 2)\n",
    "df_crkt = knife_request(\"CRKT\", 3)\n",
    "df_sog = knife_request('SOG', 5)\n",
    "df_spyderco = knife_request('Spyderco', 6)\n",
    "\n",
    "\n",
    "bench_df.to_csv('listed_data/df_bench1.csv', index=False)\n",
    "buck_df.to_csv('listed_data/df_buck.csv', index=False)\n",
    "case_df.to_csv('listed_data/df_case.csv', index=False)\n",
    "df_caseXX.to_csv('listed_data/df_CaseXX.csv', index=False)\n",
    "df_crkt.to_csv('listed_data/df_crkt.csv', index=False)\n",
    "df_sog.to_csv('listed_data/df_sog.csv', index=False)\n",
    "df_spyderco.to_csv('listed_data/df_spyderco.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kershaw and victorinox data was requested using the FindingAPI below after tweaking some pagination through trial and error to maximize data.\n",
    "\n",
    "```\n",
    "full_dataset = []\n",
    "for page in range(1, 57):\n",
    "#         # Add or update the \"offset\" key-value pair in url_params\n",
    "\n",
    "#         # Make the query and get the response\n",
    "\n",
    "    api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "    request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': 'Kershaw'}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': page\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "        #     request['paginationInput']['pageNumber'] = page\n",
    "\n",
    "    response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "    #save the response as a json dict\n",
    "    response_dict = response.dict()\n",
    "\n",
    "    #index dict to appropriate index\n",
    "    results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "    # Call the prepare_data function to get a list of processed data\n",
    "    prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "    # Extend full_dataset with this list (don't append, or you'll get\n",
    "    # a list of lists instead of a flat list)\n",
    "    full_dataset.extend(prepared_knives)\n",
    "\n",
    "    # Check the length of the full dataset. It will be up to `total`,\n",
    "    # potentially less if there were missing values\n",
    "\n",
    "    df = pd.DataFrame(full_dataset)\n",
    "    \n",
    "df_kershaw = prepare_df(df)\n",
    "df_kershaw = prepare_brands(df_kershaw, 4)\n",
    "df_kershaw.to_csv('listed_data/df_kershaw.csv', index=False)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "full_dataset = []\n",
    "for page in range(1, 86):\n",
    "\n",
    "    api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "    request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': 'Victorinox'}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': page\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "    response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "    response_dict = response.dict()\n",
    "\n",
    "    results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "    prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "    full_dataset.extend(prepared_knives)\n",
    "    \n",
    "df_victorinox = pd.DataFrame(full_dataset)\n",
    "df_victorinox = prepare_df(df_victorinox)\n",
    "df_victorinox = prepare_brands(df_victorinox, 7)\n",
    "df_victorinox.to_csv('listed_data/df_victorinox.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start of API call section using IDs from preview listed datasets to get Item Specific data from ebay. This will return more descriptive information about the knives, pulling from a container on the website that sellers must complete to post a listing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.read_csv(\"listed_data/df_bench.csv\")\n",
    "df_buck = pd.read_csv(\"listed_data/df_buck.csv\")\n",
    "df_case = pd.read_csv(\"listed_data/df_case.csv\")\n",
    "df_caseXX = pd.read_csv(\"listed_data/df_CaseXX.csv\")\n",
    "df_crkt = pd.read_csv(\"listed_data/df_crkt.csv\")\n",
    "df_kersh = pd.read_csv(\"listed_data/df_kershaw.csv\")\n",
    "df_sog = pd.read_csv(\"listed_data/df_sog.csv\")\n",
    "df_spyd = pd.read_csv(\"listed_data/df_spyderco.csv\")\n",
    "df_vict = pd.read_csv(\"listed_data/df_victorinox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_bench,df_buck,\n",
    "           df_case,df_caseXX,\n",
    "           df_crkt,df_kersh,\n",
    "           df_sog,df_spyd,\n",
    "           df_vict]\n",
    "\n",
    "for dataframe in df_list:\n",
    "    dataframe.drop('galleryPlusPictureURL', axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchIds = df_bench.itemId.values.tolist()\n",
    "buckIds = df_buck.itemId.values.tolist()\n",
    "caseIds = df_case.itemId.values.tolist()\n",
    "caseXXIds = df_caseXX.itemId.values.tolist()\n",
    "crktIds = df_crkt.itemId.values.tolist()\n",
    "kershawIds = df_kersh.itemId.values.tolist()\n",
    "sogIds = df_sog.itemId.values.tolist()\n",
    "spydIds = df_spyd.itemId.values.tolist()\n",
    "victIds = df_vict.itemId.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return benchmade item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(benchIds), 20):\n",
    "    process_list(benchIds[i:i+20])\n",
    "\n",
    "bench = pd.DataFrame(full_dataset)\n",
    "bench.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "bench.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return buck item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(buckIds), 20):\n",
    "    process_list(buckIds[i:i+20])\n",
    "\n",
    "buck = pd.DataFrame(full_dataset)\n",
    "buck.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "buck.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return case brand item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(caseIds), 20):\n",
    "    process_list(caseIds[i:i+20])\n",
    "\n",
    "df_case = pd.DataFrame(full_dataset)\n",
    "df_case.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "df_case.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return caseXX brand item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(caseXXIds), 20):\n",
    "    process_list(caseXXIds[i:i+20])\n",
    "\n",
    "df_caseXX = pd.DataFrame(full_dataset)\n",
    "df_caseXX.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "df_caseXX.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return crkt item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(crktIds), 20):\n",
    "    process_list(crktIds[i:i+20])\n",
    "\n",
    "crkt = pd.DataFrame(full_dataset)\n",
    "crkt.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "crkt.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return kershaw item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(kershawIds), 20):\n",
    "    process_list(kershawIds[i:i+20])\n",
    "\n",
    "kershaw = pd.DataFrame(full_dataset)\n",
    "kershaw.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "kershaw.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return SOG item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(sogIds), 20):\n",
    "    process_list(sogIds[i:i+20])\n",
    "\n",
    "sog = pd.DataFrame(full_dataset)\n",
    "sog.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "sog.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ShoppingAPI call to return spyderco item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(spydIds), 20):\n",
    "    process_list(spydIds[i:i+20])\n",
    "spyd = pd.DataFrame(full_dataset)\n",
    "spyd.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "spyd.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return victorinox item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(victIds), 20):\n",
    "    process_list(victIds[i:i+20])\n",
    "    \n",
    "vict = pd.DataFrame(full_dataset)\n",
    "vict.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "vict.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "bench.to_csv(\"listed_data/benchIds.csv\", index=False)\n",
    "buck.to_csv(\"listed_data/buckIds.csv\", index=False)\n",
    "df_case.to_csv(\"listed_data/caseIds.csv\", index=False)\n",
    "df_caseXX.to_csv(\"listed_data/caseXXIds.csv\", index=False)\n",
    "crkt.to_csv(\"listed_data/crktIds.csv\", index=False)\n",
    "kershaw.to_csv(\"listed_data/kershawIds.csv\", index=False)\n",
    "leath.to_csv(\"listed_data/leathIds.csv\", index=False)\n",
    "sog.to_csv(\"listed_data/sogIds.csv\", index=False)\n",
    "spyd.to_csv(\"listed_data/spydIds.csv\", index=False)\n",
    "vict.to_csv(\"listed_data/victIds.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning of prep to merge original listed data with item specific data requested using a seperate API for more complete details about all listings gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = pd.read_csv(\"listed_data/benchIds.csv\")\n",
    "buck = pd.read_csv(\"listed_data/buckIds.csv\")\n",
    "case = pd.read_csv(\"listed_data/caseIds.csv\")\n",
    "caseXX = pd.read_csv(\"listed_data/caseXXIds.csv\")\n",
    "crkt = pd.read_csv(\"listed_data/crktIds.csv\")\n",
    "kershaw = pd.read_csv(\"listed_data/kershawIds.csv\")\n",
    "sog = pd.read_csv(\"listed_data/sogIds.csv\")\n",
    "spyd = pd.read_csv(\"listed_data/spydIds.csv\")\n",
    "vict = pd.read_csv(\"listed_data/victIds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids_df = pd.concat([bench,buck,\n",
    "                   case,caseXX,\n",
    "                   crkt,kershaw,\n",
    "                   sog,spyd,vict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['ItemID', 'GalleryURL', 'PictureURL', 'Location', 'ConvertedCurrentPrice', 'Title', 'ItemSpecifics', 'Country', 'ConditionID'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_list = [bench,buck,\n",
    "           case,caseXX,\n",
    "           crkt,kershaw,\n",
    "           sog,spyd]\n",
    "\n",
    "for dataframe in df_list:\n",
    "    display(dataframe.columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [bench,buck,\n",
    "           case,caseXX,\n",
    "           crkt,kershaw,\n",
    "           sog,spyd,vict]\n",
    "\n",
    "for dataframe in df_list:\n",
    "    dataframe.rename({'Title': 'title',\n",
    "                      'ItemID': 'itemId'},\n",
    "                     axis=1,inplace=True)\n",
    "    \n",
    "    dataframe.drop(['ConditionID','ConvertedCurrentPrice'], \n",
    "                   axis=1, inplace=True)\n",
    "    dataframe['title'] = dataframe['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge Item Specific dataframes with original listed data using itemIds and title\n",
    "bench_merged = df_bench.merge(bench)\n",
    "buck_merged = df_buck.merge(buck)\n",
    "case_merged = df_case.merge(case)\n",
    "caseXX_merged = df_caseXX.merge(caseXX)\n",
    "crkt_merged = df_crkt.merge(crkt)\n",
    "kershaw_merged = df_kersh.merge(kershaw)\n",
    "spyd_merged = df_spyd.merge(spyd)\n",
    "sog_merged = df_sog.merge(sog)\n",
    "vict_merged = df_vict.merge(vict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_spec = transform_item_specifics(bench_merged)\n",
    "buck_spec = transform_item_specifics(buck_merged)\n",
    "case_spec = transform_item_specifics(case_merged)\n",
    "caseXX_spec = transform_item_specifics(caseXX_merged)\n",
    "crkt_spec = transform_item_specifics(crkt_merged)\n",
    "kershaw_spec = transform_item_specifics(kershaw_merged)\n",
    "sog_spec = transform_item_specifics(sog_merged)\n",
    "spyd_spec = transform_item_specifics(spyd_merged)\n",
    "vict_spec = transform_item_specifics(vict_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_list = [bench_spec, buck_spec,\n",
    "              case_spec, caseXX_spec,\n",
    "              crkt_spec, kershaw_spec,\n",
    "              sog_spec, spyd_spec,\n",
    "              vict_spec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1979 entries, 0 to 1978\n",
      "Data columns (total 16 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Blade Material                 1008 non-null   object\n",
      " 1   Model                          1696 non-null   object\n",
      " 2   Product Line                   772 non-null    object\n",
      " 3   Opening Mechanism              1105 non-null   object\n",
      " 4   Number of Blades               1180 non-null   object\n",
      " 5   Handle Material                1301 non-null   object\n",
      " 6   Blade Type                     1042 non-null   object\n",
      " 7   Brand                          1947 non-null   object\n",
      " 8   Color                          1431 non-null   object\n",
      " 9   Type                           1497 non-null   object\n",
      " 10  Country/Region of Manufacture  1166 non-null   object\n",
      " 11  Lock Type                      831 non-null    object\n",
      " 12  Blade Edge                     1045 non-null   object\n",
      " 13  Dexterity                      758 non-null    object\n",
      " 14  Original/Reproduction          718 non-null    object\n",
      " 15  Blade Range                    813 non-null    object\n",
      "dtypes: object(16)\n",
      "memory usage: 247.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2748 entries, 0 to 2747\n",
      "Data columns (total 16 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Type                           2039 non-null   object\n",
      " 1   Model                          2286 non-null   object\n",
      " 2   Blade Material                 1380 non-null   object\n",
      " 3   Lock Type                      1431 non-null   object\n",
      " 4   Blade Type                     1171 non-null   object\n",
      " 5   Blade Edge                     1430 non-null   object\n",
      " 6   Color                          1751 non-null   object\n",
      " 7   Number of Blades               2010 non-null   object\n",
      " 8   Opening Mechanism              1679 non-null   object\n",
      " 9   Handle Material                1627 non-null   object\n",
      " 10  Brand                          2717 non-null   object\n",
      " 11  Original/Reproduction          1188 non-null   object\n",
      " 12  Blade Range                    1020 non-null   object\n",
      " 13  Dexterity                      1081 non-null   object\n",
      " 14  Country/Region of Manufacture  1618 non-null   object\n",
      " 15  Modified Item                  1019 non-null   object\n",
      "dtypes: object(16)\n",
      "memory usage: 343.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9191 entries, 0 to 9190\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Type                           6676 non-null   object\n",
      " 1   Model                          6800 non-null   object\n",
      " 2   Dexterity                      4239 non-null   object\n",
      " 3   Blade Edge                     5159 non-null   object\n",
      " 4   Blade Material                 5495 non-null   object\n",
      " 5   Brand                          9014 non-null   object\n",
      " 6   Number of Blades               6020 non-null   object\n",
      " 7   Handle Material                6071 non-null   object\n",
      " 8   Blade Range                    4173 non-null   object\n",
      " 9   Color                          5670 non-null   object\n",
      " 10  Opening Mechanism              5327 non-null   object\n",
      " 11  Blade Type                     4995 non-null   object\n",
      " 12  Lock Type                      4593 non-null   object\n",
      " 13  Original/Reproduction          4481 non-null   object\n",
      " 14  Country/Region of Manufacture  4900 non-null   object\n",
      "dtypes: object(15)\n",
      "memory usage: 1.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7293 entries, 0 to 7292\n",
      "Data columns (total 13 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Brand                          7229 non-null   object\n",
      " 1   Blade Material                 4923 non-null   object\n",
      " 2   Type                           6200 non-null   object\n",
      " 3   Color                          5867 non-null   object\n",
      " 4   Opening Mechanism              4535 non-null   object\n",
      " 5   Model                          6532 non-null   object\n",
      " 6   Blade Edge                     2918 non-null   object\n",
      " 7   Original/Reproduction          2584 non-null   object\n",
      " 8   Number of Blades               5834 non-null   object\n",
      " 9   Country/Region of Manufacture  5074 non-null   object\n",
      " 10  Blade Type                     2642 non-null   object\n",
      " 11  Year                           2646 non-null   object\n",
      " 12  Handle Material                5754 non-null   object\n",
      "dtypes: object(13)\n",
      "memory usage: 740.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1465 entries, 0 to 1464\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Brand                  1460 non-null   object\n",
      " 1   Type                   1181 non-null   object\n",
      " 2   Color                  1090 non-null   object\n",
      " 3   Model                  1341 non-null   object\n",
      " 4   Lock Type              918 non-null    object\n",
      " 5   Number of Blades       1100 non-null   object\n",
      " 6   Blade Type             870 non-null    object\n",
      " 7   Opening Mechanism      983 non-null    object\n",
      " 8   Handle Material        925 non-null    object\n",
      " 9   Blade Material         799 non-null    object\n",
      " 10  Blade Range            607 non-null    object\n",
      " 11  Blade Edge             938 non-null    object\n",
      " 12  Original/Reproduction  562 non-null    object\n",
      "dtypes: object(13)\n",
      "memory usage: 148.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5321 entries, 0 to 5320\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Blade Material                 2873 non-null   object\n",
      " 1   Dexterity                      1950 non-null   object\n",
      " 2   Color                          3501 non-null   object\n",
      " 3   Opening Mechanism              3282 non-null   object\n",
      " 4   Blade Edge                     3023 non-null   object\n",
      " 5   Brand                          5242 non-null   object\n",
      " 6   Blade Type                     2563 non-null   object\n",
      " 7   Lock Type                      3009 non-null   object\n",
      " 8   Type                           4036 non-null   object\n",
      " 9   Model                          3906 non-null   object\n",
      " 10  Number of Blades               3358 non-null   object\n",
      " 11  Country/Region of Manufacture  2564 non-null   object\n",
      " 12  Handle Material                2977 non-null   object\n",
      " 13  Blade Range                    2166 non-null   object\n",
      " 14  Original/Reproduction          2211 non-null   object\n",
      "dtypes: object(15)\n",
      "memory usage: 623.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1285 entries, 0 to 1284\n",
      "Data columns (total 17 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Brand                          1278 non-null   object\n",
      " 1   Blade Material                 842 non-null    object\n",
      " 2   Type                           1065 non-null   object\n",
      " 3   Color                          895 non-null    object\n",
      " 4   Model                          1093 non-null   object\n",
      " 5   Blade Edge                     898 non-null    object\n",
      " 6   Original/Reproduction          632 non-null    object\n",
      " 7   Number of Blades               1003 non-null   object\n",
      " 8   Handle Material                836 non-null    object\n",
      " 9   Blade Type                     751 non-null    object\n",
      " 10  Lock Type                      785 non-null    object\n",
      " 11  Opening Mechanism              914 non-null    object\n",
      " 12  MPN                            501 non-null    object\n",
      " 13  Modified Item                  524 non-null    object\n",
      " 14  Country/Region of Manufacture  480 non-null    object\n",
      " 15  Dexterity                      662 non-null    object\n",
      " 16  Blade Range                    571 non-null    object\n",
      "dtypes: object(17)\n",
      "memory usage: 170.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7218 entries, 0 to 7217\n",
      "Data columns (total 18 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Model                          5651 non-null   object\n",
      " 1   Modified Item                  2556 non-null   object\n",
      " 2   Country/Region of Manufacture  4363 non-null   object\n",
      " 3   Blade Material                 4443 non-null   object\n",
      " 4   Lock Type                      4295 non-null   object\n",
      " 5   Blade Type                     3615 non-null   object\n",
      " 6   Blade Edge                     4702 non-null   object\n",
      " 7   Dexterity                      3644 non-null   object\n",
      " 8   Original/Reproduction          3262 non-null   object\n",
      " 9   Blade Range                    3673 non-null   object\n",
      " 10  Type                           5779 non-null   object\n",
      " 11  Color                          5560 non-null   object\n",
      " 12  Number of Blades               4600 non-null   object\n",
      " 13  Opening Mechanism              4399 non-null   object\n",
      " 14  MPN                            3083 non-null   object\n",
      " 15  Handle Material                5045 non-null   object\n",
      " 16  Brand                          7190 non-null   object\n",
      " 17  Product Line                   2534 non-null   object\n",
      "dtypes: object(18)\n",
      "memory usage: 1015.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4472 entries, 0 to 4471\n",
      "Data columns (total 16 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   Type                           3828 non-null   object\n",
      " 1   Brand                          4448 non-null   object\n",
      " 2   Country/Region of Manufacture  2833 non-null   object\n",
      " 3   Opening Mechanism              2734 non-null   object\n",
      " 4   Blade Material                 2532 non-null   object\n",
      " 5   Color                          3551 non-null   object\n",
      " 6   Model                          3612 non-null   object\n",
      " 7   Blade Edge                     2259 non-null   object\n",
      " 8   Original/Reproduction          1998 non-null   object\n",
      " 9   Handle Material                2831 non-null   object\n",
      " 10  Modified Item                  1627 non-null   object\n",
      " 11  Blade Range                    1682 non-null   object\n",
      " 12  Lock Type                      1619 non-null   object\n",
      " 13  Blade Type                     1856 non-null   object\n",
      " 14  Tools                          2110 non-null   object\n",
      " 15  Number of Blades               2625 non-null   object\n",
      "dtypes: object(16)\n",
      "memory usage: 559.1+ KB\n"
     ]
    }
   ],
   "source": [
    "for dataframe in specs_list:\n",
    "    dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in specs_list:\n",
    "    dataframe.drop('Brand', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_bench = bench_merged.join(bench_spec)\n",
    "tot_buck = buck_merged.join(buck_spec)\n",
    "tot_case = case_merged.join(case_spec)\n",
    "tot_caseXX = caseXX_merged.join(caseXX_spec)\n",
    "tot_crkt = crkt_merged.join(crkt_spec)\n",
    "tot_kershaw = kershaw_merged.join(kershaw_spec)\n",
    "tot_sog = sog_merged.join(sog_spec)\n",
    "tot_spyd = spyd_merged.join(spyd_spec)\n",
    "tot_vict = vict_merged.join(vict_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_bench.to_csv('listed_data/total_list_bench.csv', index=False)\n",
    "tot_buck.to_csv('listed_data/total_list_buck.csv', index=False)\n",
    "tot_case.to_csv('listed_data/total_list_case.csv', index=False)\n",
    "tot_caseXX.to_csv('listed_data/total_list_caseXX.csv', index=False)\n",
    "tot_crkt.to_csv('listed_data/total_list_crkt.csv', index=False)\n",
    "tot_kershaw.to_csv('listed_data/total_list_kershaw.csv', index=False)\n",
    "tot_sog.to_csv('listed_data/total_list_sog.csv', index=False)\n",
    "tot_spyd.to_csv('listed_data/total_list_spyd.csv', index=False)\n",
    "tot_vict.to_csv('listed_data/total_list_vict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.read_csv(\"listed_data/df_bench.csv\")\n",
    "df_buck = pd.read_csv(\"listed_data/df_buck.csv\")\n",
    "df_case = pd.read_csv(\"listed_data/df_case.csv\")\n",
    "df_caseXX = pd.read_csv(\"listed_data/df_CaseXX.csv\")\n",
    "df_crkt = pd.read_csv(\"listed_data/df_crkt.csv\")\n",
    "df_kersh = pd.read_csv(\"listed_data/df_kershaw.csv\")\n",
    "df_sog = pd.read_csv(\"listed_data/df_sog.csv\")\n",
    "df_spyd = pd.read_csv(\"listed_data/df_spyderco.csv\")\n",
    "df_vict = pd.read_csv(\"listed_data/df_victorinox.csv\")\n",
    "\n",
    "\n",
    "\n",
    "bench = pd.read_csv(\"listed_data/benchIds.csv\")\n",
    "buck = pd.read_csv(\"listed_data/buckIds.csv\")\n",
    "case = pd.read_csv(\"listed_data/caseIds.csv\")\n",
    "caseXX = pd.read_csv(\"listed_data/caseXXIds.csv\")\n",
    "crkt = pd.read_csv(\"listed_data/crktIds.csv\")\n",
    "kershaw = pd.read_csv(\"listed_data/kershawIds.csv\")\n",
    "sog = pd.read_csv(\"listed_data/sogIds.csv\")\n",
    "spyd = pd.read_csv(\"listed_data/spydIds.csv\")\n",
    "vict = pd.read_csv(\"listed_data/victIds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_df = pd.concat([df_bench,df_buck,\n",
    "                       df_case,df_caseXX,\n",
    "                       df_crkt,df_kersh,\n",
    "                       df_sog,df_spyd,\n",
    "                       df_vict])\n",
    "\n",
    "listed_df.drop('galleryPlusPictureURL', axis=1, inplace=True)\n",
    "\n",
    "Ids_df = pd.concat([bench,buck,\n",
    "                   case,caseXX,\n",
    "                   crkt,kershaw,\n",
    "                   sog,spyd,vict])\n",
    "\n",
    "\n",
    "\n",
    "Ids_df.rename({'Title': 'title',\n",
    "               'ItemID': 'itemId'},\n",
    "               axis=1,inplace=True)\n",
    "    \n",
    "Ids_df.drop(['ConditionID','ConvertedCurrentPrice'], \n",
    "             axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ids_df['title'] = Ids_df['title'].str.lower()\n",
    "\n",
    "\n",
    "df_merged = listed_df.merge(Ids_df)\n",
    "\n",
    "df_spec = transform_item_specifics(df_merged, perc=65.0)\n",
    "\n",
    "df_spec.drop('Brand', axis=1, inplace=True)\n",
    "\n",
    "tot_listed_df = df_merged.join(df_spec)\n",
    "\n",
    "listed_knives = data_cleaner(tot_listed_df).copy()\n",
    "listed_knives.drop(['sellingStatus', 'shippingInfo', \n",
    "                    'GalleryURL', 'ItemSpecifics', \n",
    "                    'item_list', 'listingInfo'], \n",
    "                    axis=1, inplace=True)\n",
    "listed_used_knives = listed_knives.loc[listed_knives['condition'] != 1000.0]\n",
    "listed_used_knives.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11855 entries, 0 to 11854\n",
      "Data columns (total 35 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   itemId                         11855 non-null  int64  \n",
      " 1   title                          11855 non-null  object \n",
      " 2   galleryURL                     11854 non-null  object \n",
      " 3   viewItemURL                    11855 non-null  object \n",
      " 4   autoPay                        11855 non-null  bool   \n",
      " 5   postalCode                     11576 non-null  object \n",
      " 6   returnsAccepted                11855 non-null  bool   \n",
      " 7   condition                      11854 non-null  float64\n",
      " 8   topRatedListing                11855 non-null  bool   \n",
      " 9   pictureURLLarge                11208 non-null  object \n",
      " 10  pictureURLSuperSize            11159 non-null  object \n",
      " 11  shipping_cost                  11855 non-null  float64\n",
      " 12  price_in_US                    11855 non-null  float64\n",
      " 13  converted_price                11855 non-null  float64\n",
      " 14  brand                          11855 non-null  object \n",
      " 15  cost                           11855 non-null  float64\n",
      " 16  profit                         11855 non-null  float64\n",
      " 17  ROI                            11855 non-null  float64\n",
      " 18  PictureURL                     11854 non-null  object \n",
      " 19  Location                       11854 non-null  object \n",
      " 20  Country                        11855 non-null  object \n",
      " 21  Blade Material                 6625 non-null   object \n",
      " 22  Model                          9373 non-null   object \n",
      " 23  Opening Mechanism              7100 non-null   object \n",
      " 24  Number of Blades               7865 non-null   object \n",
      " 25  Handle Material                7529 non-null   object \n",
      " 26  Blade Type                     5336 non-null   object \n",
      " 27  Color                          8262 non-null   object \n",
      " 28  Type                           9147 non-null   object \n",
      " 29  Country/Region of Manufacture  6568 non-null   object \n",
      " 30  Lock Type                      5482 non-null   object \n",
      " 31  Blade Edge                     6155 non-null   object \n",
      " 32  Dexterity                      4383 non-null   object \n",
      " 33  Original/Reproduction          4879 non-null   object \n",
      " 34  Blade Range                    4403 non-null   object \n",
      "dtypes: bool(3), float64(7), int64(1), object(24)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "listed_used_knives.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_knives.drop(['Original/Reproduction'],\n",
    "                    axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_knives.to_csv(\"listed_data/listed_knives_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of section for obtaining listed data from eBay APIs. Below is the start of processing scraped data from eBay's seller exclusive website. This data goes back 2 years and is filtered to include only used knives with final sale values. The listed data above only goes back 90 days and only shows listings currently up for sale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_bench = pd.read_csv(\"terapeak_data/bench_scraped2.csv\")\n",
    "sold_buck1 = pd.read_csv(\"terapeak_data/buck_scraped2.csv\")\n",
    "sold_buck2 = pd.read_csv(\"terapeak_data/buck_scraped2_reversed.csv\")\n",
    "sold_case = pd.read_csv(\"terapeak_data/case_scraped2.csv\")\n",
    "sold_caseXX1 = pd.read_csv(\"terapeak_data/caseXX_scraped2.csv\")\n",
    "sold_caseXX2 = pd.read_csv(\"terapeak_data/caseXX2_reversed.csv\")\n",
    "sold_crkt = pd.read_csv(\"terapeak_data/crkt_scraped.csv\")\n",
    "sold_kershaw1 = pd.read_csv(\"terapeak_data/kershaw_scraped2.csv\")\n",
    "sold_kershaw2 = pd.read_csv(\"terapeak_data/kershaw_scraped2_reversed.csv\")\n",
    "sold_sog = pd.read_csv(\"terapeak_data/SOG_scraped2.csv\")\n",
    "sold_spyd = pd.read_csv(\"terapeak_data/spyd_scraped2.csv\")\n",
    "sold_vict1 = pd.read_csv(\"terapeak_data/vict_scraped.csv\")\n",
    "sold_vict2 = pd.read_csv(\"terapeak_data/vict_reversed.csv\")\n",
    "\n",
    "sold_list = [sold_bench,sold_buck1,\n",
    "             sold_buck2,sold_case,\n",
    "             sold_caseXX1,sold_caseXX2,\n",
    "             sold_crkt,sold_kershaw1,\n",
    "             sold_kershaw2,sold_sog, \n",
    "             sold_spyd, sold_vict1,\n",
    "             sold_vict2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmade\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8791 entries, 0 to 8790\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        8791 non-null   object\n",
      " 1   url          1843 non-null   object\n",
      " 2   date_sold    8791 non-null   object\n",
      " 3   price_in_US  8791 non-null   object\n",
      " 4   shipping_    8791 non-null   object\n",
      " 5   Text         8791 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 412.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buck1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        9999 non-null   object\n",
      " 1   url          3659 non-null   object\n",
      " 2   date_sold    9999 non-null   object\n",
      " 3   price_in_US  9999 non-null   object\n",
      " 4   shipping_    9999 non-null   object\n",
      " 5   Text         9999 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 468.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buck2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8918 entries, 0 to 8917\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        8918 non-null   object\n",
      " 1   url          4 non-null      object\n",
      " 2   date_sold    8918 non-null   object\n",
      " 3   price_in_US  8918 non-null   object\n",
      " 4   shipping_    8918 non-null   object\n",
      " 5   Text         8918 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 418.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        9999 non-null   object\n",
      " 1   url          2198 non-null   object\n",
      " 2   date_sold    9999 non-null   object\n",
      " 3   price_in_US  9999 non-null   object\n",
      " 4   shipping_    9999 non-null   object\n",
      " 5   Text         9999 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 468.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseXX1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        9999 non-null   object\n",
      " 1   url          3309 non-null   object\n",
      " 2   date_sold    9999 non-null   object\n",
      " 3   price_in_US  9999 non-null   object\n",
      " 4   shipping_    9999 non-null   object\n",
      " 5   Text         9999 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 468.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseXX2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8494 entries, 0 to 8493\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        8494 non-null   object\n",
      " 1   url          10 non-null     object\n",
      " 2   date_sold    8494 non-null   object\n",
      " 3   price_in_US  8494 non-null   object\n",
      " 4   shipping_    8494 non-null   object\n",
      " 5   Text         8494 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 398.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crkt\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6742 entries, 0 to 6741\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        6742 non-null   object\n",
      " 1   url          1272 non-null   object\n",
      " 2   date_sold    6742 non-null   object\n",
      " 3   price_in_US  6742 non-null   object\n",
      " 4   shipping_    6742 non-null   object\n",
      " 5   Text         6742 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 316.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kershaw1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        10000 non-null  object\n",
      " 1   url          3370 non-null   object\n",
      " 2   date_sold    10000 non-null  object\n",
      " 3   price_in_US  10000 non-null  object\n",
      " 4   shipping_    10000 non-null  object\n",
      " 5   Text         10000 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 468.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kershaw2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9447 entries, 0 to 9446\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        9447 non-null   object\n",
      " 1   url          11 non-null     object\n",
      " 2   date_sold    9447 non-null   object\n",
      " 3   price_in_US  9447 non-null   object\n",
      " 4   shipping_    9447 non-null   object\n",
      " 5   Text         9447 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 443.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sog\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4858 entries, 0 to 4857\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        4858 non-null   object\n",
      " 1   url          900 non-null    object\n",
      " 2   date_sold    4858 non-null   object\n",
      " 3   price_in_US  4858 non-null   object\n",
      " 4   shipping_    4858 non-null   object\n",
      " 5   Text         4858 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 227.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spyderco\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9206 entries, 0 to 9205\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        9206 non-null   object\n",
      " 1   url          1936 non-null   object\n",
      " 2   date_sold    9206 non-null   object\n",
      " 3   price_in_US  9206 non-null   object\n",
      " 4   shipping_    9206 non-null   object\n",
      " 5   Text         9206 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 431.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7799 entries, 0 to 7798\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        7799 non-null   object\n",
      " 1   url          6115 non-null   object\n",
      " 2   date_sold    7799 non-null   object\n",
      " 3   price_in_US  7799 non-null   object\n",
      " 4   shipping_    7799 non-null   object\n",
      " 5   Text         7799 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 365.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7068 entries, 0 to 7067\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Image        7068 non-null   object\n",
      " 1   url          20 non-null     object\n",
      " 2   date_sold    7068 non-null   object\n",
      " 3   price_in_US  7068 non-null   object\n",
      " 4   shipping_    7068 non-null   object\n",
      " 5   Text         7068 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 331.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dict = {'benchmade': sold_bench, \n",
    "           'buck1': sold_buck1,\n",
    "           'buck2': sold_buck2,\n",
    "           'case':sold_case,\n",
    "           'caseXX1':sold_caseXX1,\n",
    "           'caseXX2':sold_caseXX2,\n",
    "           'crkt':sold_crkt,\n",
    "           'kershaw1':sold_kershaw1,\n",
    "           'kershaw2':sold_kershaw2,\n",
    "           'sog':sold_sog, \n",
    "           'spyderco':sold_spyd,\n",
    "           'vict1':sold_vict1,\n",
    "           'vict2':sold_vict2}\n",
    "          \n",
    "\n",
    "for key,val in df_dict.items():\n",
    "    print(key)\n",
    "    display(val.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['title'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a3cd799ef523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['title'] not found in axis\""
     ]
    }
   ],
   "source": [
    "for val in df_dict.values():\n",
    "    val.drop('title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df_dict.values():\n",
    "    val.rename({'Text': 'title',\n",
    "                'shipping_': 'shipping_cost'},\n",
    "               axis=1, inplace=True)\n",
    "\n",
    "    val['date_sold'] = pd.to_datetime(val['date_sold'])\n",
    "\n",
    "sold_buck = pd.concat([sold_buck1,sold_buck2])\n",
    "sold_caseXX = pd.concat([sold_caseXX1,sold_caseXX2])\n",
    "sold_kershaw = pd.concat([sold_kershaw1,sold_kershaw2])\n",
    "sold_vict = pd.concat([sold_vict1,sold_vict2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmade\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buck1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buck2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseXX1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caseXX2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crkt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kershaw1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kershaw2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spyderco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'url', 'date_sold', 'price_in_US', 'shipping_cost', 'title'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key,val in df_dict.items():\n",
    "    print(key)\n",
    "    display(val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sold_buck.drop_duplicates(\n",
    "#     subset = ['date_sold', 'price_in_US', 'shipping_cost'],\n",
    "#     keep = 'last', inplace=True)\n",
    "\n",
    "# sold_caseXX.drop_duplicates(\n",
    "#     subset = ['date_sold', 'price_in_US', 'shipping_cost'],\n",
    "#     keep = 'last', inplace=True)\n",
    "\n",
    "# sold_kershaw.drop_duplicates(\n",
    "#     subset = ['date_sold', 'price_in_US', 'shipping_cost'],\n",
    "#     keep = 'last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_bench = prepare_tera_df(sold_bench, 0)\n",
    "sold_buck = prepare_tera_df(sold_buck, 1)\n",
    "sold_case = prepare_tera_df(sold_case, 2)\n",
    "sold_caseXX = prepare_tera_df(sold_caseXX, 2)\n",
    "sold_crkt = prepare_tera_df(sold_crkt, 3)\n",
    "sold_kershaw = prepare_tera_df(sold_kershaw, 4)\n",
    "sold_sog = prepare_tera_df(sold_sog, 5)\n",
    "sold_spyd = prepare_tera_df(sold_spyd, 6)\n",
    "sold_vict = prepare_tera_df(sold_vict, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in df_dict.values():\n",
    "    dataframe['title'] = dataframe['title'].str.lower()\n",
    "    dataframe['title'] = dataframe['title'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case          28492\n",
       "kershaw       19447\n",
       "buck          18917\n",
       "victorinox    14867\n",
       "spyderco       9206\n",
       "benchmade      8791\n",
       "crkt           6742\n",
       "sog            4858\n",
       "Name: brand, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sold_df = pd.concat([sold_bench, sold_buck,\n",
    "                     sold_case, sold_caseXX, \n",
    "                     sold_crkt, sold_kershaw,\n",
    "                     sold_sog, sold_spyd,\n",
    "                     sold_vict]) \n",
    "\n",
    "sold_df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_df.to_csv(\"terapeak_data/terapeak_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_knives = data_cleaner(sold_df).copy()\n",
    "sold_knives.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case          18918\n",
       "kershaw       12957\n",
       "buck          12534\n",
       "victorinox     9437\n",
       "spyderco       6046\n",
       "benchmade      5712\n",
       "crkt           4276\n",
       "sog            3006\n",
       "Name: brand, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sold_knives.brand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72886 entries, 0 to 72885\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Image            72886 non-null  object        \n",
      " 1   url              15070 non-null  object        \n",
      " 2   date_sold        72886 non-null  datetime64[ns]\n",
      " 3   price_in_US      72886 non-null  float64       \n",
      " 4   shipping_cost    72886 non-null  float64       \n",
      " 5   title            72886 non-null  object        \n",
      " 6   converted_price  72886 non-null  float64       \n",
      " 7   profit           72886 non-null  float64       \n",
      " 8   ROI              72886 non-null  float64       \n",
      " 9   brand            72886 non-null  object        \n",
      " 10  cost             72886 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), object(4)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "sold_knives.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sold_bench.to_csv(\"terapeak_data/tera_bench_prepared.csv\", index=False)\n",
    "# sold_buck.to_csv(\"terapeak_data/tera_buck_prepared.csv\", index=False)\n",
    "# sold_case.to_csv(\"terapeak_data/tera_case_prepared.csv\", index=False)\n",
    "# sold_caseXX.to_csv(\"terapeak_data/tera_caseXX_prepared.csv\", index=False)\n",
    "# sold_crkt.to_csv(\"terapeak_data/tera_crkt_prepared.csv\", index=False)\n",
    "# sold_kershaw.to_csv(\"terapeak_data/tera_kershaw_prepared.csv\", index=False)\n",
    "# sold_sog.to_csv(\"terapeak_data/tera_sog_prepared.csv\", index=False)\n",
    "# sold_spyd.to_csv(\"terapeak_data/tera_spyd_prepared.csv\", index=False)\n",
    "sold_knives.to_csv(\"terapeak_data/sold_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below block of code merged all available teraform ebay itemIds with the appropriate data. This was done in order to call the ebay Shopping API that will only accept itemIds as input. However, much of the data is older than 90 days and can no longer be accessed using the ebay Shopping API. Therefore, the teraform data will unfortunatly lack additional item specific data.  \n",
    "\n",
    "```\n",
    "teradf_benchIDs = pd.read_csv(\"teraform_data/tera_benchmade_itemID.csv\")\n",
    "teradf_buckIDs = pd.read_csv(\"teraform_data/tera_buck_ItemIDs.csv\")\n",
    "teradf_caseIDs = pd.read_csv(\"teraform_data/tera_case_itemIDs.csv\")\n",
    "teradf_kershawIDs = pd.read_csv(\"teraform_data/tera_kershaw_ItemIDs.csv\")\n",
    "teradf_sogIDs = pd.read_csv(\"teraform_data/tera_sog_ItemIDs.csv\")\n",
    "teradf_spydIDs = pd.read_csv(\"teraform_data/tera_spyderco_ItemIDs.csv\")\n",
    "\n",
    "dfID_list = [teradf_benchIDs,teradf_buckIDs,\n",
    "             teradf_caseIDs, teradf_kershawIDs,\n",
    "             teradf_sogIDs, teradf_spydIDs]\n",
    "\n",
    "for dataframe in dfID_list:\n",
    "    dataframe.rename({'Field4': 'date_sold',\n",
    "                      'Data_field': 'itemID',\n",
    "                      'Title': 'title'}, \n",
    "                       axis=1, inplace=True)\n",
    "    \n",
    "teradf_kershawIDs.rename({'item': 'title'}, \n",
    "                       axis=1, inplace=True)\n",
    "                       \n",
    "for dataframe in dfID_list:\n",
    "    dataframe.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "for dataframe in dfID_list:\n",
    "    dataframe.rename({'Field4': 'date_sold',\n",
    "                      'Data_field': 'itemID',\n",
    "                      'Title': 'title'}, \n",
    "                       axis=1, inplace=True)\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe['itemID'] = dataframe['itemID'].apply(int)\n",
    "\n",
    "teradf_kershawIDs.rename({'item': 'title'}, \n",
    "                       axis=1, inplace=True)\n",
    "\n",
    "tera_benchIds = teradf_benchIDs.itemID.values.tolist()\n",
    "tera_buckIds = teradf_buckIDs.itemID.values.tolist()\n",
    "tera_caseIds = teradf_caseIDs.itemID.values.tolist()\n",
    "tera_kershawIds = teradf_kershawIDs.itemID.values.tolist()\n",
    "tera_sogIds = teradf_sogIDs.itemID.values.tolist()\n",
    "tera_spydIds = teradf_spydIDs.itemID.values.tolist()\n",
    "\n",
    "idMerge_bench = teradf_bench.merge(teradf_benchIDs, on='Image')\n",
    "idMerge_buck = teradf_buck.merge(teradf_buckIDs)\n",
    "idMerge_case = teradf_case.merge(teradf_caseIDs)\n",
    "idMerge_kershaw = teradf_kershaw.merge(teradf_kershawIDs)\n",
    "idMerge_spyd = teradf_spyd.merge(teradf_spydIDs)\n",
    "idMerge_sog = teradf_sog.merge(teradf_sogIDs)\n",
    "\n",
    "# idMerge_bench.to_csv('teraform_data/tera_bench_idMerge.csv', index=False)\n",
    "# idMerge_buck.to_csv('teraform_data/tera_buck_idMerge.csv', index=False)\n",
    "# idMerge_case.to_csv('teraform_data/tera_case_idMerge.csv', index=False)\n",
    "# idMerge_kershaw.to_csv('teraform_data/tera_kershaw_idMerge.csv', index=False)\n",
    "# idMerge_spyd.to_csv('teraform_data/tera_spyd_idMerge.csv', index=False)\n",
    "# idMerge_sog.to_csv('teraform_data/tera_sog_idMerge.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#Create row for converted Price of Knives in US dollars\n",
    "price_list = []\n",
    "for row in full_dataset:\n",
    "    listed_price = np.float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "    price_list.append(listed_price)\n",
    "    \n",
    "df['price_in_US'] = price_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#atttempt to pull shipping cost from json dict\n",
    "shipping_cost_list = []\n",
    "for row in full_dataset:\n",
    "    shipping_cost = np.float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "    shipping_cost_list.append(shipping_cost)\n",
    "    \n",
    "df['shipping_price'] = shipping_cost_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#pull shipping cost from json dict with regex \n",
    "df['shipping_cost'] = df['shippingInfo'].apply(lambda x: re.findall(\"(\\d+\\S+\\d)\", json.dumps(x)))\n",
    "df['shipping_cost'] = df['shipping_cost'].apply(lambda x: ''.join(x))\n",
    "df.drop(df[df['shipping_cost'] == ''].index, inplace=True)\n",
    "df['shipping_cost'] = df['shipping_cost'].apply(lambda x: np.float(x))\n",
    "\n",
    "#create new feature 'converted price'\n",
    "df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "df = df.drop_duplicates(subset=['title', 'galleryURL'], keep='first')\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "\n",
    "df.to_csv('data/full_dataset.csv', index=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
