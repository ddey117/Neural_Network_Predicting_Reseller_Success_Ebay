{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebaysdk.finding import Connection\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebaysdk.shopping import Connection as Shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import  json\n",
    "import numpy as np\n",
    "import re\n",
    "# import preprocess_ddey117 as pp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import ast\n",
    "\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create function for organizing API call\n",
    "# def prepare_data(data_list):\n",
    "#     \"\"\"\n",
    "#     This function takes in a list of dictionaries and prepares it\n",
    "#     for analysis\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Make a new list to hold results\n",
    "#     results = []\n",
    "    \n",
    "#     for business_data in data_list:\n",
    "    \n",
    "#         # Make a new dictionary to hold prepared data for this business\n",
    "#         prepared_data = {}\n",
    "        \n",
    "#         # Extract name, review_count, rating, and price key-value pairs\n",
    "#         # from business_data and add to prepared_data\n",
    "#         # If a key is not present in business_data, add it to prepared_data\n",
    "#         # with an associated value of None\n",
    "        \n",
    "#         keys = ['itemId', 'title', 'galleryURL', \n",
    "#         'viewItemURL', 'autoPay', 'postalCode', \n",
    "#         'sellingStatus', 'shippingInfo', 'listingInfo',\n",
    "#         'returnsAccepted', 'condition', 'topRatedListing',\n",
    "#         'galleryPlusPictureURL']\n",
    "        \n",
    "#         for key in keys:\n",
    "#             prepared_data[key] = business_data.get(key, None)\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "#         # Add to list if all values are present\n",
    "# #         if all(prepared_data.values()):\n",
    "# #             results.append(prepared_data)\n",
    "    \n",
    "    \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_df(df):\n",
    "#     price_list = []\n",
    "#     for row in full_dataset:\n",
    "#         listed_price = np.float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "#         price_list.append(listed_price)\n",
    "\n",
    "#     df['price_in_US'] = price_list\n",
    "#     #pull shipping cost from json dict with regex \n",
    "#     df['shipping_cost'] = df['shippingInfo'].apply(lambda x: re.findall(\"(\\d+\\S+\\d)\", json.dumps(x)))\n",
    "#     df['shipping_cost'] = df['shipping_cost'].apply(lambda x: ''.join(x))\n",
    "#     df.drop(df[df['shipping_cost'] == ''].index, inplace=True)\n",
    "#     df['shipping_cost'] = df['shipping_cost'].apply(lambda x: np.float(x))\n",
    "\n",
    "#     #create new feature 'converted price'\n",
    "#     df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "#     df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "#     display(df.head())\n",
    "#     display(df.info())\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    price_list = []\n",
    "    ship_price_list = []\n",
    "    condition_list = []\n",
    "    condition = None\n",
    "    for row in full_dataset:\n",
    "        listed_price = float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "        price_list.append(listed_price)\n",
    "     \n",
    "        try:\n",
    "            listed_ship_price = float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "            ship_price_list.append(listed_ship_price)\n",
    "        except: \n",
    "            listed_ship_price = 0\n",
    "            ship_price_list.append(listed_ship_price)\n",
    "\n",
    "        try:\n",
    "            condition = float(row['condition']['conditionId'])\n",
    "            condition_list.append(condition)\n",
    "        except: \n",
    "            conditon = 0\n",
    "            condition_list.append(condition)\n",
    "\n",
    "    df['shipping_cost'] = ship_price_list\n",
    "    df['price_in_US'] = price_list\n",
    "    df['condition'] = condition_list\n",
    "    \n",
    "    #create new feature 'converted price'\n",
    "    df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "    df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "bucket_dict = {'benchmade': 45.0,\n",
    "               'buck': 20.0,\n",
    "               'case': 20.0,\n",
    "               'crkt': 15.0,\n",
    "               'kershaw': 15.0,\n",
    "               'leatherman': 30.0,\n",
    "               'sog': 15.0,\n",
    "               'spyderco': 30.0,\n",
    "               'victorinox': 20.0\n",
    "              }\n",
    "\n",
    "overhead_cost = 3\n",
    "def prepare_brands(df, bucket_dict_position):\n",
    "\n",
    "    df.title = df.title.apply(str.lower)\n",
    " \n",
    "    #remove special characters\n",
    "#     df.title.apply(pp.remove_special_chars)\n",
    "    df['brand'] = str(list(bucket_dict.keys())[bucket_dict_position])\n",
    "    df['cost'] = float(list(bucket_dict.values())[bucket_dict_position])\n",
    "    df['profit'] = (df['converted_price'] -  df['cost'] - overhead_cost)\n",
    "    df['ROI'] = (df['profit']/( df['cost'] + overhead_cost))*100.0\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_data(data_list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of dictionaries and prepares it\n",
    "    for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a new list to hold results\n",
    "    results = []\n",
    "    \n",
    "    for business_data in data_list:\n",
    "    \n",
    "        # Make a new dictionary to hold prepared data for this business\n",
    "        prepared_data = {}\n",
    "        \n",
    "        # Extract name, review_count, rating, and price key-value pairs\n",
    "        # from business_data and add to prepared_data\n",
    "        # If a key is not present in business_data, add it to prepared_data\n",
    "        # with an associated value of None\n",
    "        \n",
    "        keys = ['itemId', 'title', 'galleryURL', \n",
    "                'viewItemURL', 'autoPay', 'postalCode', \n",
    "                'sellingStatus', 'shippingInfo', 'listingInfo',\n",
    "                'returnsAccepted', 'condition', 'topRatedListing',\n",
    "                'galleryPlusPictureURL','pictureURLLarge', \n",
    "                'pictureURLSuperSize']\n",
    "        \n",
    "        for key in keys:\n",
    "            prepared_data[key] = business_data.get(key, None)\n",
    "            results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "        # Add to list if all values are present\n",
    "#         if all(prepared_data.values()):\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "    \n",
    "    return results\n",
    "\n",
    "def knife_request(Brand, dict_pos):\n",
    "    api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "    request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': 1\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "    #     request['paginationInput']['pageNumber'] = page\n",
    "\n",
    "    response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "\n",
    "    response_pages = response.dict()\n",
    "\n",
    "    full_dataset = []\n",
    "    \n",
    "    total_pages = int(response_pages['paginationOutput']['totalPages'])\n",
    "\n",
    "    if total_pages > 100:\n",
    "        pages_to_request = 100\n",
    "        \n",
    "    else:\n",
    "        pages_to_request = total_pages - 1\n",
    "        \n",
    "        \n",
    "\n",
    "    for page in range(1, pages_to_request):\n",
    "        # Add or update the \"offset\" key-value pair in url_params\n",
    "\n",
    "        # Make the query and get the response\n",
    "\n",
    "        api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "        request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': page\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "\n",
    "        response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "        #save the response as a json dict\n",
    "        response_dict = response.dict()\n",
    "\n",
    "\n",
    "        #index dict to appropriate index\n",
    "        results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "        # Call the prepare_data function to get a list of processed data\n",
    "        prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "        # Extend full_dataset with this list (don't append, or you'll get\n",
    "        # a list of lists instead of a flat list)\n",
    "        full_dataset.extend(prepared_knives)\n",
    "\n",
    "    # Check the length of the full dataset. It will be up to `total`,\n",
    "    # potentially less if there were missing values\n",
    "    display(len(full_dataset))\n",
    "    \n",
    "    df = pd.DataFrame(full_dataset)\n",
    "    \n",
    "    price_list = []\n",
    "    ship_price_list = []\n",
    "    condition_list = []\n",
    "    condition = None\n",
    "    for row in full_dataset:\n",
    "        try:\n",
    "            listed_price = float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "            price_list.append(listed_price)\n",
    "        except:\n",
    "            listed_price = \"Na\"\n",
    "            price_list.append(listed_price)\n",
    "        try:\n",
    "            listed_ship_price = float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "            ship_price_list.append(listed_ship_price)\n",
    "        except: \n",
    "            listed_ship_price = 0\n",
    "            ship_price_list.append(listed_ship_price)\n",
    "        try:\n",
    "            condition = float(row['condition']['conditionId'])\n",
    "            condition_list.append(condition)\n",
    "        except: \n",
    "            conditon = 0\n",
    "            condition_list.append(condition)\n",
    "\n",
    "    df['shipping_cost'] = ship_price_list\n",
    "    df['price_in_US'] = price_list\n",
    "    df['condition'] = condition_list\n",
    "    \n",
    "    #create new feature 'converted price'\n",
    "    df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "    df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df = prepare_brands(df, dict_pos)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_dataIds(data_list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of dictionaries and prepares it\n",
    "    for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a new list to hold results\n",
    "    results = []\n",
    "    \n",
    "    for business_data in data_list:\n",
    "    \n",
    "        # Make a new dictionary to hold prepared data for this business\n",
    "        prepared_data = {}\n",
    "        \n",
    "        # Extract name, review_count, rating, and price key-value pairs\n",
    "        # from business_data and add to prepared_data\n",
    "        # If a key is not present in business_data, add it to prepared_data\n",
    "        # with an associated value of None\n",
    "        \n",
    "        keys = ['ItemID','GalleryURL','PictureURL',\n",
    "                'Location','ConvertedCurrentPrice',\n",
    "                'Title','ItemSpecifics', \n",
    "                'Country','ConditionID']\n",
    "        \n",
    "        for key in keys:\n",
    "            prepared_data[key] = business_data.get(key, None)\n",
    "            results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "        # Add to list if all values are present\n",
    "#         if all(prepared_data.values()):\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_list(my_list):\n",
    " \n",
    "    api = Shopping(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "    request = {\n",
    "               'itemID': my_list,\n",
    "               'IncludeSelector': 'ItemSpecifics'\n",
    "              }\n",
    "    response = api.execute('GetMultipleItems', request)\n",
    "\n",
    "    \n",
    "\n",
    "    #save the response as a json dict\n",
    "    response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "    #index dict to appropriate index\n",
    "    results_list_of_dicts = response_dict['Item']\n",
    "\n",
    "    # Call the prepare_data function to get a list of processed data\n",
    "    prepared_knives = prepare_dataIds(results_list_of_dicts)\n",
    "\n",
    "    # Extend full_dataset with this list (don't append, or you'll get\n",
    "    # a list of lists instead of a flat list)\n",
    "    full_dataset.extend(prepared_knives)\n",
    "    \n",
    "    return full_dataset\n",
    "\n",
    "bucket_dict = {'benchmade': 45.0,\n",
    "               'buck': 20.0,\n",
    "               'case': 20.0,\n",
    "               'crkt': 15.0,\n",
    "               'kershaw': 15.0,\n",
    "               'leatherman': 30.0, \n",
    "               'sog': 15.0,\n",
    "               'spyderco': 30.0,\n",
    "               'victorinox': 20.0\n",
    "              }\n",
    "\n",
    "#x = position of bucket_dictionary\n",
    "def prepare_tera_df(df, x):\n",
    "    df['price_in_US'] = df['price_in_US'].str.replace(\"$\", \"\")\n",
    "    df['price_in_US'] = df['price_in_US'].str.replace(\",\", \"\")\n",
    "    df['price_in_US'] = df['price_in_US'].apply(float)\n",
    "    \n",
    "    df['shipping_cost'] = df['shipping_cost'].str.replace(\"$\", \"\")\n",
    "    df['shipping_cost'] = df['shipping_cost'].str.replace(\",\", \"\")\n",
    "    df['shipping_cost'] = df['shipping_cost'].apply(float)\n",
    "    \n",
    "    df['converted_price'] = (df['price_in_US'] + df['shipping_cost'])\n",
    "    \n",
    "    df['profit'] = (df['converted_price'] - list(bucket_dict.values())[x])\n",
    "    df['ROI'] = (df['profit']/(list(bucket_dict.values())[x]))*100.0\n",
    "    \n",
    "    df['brand'] = list(bucket_dict.keys())[x]\n",
    "    df['cost'] = list(bucket_dict.values())[x]\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fix(col):\n",
    "    dd = dict()\n",
    "    for d in col:\n",
    "        values = list(d.values())\n",
    "        if len(values) == 2:\n",
    "            dd[values[0]] = values[1]\n",
    "    return dd\n",
    "\n",
    "\n",
    "def transform_item_specifics(df, perc=90.0):\n",
    "\n",
    "    df.dropna(subset=['ItemSpecifics'], inplace=True)\n",
    "    df['ItemSpecifics'] = df['ItemSpecifics'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['item_list'] = df['ItemSpecifics'].apply(lambda x: x['NameValueList'])\n",
    "\n",
    "    df['ItemSpecifics'] = df['ItemSpecifics'].apply(lambda x: [x['NameValueList']] if isinstance(x['NameValueList'], dict) else x['NameValueList'])\n",
    "\n",
    "    df['ItemSpecifics'] = df['ItemSpecifics'].apply(fix)\n",
    "\n",
    "    df = pd.json_normalize(df['ItemSpecifics'])\n",
    "\n",
    "    min_count =  int(((100-perc)/100)*df.shape[0] + 1)\n",
    "    mod_df = df.dropna(axis=1, \n",
    "                       thresh=min_count)\n",
    "\n",
    "    return mod_df\n",
    "\n",
    "\n",
    "def data_cleaner(df):\n",
    "    lot = re.compile('(?<!-\\S)lot(?![^\\s.,:?!])')\n",
    "    disp = re.compile('(display)')\n",
    "    box = re.compile('(box)')\n",
    "    group = re.compile('(group)')\n",
    "    is_set = re.compile('(?<!-\\S)set(?![^\\s.,?!])')\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    trim_list = [lot,disp,box,group,is_set]\n",
    "    for item in trim_list:\n",
    "        df.loc[df['title'].apply(lambda x: re.search(item, x)).notnull(), 'trim'] = 1 \n",
    "    to_drop = df.loc[df['trim'] == 1].index\n",
    "    df.drop(to_drop, inplace=True)\n",
    "    df.drop('trim', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning of API calls for listed data. To be merged with item specific data using ebay itemIds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Understading: Cost Breakdown\n",
    "- padded envelopes: \\$0.50 per knife\n",
    "- flatrate shipping: \\$4.45 per knife\n",
    "- brand knife at surplus store: 15, 20, 30, or 45 dollars per knife\n",
    "- overhead expenses (gas, cleaning suplies, sharpening supplies, etc): $7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running functions to call the Finding API and return datasets for cat () knives for sale listed on ebay in the last 90 days. (explain how ebay rules work)\n",
    "\n",
    "```\n",
    "bench_df = knife_request('Benchmade', 0)\n",
    "buck_df = knife_request('Buck', 1)\n",
    "case_df = knife_request('Case', 2)\n",
    "df_caseXX = knife_request('Case XX', 2)\n",
    "df_crkt = knife_request(\"CRKT\", 3)\n",
    "df_leatherman = knife_request('Leatherman', 5)\n",
    "df_sog = knife_request('SOG', 6)\n",
    "df_spyderco = knife_request('Spyderco', 7)\n",
    "\n",
    "\n",
    "bench_df.to_csv('data/df_bench1.csv', index=False)\n",
    "buck_df.to_csv('data/df_buck.csv', index=False)\n",
    "case_df.to_csv('data/df_case.csv', index=False)\n",
    "df_caseXX.to_csv('data/df_CaseXX.csv', index=False)\n",
    "df_crkt.to_csv('data/df_crkt.csv', index=False)\n",
    "df_leatherman.to_csv('data/df_leatherman.csv', index=False)\n",
    "df_sog.to_csv('data/df_sog.csv', index=False)\n",
    "df_spyderco.to_csv('data/df_spyderco.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kershaw and victorinox data was requested using the FindingAPI below after tweaking some pagination through trial and error to maximize data.\n",
    "\n",
    "```\n",
    "full_dataset = []\n",
    "for page in range(1, 57):\n",
    "#         # Add or update the \"offset\" key-value pair in url_params\n",
    "\n",
    "#         # Make the query and get the response\n",
    "\n",
    "    api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "    request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': 'Kershaw'}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': page\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "        #     request['paginationInput']['pageNumber'] = page\n",
    "\n",
    "    response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "    #save the response as a json dict\n",
    "    response_dict = response.dict()\n",
    "\n",
    "    #index dict to appropriate index\n",
    "    results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "    # Call the prepare_data function to get a list of processed data\n",
    "    prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "    # Extend full_dataset with this list (don't append, or you'll get\n",
    "    # a list of lists instead of a flat list)\n",
    "    full_dataset.extend(prepared_knives)\n",
    "\n",
    "    # Check the length of the full dataset. It will be up to `total`,\n",
    "    # potentially less if there were missing values\n",
    "\n",
    "    df = pd.DataFrame(full_dataset)\n",
    "    \n",
    "df_kershaw = prepare_df(df)\n",
    "df_kershaw = prepare_brands(df_kershaw, 4)\n",
    "df_kershaw.to_csv('data/df_kershaw.csv', index=False)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "full_dataset = []\n",
    "for page in range(1, 86):\n",
    "\n",
    "    api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "    request = {\n",
    "                'categoryId': 48818,\n",
    "                'itemFilter': [\n",
    "                                {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "                              ],\n",
    "                'aspectFilter': [\n",
    "                                  {'aspectName': 'Brand', 'aspectValueName': 'Victorinox'}],\n",
    "\n",
    "                'outputSelector': ['PictureURLLarge', 'PictureURLSuperSize'],\n",
    "\n",
    "\n",
    "                'paginationInput': {\n",
    "                                    'entriesPerPage': 100,\n",
    "                                    'pageNumber': page\n",
    "\n",
    "                                    },\n",
    "\n",
    "                }\n",
    "\n",
    "    response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "    response_dict = response.dict()\n",
    "\n",
    "    results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "    prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "    full_dataset.extend(prepared_knives)\n",
    "    \n",
    "df_victorinox = pd.DataFrame(full_dataset)\n",
    "df_victorinox = prepare_df(df_victorinox)\n",
    "df_victorinox = prepare_brands(df_victorinox, 8)\n",
    "df_victorinox.to_csv('data/df_victorinox.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of API call for listed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start of API call section using IDs from preview listed datasets to get Item Specific data from ebay. This will return more descriptive information about the knives, pulling from a container on the website that sellers must complete to post a listing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = pd.read_csv(\"listed_data/df_bench1.csv\")\n",
    "df_buck = pd.read_csv(\"listed_data/df_buck.csv\")\n",
    "df_case = pd.read_csv(\"listed_data/df_case.csv\")\n",
    "df_caseXX = pd.read_csv(\"listed_data/df_CaseXX.csv\")\n",
    "df_crkt = pd.read_csv(\"listed_data/df_crkt.csv\")\n",
    "df_kershaw = pd.read_csv(\"listed_data/df_kershaw.csv\")\n",
    "df_leatherman = pd.read_csv(\"listed_data/df_leatherman.csv\")\n",
    "df_sog = pd.read_csv(\"listed_data/df_sog.csv\")\n",
    "df_spyderco = pd.read_csv(\"listed_data/df_spyderco.csv\")\n",
    "df_victorinox = pd.read_csv(\"listed_data/df_victorinox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchIds = df_bench.itemId.values.tolist()\n",
    "buckIds = df_buck.itemId.values.tolist()\n",
    "caseIds = df_case.itemId.values.tolist()\n",
    "caseXXIds = df_caseXX.itemId.values.tolist()\n",
    "crktIds = df_crkt.itemId.values.tolist()\n",
    "kershawIds = df_kershaw.itemId.values.tolist()\n",
    "leathIds = df_leatherman.itemId.values.tolist()\n",
    "sogIds = df_sog.itemId.values.tolist()\n",
    "spydIds = df_spyderco.itemId.values.tolist()\n",
    "victIds = df_victorinox.itemId.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return benchmade item specific data.\n",
    "\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(benchIds), 20):\n",
    "    process_list(benchIds[i:i+20])\n",
    "\n",
    "bench = pd.DataFrame(full_dataset)\n",
    "bench.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "bench.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return buck item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(buckIds), 20):\n",
    "    process_list(buckIds[i:i+20])\n",
    "\n",
    "buck = pd.DataFrame(full_dataset)\n",
    "buck.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "buck.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return case brand item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(caseIds), 20):\n",
    "    process_list(caseIds[i:i+20])\n",
    "\n",
    "df_case = pd.DataFrame(full_dataset)\n",
    "df_case.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "df_case.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return caseXX brand item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(caseXXIds), 20):\n",
    "    process_list(caseXXIds[i:i+20])\n",
    "\n",
    "df_caseXX = pd.DataFrame(full_dataset)\n",
    "df_caseXX.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "df_caseXX.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return crkt item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(crktIds), 20):\n",
    "    process_list(crktIds[i:i+20])\n",
    "\n",
    "crkt = pd.DataFrame(full_dataset)\n",
    "crkt.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "crkt.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return kershaw item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(kershawIds), 20):\n",
    "    process_list(kershawIds[i:i+20])\n",
    "\n",
    "kershaw = pd.DataFrame(full_dataset)\n",
    "kershaw.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "kershaw.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return leatherman item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(leathIds), 20):\n",
    "    process_list(leathIds[i:i+20])\n",
    "\n",
    "leath = pd.DataFrame(full_dataset)\n",
    "leath.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "leath.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return SOG item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(sogIds), 20):\n",
    "    process_list(sogIds[i:i+20])\n",
    "\n",
    "sog = pd.DataFrame(full_dataset)\n",
    "sog.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "sog.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return spyderco item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(spydIds), 20):\n",
    "    process_list(spydIds[i:i+20])\n",
    "\n",
    "spyd = pd.DataFrame(full_dataset)\n",
    "spyd.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "spyd.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ShoppingAPI call to return victorinox item specific data.\n",
    "```\n",
    "full_dataset = []\n",
    "for i in range(0, len(victIds), 20):\n",
    "    process_list(victIds[i:i+20])\n",
    "    \n",
    "vict = pd.DataFrame(full_dataset)\n",
    "vict.drop_duplicates(subset=['ItemID'], inplace=True)\n",
    "vict.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "bench.to_csv(\"listed_data/benchIds.csv\", index=False)\n",
    "buck.to_csv(\"listed_data/buckIds.csv\", index=False)\n",
    "case.to_csv(\"listed_data/caseIds.csv\", index=False)\n",
    "caseXX.to_csv(\"listed_data/caseXXIds.csv\", index=False)\n",
    "crkt.to_csv(\"listed_data/crktIds.csv\", index=False)\n",
    "kershaw.to_csv(\"listed_data/kershawIds.csv\", index=False)\n",
    "leath.to_csv(\"listed_data/leathIds.csv\", index=False)\n",
    "sog.to_csv(\"listed_data/sogIds.csv\", index=False)\n",
    "spyd.to_csv(\"listed_data/spydIds.csv\", index=False)\n",
    "vict.to_csv(\"listed_data/victIds.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning of prep to merge original listed data with item specific data requested using a seperate API for more complete details about all listings gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = pd.read_csv(\"listed_data/benchIds.csv\")\n",
    "buck = pd.read_csv(\"listed_data/buckIds.csv\")\n",
    "case = pd.read_csv(\"listed_data/caseIds.csv\")\n",
    "caseXX = pd.read_csv(\"listed_data/caseXXIds.csv\")\n",
    "crkt = pd.read_csv(\"listed_data/crktIds.csv\")\n",
    "kershaw = pd.read_csv(\"listed_data/kershawIds.csv\")\n",
    "leath = pd.read_csv(\"listed_data/leathIds.csv\")\n",
    "sog = pd.read_csv(\"listed_data/sogIds.csv\")\n",
    "spyd = pd.read_csv(\"listed_data/spydIds.csv\")\n",
    "vict = pd.read_csv(\"listed_data/victIds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [bench,buck,\n",
    "           case,caseXX,\n",
    "           crkt,kershaw,\n",
    "           leath,sog,\n",
    "           spyd,vict]\n",
    "\n",
    "for dataframe in df_list:\n",
    "    dataframe.rename({'Title': 'title',\n",
    "                      'ItemID': 'itemId'},\n",
    "                     axis=1,inplace=True)\n",
    "    \n",
    "    dataframe.drop(['ConditionID','ConvertedCurrentPrice'], \n",
    "                   axis=1, inplace=True)\n",
    "    dataframe['title'] = dataframe['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge Item Specific dataframes with original listed data using itemIds and title\n",
    "bench_merged = df_bench.merge(bench)\n",
    "buck_merged = df_buck.merge(buck)\n",
    "case_merged = df_case.merge(case)\n",
    "caseXX_merged = df_caseXX.merge(caseXX)\n",
    "crkt_merged = df_crkt.merge(crkt)\n",
    "kershaw_merged = df_kershaw.merge(kershaw)\n",
    "leath_merged = df_leatherman.merge(leath)\n",
    "spyd_merged = df_spyderco.merge(spyd)\n",
    "sog_merged = df_sog.merge(sog)\n",
    "vict_merged = df_victorinox.merge(vict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bench_merged.to_csv('listed_data/bench_merged.csv',index=False)\n",
    "# buck_merged.to_csv('listed_data/buck_merged.csv',index=False)\n",
    "# case_merged.to_csv('listed_data/case_merged.csv',index=False)\n",
    "# caseXX_merged.to_csv('listed_data/caseXX_merged.csv',index=False)\n",
    "# crkt_merged.to_csv('listed_data/crkt_merged.csv',index=False)\n",
    "# kershaw_merged.to_csv('listed_data/kershaw_merged.csv',index=False)\n",
    "# leath_merged.to_csv('listed_data/leath_merged.csv',index=False)\n",
    "# sog_merged.to_csv('listed_data/sog_merged.csv',index=False)\n",
    "# spyd_merged.to_csv('listed_data/spyd_merged.csv',index=False)\n",
    "# vict_merged.to_csv('listed_data/vict_merged.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bench_merged = pd.read_csv('listed_data/bench_merged.csv')\n",
    "# buck_merged = pd.read_csv('listed_data/buck_merged.csv')\n",
    "# case_merged = pd.read_csv('listed_data/case_merged.csv')\n",
    "# caseXX_merged = pd.read_csv('listed_data/caseXX_merged.csv')\n",
    "# crkt_merged = pd.read_csv('listed_data/crkt_merged.csv')\n",
    "# kershaw_merged = pd.read_csv('listed_data/kershaw_merged.csv')\n",
    "# leath_merged = pd.read_csv('listed_data/leath_merged.csv')\n",
    "# sog_merged = pd.read_csv('listed_data/sog_merged.csv')\n",
    "# spyd_merged = pd.read_csv('listed_data/spyd_merged.csv')\n",
    "# vict_merged = pd.read_csv('listed_data/vict_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of API calls for listed data on ebay website. Now will be using scraped data from ebay's proprietery Teraform webapp for researching data. This data shows used knives that were marked as sold and complete and goes back two years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_spec = transform_item_specifics(bench_merged, perc=90.0)\n",
    "buck_spec = transform_item_specifics(buck_merged, perc=90.0)\n",
    "case_spec = transform_item_specifics(case_merged, perc=90.0)\n",
    "caseXX_spec = transform_item_specifics(caseXX_merged, perc=90.0)\n",
    "crkt_spec = transform_item_specifics(crkt_merged, perc=90.0)\n",
    "kershaw_spec = transform_item_specifics(kershaw_merged, perc=90.0)\n",
    "leath_spec = transform_item_specifics(leath_merged, perc=90.0)\n",
    "sog_spec = transform_item_specifics(sog_merged, perc=90.0)\n",
    "spyd_spec = transform_item_specifics(spyd_merged, perc=90.0)\n",
    "vict_spec = transform_item_specifics(vict_merged, perc=90.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_list = [bench_spec, buck_spec,\n",
    "              case_spec, caseXX_spec,\n",
    "              crkt_spec, kershaw_spec,\n",
    "              leath_spec, sog_spec,\n",
    "              spyd, vict_spec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in specs_list:\n",
    "    dataframe.rename({'Brand': 'specBrand'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_bench = bench_merged.join(bench_spec)\n",
    "tot_buck = buck_merged.join(buck_spec)\n",
    "tot_case = case_merged.join(case_spec)\n",
    "tot_caseXX = caseXX_merged.join(caseXX_spec)\n",
    "tot_crkt = crkt_merged.join(crkt_spec)\n",
    "tot_kershaw = kershaw_merged.join(kershaw_spec)\n",
    "tot_leath = leath_merged.join(leath_spec)\n",
    "tot_sog = sog_merged.join(sog_spec)\n",
    "tot_spyd = spyd_merged.join(spyd_spec)\n",
    "tot_vict = vict_merged.join(vict_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot_bench.to_csv('listed_data/total_list_bench.csv', index=False)\n",
    "# tot_buck.to_csv('listed_data/total_list_buck.csv', index=False)\n",
    "# tot_case.to_csv('listed_data/total_list_case.csv', index=False)\n",
    "# tot_caseXX.to_csv('listed_data/total_list_caseXX.csv', index=False)\n",
    "# tot_crkt.to_csv('listed_data/total_list_crkt.csv', index=False)\n",
    "# tot_kershaw.to_csv('listed_data/total_list_kershaw.csv', index=False)\n",
    "# tot_leath.to_csv('listed_data/total_list_leath.csv', index=False)\n",
    "# tot_sog.to_csv('listed_data/total_list_sog.csv', index=False)\n",
    "# tot_spyd.to_csv('listed_data/total_list_spyd.csv', index=False)\n",
    "# tot_vict.to_csv('listed_data/total_list_vict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot_bench = pd.read_csv('listed_data/total_list_bench.csv')\n",
    "# tot_buck = pd.read_csv('listed_data/total_list_buck.csv')\n",
    "# tot_case = pd.read_csv('listed_data/total_list_case.csv')\n",
    "# tot_caseXX = pd.read_csv('listed_data/total_list_caseXX.csv')\n",
    "# tot_crkt = pd.read_csv('listed_data/total_list_crkt.csv')\n",
    "# tot_kershaw = pd.read_csv('listed_data/total_list_kershaw.csv')\n",
    "# tot_leath = pd.read_csv('listed_data/total_list_leath.csv')\n",
    "# tot_sog = pd.read_csv('listed_data/total_list_sog.csv')\n",
    "# tot_spyd = pd.read_csv('listed_data/total_list_spyd.csv')\n",
    "# tot_vict = pd.read_csv('listed_data/total_list_vict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_bench['PictureURL'] = tot_bench['PictureURL'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_bench['PictureURL'] = tot_bench['PictureURL'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "listed_df = pd.concat([tot_bench, tot_buck,\n",
    "            tot_case, tot_caseXX,\n",
    "            tot_crkt, tot_kershaw,\n",
    "            tot_leath, tot_sog,\n",
    "            tot_spyd, tot_vict])\n",
    "\n",
    "listed_df = data_cleaner(listed_df).copy()\n",
    "listed_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_df.to_csv(\"listed_data/listed_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teradf_bench = pd.read_csv(\"teraform_data/tera_benchmade.csv\")\n",
    "teradf_buck = pd.read_csv(\"teraform_data/tera_buck.csv\")\n",
    "teradf_case = pd.read_csv(\"teraform_data/tera_case.csv\")\n",
    "teradf_crkt = pd.read_csv(\"teraform_data/tera_CRKT.csv\")\n",
    "teradf_kershaw = pd.read_csv(\"teraform_data/tera_kershaw.csv\")\n",
    "teradf_leath = pd.read_csv(\"teraform_data/tera_leatherman.csv\")\n",
    "teradf_sog = pd.read_csv(\"teraform_data/tera_SOG.csv\")\n",
    "teradf_spyd = pd.read_csv(\"teraform_data/tera_spyderco.csv\")\n",
    "teradf_vict = pd.read_csv(\"teraform_data/tera_victorinox.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Field</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field2</th>\n",
       "      <th>Data_field</th>\n",
       "      <th>Data_field1</th>\n",
       "      <th>Data_field2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/11512220828...</td>\n",
       "      <td>8</td>\n",
       "      <td>$1,039.60</td>\n",
       "      <td>Dec 21, 2021</td>\n",
       "      <td>Benchmade - 940-2 Knife, Reverse Tanto, G10Ben...</td>\n",
       "      <td>$129.95</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/12503547053...</td>\n",
       "      <td>7</td>\n",
       "      <td>$419.95</td>\n",
       "      <td>Dec 7, 2021</td>\n",
       "      <td>Benchmade USA Grizzly Ridge 15061 S30V Folding...</td>\n",
       "      <td>$59.99</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/30327063273...</td>\n",
       "      <td>7</td>\n",
       "      <td>$839.65</td>\n",
       "      <td>Nov 6, 2021</td>\n",
       "      <td>BENCHMADE 319 PROPER CPM-S30V, SHEEPSFOOT BLAD...</td>\n",
       "      <td>$119.95</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/12503499227...</td>\n",
       "      <td>6</td>\n",
       "      <td>$393.10</td>\n",
       "      <td>Dec 7, 2021</td>\n",
       "      <td>Benchmade 585 Mini Barrage CM154 Axis-Lock Fol...</td>\n",
       "      <td>$65.52</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/23435725332...</td>\n",
       "      <td>6</td>\n",
       "      <td>$1,259.94</td>\n",
       "      <td>Mar 10, 2022</td>\n",
       "      <td>BENCHMADE Osborne 940-1 Knife CPM-S90V Steel &amp;...</td>\n",
       "      <td>$209.99</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image  Field      Price        Field2                                         Data_field Data_field1 Data_field2\n",
       "0  https://thumbs.ebaystatic.com/pict/11512220828...      8  $1,039.60  Dec 21, 2021  Benchmade - 940-2 Knife, Reverse Tanto, G10Ben...     $129.95       $0.00\n",
       "1  https://thumbs.ebaystatic.com/pict/12503547053...      7    $419.95   Dec 7, 2021  Benchmade USA Grizzly Ridge 15061 S30V Folding...      $59.99       $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/30327063273...      7    $839.65   Nov 6, 2021  BENCHMADE 319 PROPER CPM-S30V, SHEEPSFOOT BLAD...     $119.95       $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/12503499227...      6    $393.10   Dec 7, 2021  Benchmade 585 Mini Barrage CM154 Axis-Lock Fol...      $65.52       $0.00\n",
       "4  https://thumbs.ebaystatic.com/pict/23435725332...      6  $1,259.94  Mar 10, 2022  BENCHMADE Osborne 940-1 Knife CPM-S90V Steel &...     $209.99       $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buck\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>title</th>\n",
       "      <th>title2</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/NTE3WDk5NA==/z/n5cA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUCK WHITTAKER MODEL 759 FOLDING POCKET KNIFE ...</td>\n",
       "      <td>$28.42</td>\n",
       "      <td>$6.67</td>\n",
       "      <td>https://www.ebay.com/itm/333626723981?nordt=tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33321505766...</td>\n",
       "      <td>Buck 327 Single Plain Edge Blade Folding Pocke...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/1UUA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buck USA Model 285 Bantum Folding Pocket Knife...</td>\n",
       "      <td>$22.78</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>https://www.ebay.com/itm/233947075532?nordt=tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/HvwA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUCK MINI-BUCK MODEL 425 LOCKBACK FOLDING POCK...</td>\n",
       "      <td>$28.10</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>https://www.ebay.com/itm/333806200723?nordt=tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/AkAA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buck USA 283 Bantam Nano Folding Pocket Knife ...</td>\n",
       "      <td>$16.59</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>https://www.ebay.com/itm/234165380399?nordt=tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                              title                                             title2 avg_price avg_shipping                                                url\n",
       "0  https://i.ebayimg.com/00/s/NTE3WDk5NA==/z/n5cA...                                                NaN  BUCK WHITTAKER MODEL 759 FOLDING POCKET KNIFE ...    $28.42        $6.67  https://www.ebay.com/itm/333626723981?nordt=tr...\n",
       "1  https://thumbs.ebaystatic.com/pict/33321505766...  Buck 327 Single Plain Edge Blade Folding Pocke...                                                NaN    $15.24        $0.00                                                NaN\n",
       "2  https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/1UUA...                                                NaN  Buck USA Model 285 Bantum Folding Pocket Knife...    $22.78        $0.00  https://www.ebay.com/itm/233947075532?nordt=tr...\n",
       "3  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/HvwA...                                                NaN  BUCK MINI-BUCK MODEL 425 LOCKBACK FOLDING POCK...    $28.10        $0.00  https://www.ebay.com/itm/333806200723?nordt=tr...\n",
       "4  https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/AkAA...                                                NaN  Buck USA 283 Bantam Nano Folding Pocket Knife ...    $16.59        $0.00  https://www.ebay.com/itm/234165380399?nordt=tr..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Field</th>\n",
       "      <th>url</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field4</th>\n",
       "      <th>Field5</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/7WAA...</td>\n",
       "      <td>https://www.ebay.com/itm/334166033231?nordt=tr...</td>\n",
       "      <td>10 Case XX Grey Replacement Knife Boxes for Ca...</td>\n",
       "      <td>84</td>\n",
       "      <td>$1,578.90</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$18.80</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33334285075...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>$380.38</td>\n",
       "      <td>Feb 10, 2022</td>\n",
       "      <td>Case XX USA 6254 2-Blade Folding Plain Edge Tr...</td>\n",
       "      <td>$42.26</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33411016012...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>$99.45</td>\n",
       "      <td>Feb 15, 2022</td>\n",
       "      <td>5 Case XX Black Replacement Knife Boxes for Ca...</td>\n",
       "      <td>$14.21</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33411003881...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>$138.45</td>\n",
       "      <td>Sep 30, 2021</td>\n",
       "      <td>10 Case XX Grey Replacement Knife Boxes for Ca...</td>\n",
       "      <td>$19.78</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIyMlgxNjAw/z/6M0A...</td>\n",
       "      <td>https://www.ebay.com/itm/334510870792?nordt=tr...</td>\n",
       "      <td>10 Case XX Replacement Knife Boxes for Case XX...</td>\n",
       "      <td>5</td>\n",
       "      <td>$98.55</td>\n",
       "      <td>Aug 9, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$19.71</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                              Field                                                url  units_sold      Price        Field4                                             Field5 avg_price avg_shipping\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/7WAA...  https://www.ebay.com/itm/334166033231?nordt=tr...  10 Case XX Grey Replacement Knife Boxes for Ca...          84  $1,578.90  Aug 10, 2022                                                NaN    $18.80        $0.00\n",
       "1  https://thumbs.ebaystatic.com/pict/33334285075...                                                NaN                                                NaN           9    $380.38  Feb 10, 2022  Case XX USA 6254 2-Blade Folding Plain Edge Tr...    $42.26        $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/33411016012...                                                NaN                                                NaN           7     $99.45  Feb 15, 2022  5 Case XX Black Replacement Knife Boxes for Ca...    $14.21        $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/33411003881...                                                NaN                                                NaN           7    $138.45  Sep 30, 2021  10 Case XX Grey Replacement Knife Boxes for Ca...    $19.78        $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTIyMlgxNjAw/z/6M0A...  https://www.ebay.com/itm/334510870792?nordt=tr...  10 Case XX Replacement Knife Boxes for Case XX...           5     $98.55   Aug 9, 2022                                                NaN    $19.71        $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crkt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Field</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field2</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>avg_cost</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTA4MFgxMDgw/z/ZukA...</td>\n",
       "      <td>13</td>\n",
       "      <td>$477.79</td>\n",
       "      <td>Jun 5, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRKT Crossbones 7530 Folding Knife AUS-8 Steel...</td>\n",
       "      <td>$36.75</td>\n",
       "      <td>$6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/NTMwWDEzMDY=/z/cmMA...</td>\n",
       "      <td>8</td>\n",
       "      <td>$217.81</td>\n",
       "      <td>Aug 29, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRKT M16-10KS Carson Design Folding Pocket Kni...</td>\n",
       "      <td>$27.23</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/25500479326...</td>\n",
       "      <td>8</td>\n",
       "      <td>$314.60</td>\n",
       "      <td>Sep 21, 2021</td>\n",
       "      <td>New (no box) CRKT PILAR D2 MICARTA VOXNAES DES...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$39.33</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33410395444...</td>\n",
       "      <td>6</td>\n",
       "      <td>$185.99</td>\n",
       "      <td>Jan 18, 2022</td>\n",
       "      <td>CRKT M16-01S Carson Design Folding Pocket Knif...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$31.00</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/zvIA...</td>\n",
       "      <td>5</td>\n",
       "      <td>$195.99</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRKT Columbia River McGinnis Premonition Blue ...</td>\n",
       "      <td>$39.20</td>\n",
       "      <td>$5.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image  Field    Price        Field2                                             title1                                             title2 avg_cost avg_shipping\n",
       "0  https://i.ebayimg.com/00/s/MTA4MFgxMDgw/z/ZukA...     13  $477.79   Jun 5, 2022                                                NaN  CRKT Crossbones 7530 Folding Knife AUS-8 Steel...   $36.75        $6.18\n",
       "1  https://i.ebayimg.com/00/s/NTMwWDEzMDY=/z/cmMA...      8  $217.81  Aug 29, 2022                                                NaN  CRKT M16-10KS Carson Design Folding Pocket Kni...   $27.23        $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/25500479326...      8  $314.60  Sep 21, 2021  New (no box) CRKT PILAR D2 MICARTA VOXNAES DES...                                                NaN   $39.33        $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/33410395444...      6  $185.99  Jan 18, 2022  CRKT M16-01S Carson Design Folding Pocket Knif...                                                NaN   $31.00        $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/zvIA...      5  $195.99  Aug 10, 2022                                                NaN  CRKT Columbia River McGinnis Premonition Blue ...   $39.20        $5.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kershaw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Field</th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field3</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/mZoA...</td>\n",
       "      <td>https://www.ebay.com/itm/402910684828?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 5300 Seki Japan Gentleman NS P...</td>\n",
       "      <td>58</td>\n",
       "      <td>$1,593.10</td>\n",
       "      <td>Jul 22, 2022</td>\n",
       "      <td>$27.47</td>\n",
       "      <td>$18.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/liAA...</td>\n",
       "      <td>https://www.ebay.com/itm/363429037003?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 5300 Seki Japan Small Stainles...</td>\n",
       "      <td>56</td>\n",
       "      <td>$1,233.37</td>\n",
       "      <td>Aug 24, 2022</td>\n",
       "      <td>$22.02</td>\n",
       "      <td>$18.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/38472134984...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>$1,557.55</td>\n",
       "      <td>Feb 17, 2022</td>\n",
       "      <td>$25.53</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/40288089696...</td>\n",
       "      <td>https://www.ebay.com/itm/402880896968?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 5100 Seki Japan Lacquer Gentle...</td>\n",
       "      <td>42</td>\n",
       "      <td>$1,089.90</td>\n",
       "      <td>May 19, 2022</td>\n",
       "      <td>$25.95</td>\n",
       "      <td>$11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/4J4A...</td>\n",
       "      <td>https://www.ebay.com/itm/363313999772?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 2110 Seki Japan Bone Handle 3....</td>\n",
       "      <td>40</td>\n",
       "      <td>$2,137.49</td>\n",
       "      <td>Aug 7, 2022</td>\n",
       "      <td>$53.44</td>\n",
       "      <td>$18.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                              Field                                             Field1  Field2      Price        Field3 avg_price avg_shipping\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/mZoA...  https://www.ebay.com/itm/402910684828?nordt=tr...  Vtg Kershaw Kai 5300 Seki Japan Gentleman NS P...      58  $1,593.10  Jul 22, 2022    $27.47       $18.91\n",
       "1  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/liAA...  https://www.ebay.com/itm/363429037003?nordt=tr...  Vtg Kershaw Kai 5300 Seki Japan Small Stainles...      56  $1,233.37  Aug 24, 2022    $22.02       $18.14\n",
       "2  https://thumbs.ebaystatic.com/pict/38472134984...                                                NaN                                                NaN      61  $1,557.55  Feb 17, 2022    $25.53        $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/40288089696...  https://www.ebay.com/itm/402880896968?nordt=tr...  Vtg Kershaw Kai 5100 Seki Japan Lacquer Gentle...      42  $1,089.90  May 19, 2022    $25.95       $11.32\n",
       "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/4J4A...  https://www.ebay.com/itm/363313999772?nordt=tr...  Vtg Kershaw Kai 2110 Seki Japan Bone Handle 3....      40  $2,137.49   Aug 7, 2022    $53.44       $18.32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leatherman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Field</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field2</th>\n",
       "      <th>title1</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/iWgA...</td>\n",
       "      <td>24</td>\n",
       "      <td>$498.81</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Wave Blac...</td>\n",
       "      <td>$20.78</td>\n",
       "      <td>$3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/t2YA...</td>\n",
       "      <td>20</td>\n",
       "      <td>$389.78</td>\n",
       "      <td>Aug 21, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Charge Ti...</td>\n",
       "      <td>$19.49</td>\n",
       "      <td>$4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/RmAA...</td>\n",
       "      <td>18</td>\n",
       "      <td>$634.31</td>\n",
       "      <td>Jul 25, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leatherman \"original\" PST multi tool</td>\n",
       "      <td>$35.24</td>\n",
       "      <td>$8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/LNwA...</td>\n",
       "      <td>17</td>\n",
       "      <td>$299.34</td>\n",
       "      <td>Aug 25, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Wingman  ...</td>\n",
       "      <td>$17.61</td>\n",
       "      <td>$4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/pBEA...</td>\n",
       "      <td>17</td>\n",
       "      <td>$329.54</td>\n",
       "      <td>Aug 3, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Charge Ti...</td>\n",
       "      <td>$19.38</td>\n",
       "      <td>$4.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image  Field    Price        Field2 title1                                              title avg_price avg_shipping\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/iWgA...     24  $498.81  Aug 10, 2022    NaN  Leatherman Parts Mod Replacement for Wave Blac...    $20.78        $3.47\n",
       "1  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/t2YA...     20  $389.78  Aug 21, 2022    NaN  Leatherman Parts Mod Replacement for Charge Ti...    $19.49        $4.80\n",
       "2  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/RmAA...     18  $634.31  Jul 25, 2022    NaN               Leatherman \"original\" PST multi tool    $35.24        $8.21\n",
       "3  https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/LNwA...     17  $299.34  Aug 25, 2022    NaN  Leatherman Parts Mod Replacement for Wingman  ...    $17.61        $4.80\n",
       "4  https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/pBEA...     17  $329.54   Aug 3, 2022    NaN  Leatherman Parts Mod Replacement for Charge Ti...    $19.38        $4.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sog\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Field</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field2</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/d9UA...</td>\n",
       "      <td>21</td>\n",
       "      <td>$796.03</td>\n",
       "      <td>Jun 30, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vintage SOG M33 Seki Japan Mini Gentleman Stai...</td>\n",
       "      <td>$37.91</td>\n",
       "      <td>$30.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/23336011008...</td>\n",
       "      <td>12</td>\n",
       "      <td>$102.84</td>\n",
       "      <td>Mar 5, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOG Key Small Keychain Folding Pocket Knife (V...</td>\n",
       "      <td>$8.57</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/15497125119...</td>\n",
       "      <td>10</td>\n",
       "      <td>$228.00</td>\n",
       "      <td>Jun 1, 2022</td>\n",
       "      <td>SOG Terminus Slip Joint Knife Tan G-10 BD1 Sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$22.80</td>\n",
       "      <td>$4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/20358845464...</td>\n",
       "      <td>10</td>\n",
       "      <td>$107.30</td>\n",
       "      <td>Oct 24, 2021</td>\n",
       "      <td>5 Black SOG Micron II (2) Folding Pocket Knif...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$10.73</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTA1OVgxNjAw/z/KiQA...</td>\n",
       "      <td>9</td>\n",
       "      <td>$47.09</td>\n",
       "      <td>Aug 5, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group A Choice of Knife Sog Key - Korean 3 Bla...</td>\n",
       "      <td>$5.23</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image  Field    Price        Field2                                             title1                                             title2 avg_price avg_shipping\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/d9UA...     21  $796.03  Jun 30, 2022                                                NaN  Vintage SOG M33 Seki Japan Mini Gentleman Stai...    $37.91       $30.17\n",
       "1  https://thumbs.ebaystatic.com/pict/23336011008...     12  $102.84   Mar 5, 2022                                                NaN  SOG Key Small Keychain Folding Pocket Knife (V...     $8.57        $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/15497125119...     10  $228.00   Jun 1, 2022  SOG Terminus Slip Joint Knife Tan G-10 BD1 Sta...                                                NaN    $22.80        $4.25\n",
       "3  https://thumbs.ebaystatic.com/pict/20358845464...     10  $107.30  Oct 24, 2021  5 Black SOG Micron II (2) Folding Pocket Knif...                                                NaN    $10.73        $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTA1OVgxNjAw/z/KiQA...      9   $47.09   Aug 5, 2022                                                NaN  Group A Choice of Knife Sog Key - Korean 3 Bla...     $5.23        $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spyderco\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field2</th>\n",
       "      <th>Field3</th>\n",
       "      <th>name</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/32466686588...</td>\n",
       "      <td>60</td>\n",
       "      <td>$6,399.40</td>\n",
       "      <td>Apr 11, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New NIB Spyderco Para 3 Lightweight Compressio...</td>\n",
       "      <td>$106.66</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTA2NFgxNjAw/z/dNEA...</td>\n",
       "      <td>26</td>\n",
       "      <td>$3,709.74</td>\n",
       "      <td>Aug 20, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIB New Spyderco Para 3 Knife C223GPCMO Satin ...</td>\n",
       "      <td>$142.68</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/22457770707...</td>\n",
       "      <td>18</td>\n",
       "      <td>$1,691.82</td>\n",
       "      <td>Jan 25, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New NIB Spyderco Manix 2 Lightweight Transluce...</td>\n",
       "      <td>$93.99</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTYwMFgxNjAw/z/Q1QA...</td>\n",
       "      <td>15</td>\n",
       "      <td>$2,441.86</td>\n",
       "      <td>Aug 8, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIB NEW Spyderco-LionSTEEL SpyOpera Knife 2.88...</td>\n",
       "      <td>$162.79</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/32475894633...</td>\n",
       "      <td>15</td>\n",
       "      <td>$1,175.88</td>\n",
       "      <td>Feb 27, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New NIB Spyderco Delica 4 Lockback Knife Zome ...</td>\n",
       "      <td>$78.39</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image  units_sold      Price        Field2 Field3                                               name avg_price avg_shipping\n",
       "0  https://thumbs.ebaystatic.com/pict/32466686588...          60  $6,399.40  Apr 11, 2022    NaN  New NIB Spyderco Para 3 Lightweight Compressio...   $106.66        $0.00\n",
       "1  https://i.ebayimg.com/00/s/MTA2NFgxNjAw/z/dNEA...          26  $3,709.74  Aug 20, 2022    NaN  NIB New Spyderco Para 3 Knife C223GPCMO Satin ...   $142.68        $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/22457770707...          18  $1,691.82  Jan 25, 2022    NaN  New NIB Spyderco Manix 2 Lightweight Transluce...    $93.99        $0.00\n",
       "3  https://i.ebayimg.com/00/s/MTYwMFgxNjAw/z/Q1QA...          15  $2,441.86   Aug 8, 2022    NaN  NIB NEW Spyderco-LionSTEEL SpyOpera Knife 2.88...   $162.79        $0.00\n",
       "4  https://thumbs.ebaystatic.com/pict/32475894633...          15  $1,175.88  Feb 27, 2022    NaN  New NIB Spyderco Delica 4 Lockback Knife Zome ...    $78.39        $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victorinox\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FfImage</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>Field2</th>\n",
       "      <th>Price</th>\n",
       "      <th>Field3</th>\n",
       "      <th>title2</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_shipping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/NTAwWDM3NQ==/z/smEA...</td>\n",
       "      <td>https://www.ebay.com/itm/324946521772?nordt=tr...</td>\n",
       "      <td>Victorinox Classic SD Mini Swiss Army Pocket K...</td>\n",
       "      <td>878</td>\n",
       "      <td>$5,788.01</td>\n",
       "      <td>Aug 15, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$6.59</td>\n",
       "      <td>$3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/SQEA...</td>\n",
       "      <td>https://www.ebay.com/itm/233805693414?nordt=tr...</td>\n",
       "      <td>Victorinox Classic SD Swiss Army Knife 3 Tool ...</td>\n",
       "      <td>587</td>\n",
       "      <td>$4,866.43</td>\n",
       "      <td>Jul 22, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$8.29</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/14392195183...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>503</td>\n",
       "      <td>$3,679.86</td>\n",
       "      <td>Apr 7, 2022</td>\n",
       "      <td>Victorinox Classic SD Swiss Army Knife 3 Tool ...</td>\n",
       "      <td>$7.32</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33381140129...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>$993.86</td>\n",
       "      <td>May 30, 2022</td>\n",
       "      <td>Victorinox Classic SD Swiss Army Knife 3 Tool ...</td>\n",
       "      <td>$7.89</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/C4cA...</td>\n",
       "      <td>https://www.ebay.com/itm/254705443098?nordt=tr...</td>\n",
       "      <td>Original German army Swiss Victorinox made Poc...</td>\n",
       "      <td>104</td>\n",
       "      <td>$3,436.18</td>\n",
       "      <td>Aug 16, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$33.04</td>\n",
       "      <td>$7.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             FfImage                                                url                                              title  Field2      Price        Field3                                             title2 avg_price avg_shipping\n",
       "0  https://i.ebayimg.com/00/s/NTAwWDM3NQ==/z/smEA...  https://www.ebay.com/itm/324946521772?nordt=tr...  Victorinox Classic SD Mini Swiss Army Pocket K...     878  $5,788.01  Aug 15, 2022                                                NaN     $6.59        $3.54\n",
       "1  https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/SQEA...  https://www.ebay.com/itm/233805693414?nordt=tr...  Victorinox Classic SD Swiss Army Knife 3 Tool ...     587  $4,866.43  Jul 22, 2022                                                NaN     $8.29        $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/14392195183...                                                NaN                                                NaN     503  $3,679.86   Apr 7, 2022  Victorinox Classic SD Swiss Army Knife 3 Tool ...     $7.32        $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/33381140129...                                                NaN                                                NaN     126    $993.86  May 30, 2022  Victorinox Classic SD Swiss Army Knife 3 Tool ...     $7.89        $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/C4cA...  https://www.ebay.com/itm/254705443098?nordt=tr...  Original German army Swiss Victorinox made Poc...     104  $3,436.18  Aug 16, 2022                                                NaN    $33.04        $7.44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dict = {'benchmade': teradf_bench, \n",
    "           'buck': teradf_buck,\n",
    "           'case':teradf_case,\n",
    "           'crkt':teradf_crkt,\n",
    "           'kershaw':teradf_kershaw,\n",
    "           'leatherman':teradf_leath,\n",
    "           'sog':teradf_sog, \n",
    "           'spyderco':teradf_spyd,\n",
    "           'victorinox':teradf_vict}\n",
    "\n",
    "for key,val in df_dict.items():\n",
    "    print(key)\n",
    "    display(val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teradf_bench.rename({'Data_field':'title', \n",
    "                     'Data_field1':'price_in_US', \n",
    "                     'Data_field2':'shipping_cost', \n",
    "                     'Field2':'date_sold'},\n",
    "                     axis=1, inplace=True)\n",
    "\n",
    "teradf_buck.rename({'avg_price':'price_in_US', \n",
    "                    'avg_shipping':'shipping_cost'},\n",
    "                     axis=1, inplace=True)\n",
    "\n",
    "teradf_case.rename({'url':'title', \n",
    "                    'Field5':'title2', \n",
    "                    'Field4': 'date_sold',\n",
    "                    'Field': 'url',\n",
    "                    'avg_price': 'price_in_US',\n",
    "                    'avg_shipping': 'shipping_cost'\n",
    "                    }, axis=1, inplace=True)\n",
    "\n",
    "teradf_crkt.rename({'Field2':'date_sold', \n",
    "                    'title1':'title', \n",
    "                    'avg_cost': 'price_in_US',\n",
    "                    'avg_shipping': 'shipping_cost'\n",
    "                    }, axis=1, inplace=True)\n",
    "\n",
    "teradf_kershaw.rename({'Field':'url', \n",
    "                       'Field1':'title', \n",
    "                       'Field3':'date_sold',\n",
    "                       'avg_price': 'price_in_US',\n",
    "                       'avg_shipping': 'shipping_cost'\n",
    "                       }, axis=1, inplace=True)\n",
    "\n",
    "teradf_leath.rename({'Field2':'date_sold', \n",
    "                     'title1':'title2', \n",
    "                     'avg_price': 'price_in_US',\n",
    "                     'avg_shipping': 'shipping_cost'\n",
    "                     }, axis=1, inplace=True)\n",
    "\n",
    "teradf_sog.rename({'Field2':'date_sold', \n",
    "                   'title1':'title', \n",
    "                   'avg_price': 'price_in_US',\n",
    "                   'avg_shipping': 'shipping_cost'\n",
    "                   }, axis=1, inplace=True)\n",
    "\n",
    "teradf_spyd.rename({'Field2':'date_sold', \n",
    "                    'Field3':'title', \n",
    "                    'name':'title2',\n",
    "                    'avg_price': 'price_in_US',\n",
    "                    'avg_shipping': 'shipping_cost'\n",
    "                    }, axis=1, inplace=True)\n",
    "\n",
    "teradf_vict.rename({'FfImage':'Image', \n",
    "                    'Field3':'date_sold', \n",
    "                    'avg_price': 'price_in_US',\n",
    "                    'avg_shipping': 'shipping_cost'\n",
    "                    }, axis=1, inplace=True)\n",
    "# teradf_bench.drop(['Field', 'Price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teradf_bench.drop(['Field', 'Price'], axis=1, inplace=True)\n",
    "teradf_case.drop(['units_sold', 'Price'], axis=1, inplace=True)\n",
    "teradf_crkt.drop(['Field', 'Price'], axis=1, inplace=True)\n",
    "teradf_kershaw.drop(['Field2', 'Price'], axis=1, inplace=True)\n",
    "teradf_leath.drop(['Field', 'Price'], axis=1, inplace=True)\n",
    "teradf_sog.drop(['Field', 'Price'], axis=1, inplace=True)\n",
    "teradf_spyd.drop(['units_sold', 'Price'], axis=1, inplace=True)\n",
    "teradf_vict.drop(['Field2', 'Price'], axis=1, inplace=True)\n",
    "\n",
    "teradf_buck['title'].fillna(teradf_buck['title2'], inplace=True)\n",
    "teradf_case['title'].fillna(teradf_case['title2'], inplace=True)\n",
    "teradf_crkt['title'].fillna(teradf_crkt['title2'], inplace=True)\n",
    "teradf_leath['title'].fillna(teradf_leath['title2'], inplace=True)\n",
    "teradf_sog['title'].fillna(teradf_sog['title2'], inplace=True)\n",
    "teradf_spyd['title'].fillna(teradf_spyd['title2'], inplace=True)\n",
    "teradf_vict['title'].fillna(teradf_vict['title2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "title2_list = [teradf_buck, teradf_case,\n",
    "               teradf_crkt, teradf_leath,\n",
    "               teradf_sog, teradf_spyd,\n",
    "               teradf_vict]\n",
    "               \n",
    "for dataframe in title2_list:\n",
    "    dataframe.drop('title2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>title</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/11512220828...</td>\n",
       "      <td>Dec 21, 2021</td>\n",
       "      <td>Benchmade - 940-2 Knife, Reverse Tanto, G10Ben...</td>\n",
       "      <td>$129.95</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/12503547053...</td>\n",
       "      <td>Dec 7, 2021</td>\n",
       "      <td>Benchmade USA Grizzly Ridge 15061 S30V Folding...</td>\n",
       "      <td>$59.99</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/30327063273...</td>\n",
       "      <td>Nov 6, 2021</td>\n",
       "      <td>BENCHMADE 319 PROPER CPM-S30V, SHEEPSFOOT BLAD...</td>\n",
       "      <td>$119.95</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/12503499227...</td>\n",
       "      <td>Dec 7, 2021</td>\n",
       "      <td>Benchmade 585 Mini Barrage CM154 Axis-Lock Fol...</td>\n",
       "      <td>$65.52</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/23435725332...</td>\n",
       "      <td>Mar 10, 2022</td>\n",
       "      <td>BENCHMADE Osborne 940-1 Knife CPM-S90V Steel &amp;...</td>\n",
       "      <td>$209.99</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image     date_sold                                              title price_in_US shipping_cost\n",
       "0  https://thumbs.ebaystatic.com/pict/11512220828...  Dec 21, 2021  Benchmade - 940-2 Knife, Reverse Tanto, G10Ben...     $129.95         $0.00\n",
       "1  https://thumbs.ebaystatic.com/pict/12503547053...   Dec 7, 2021  Benchmade USA Grizzly Ridge 15061 S30V Folding...      $59.99         $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/30327063273...   Nov 6, 2021  BENCHMADE 319 PROPER CPM-S30V, SHEEPSFOOT BLAD...     $119.95         $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/12503499227...   Dec 7, 2021  Benchmade 585 Mini Barrage CM154 Axis-Lock Fol...      $65.52         $0.00\n",
       "4  https://thumbs.ebaystatic.com/pict/23435725332...  Mar 10, 2022  BENCHMADE Osborne 940-1 Knife CPM-S90V Steel &...     $209.99         $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buck\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>title</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/NTE3WDk5NA==/z/n5cA...</td>\n",
       "      <td>BUCK WHITTAKER MODEL 759 FOLDING POCKET KNIFE ...</td>\n",
       "      <td>$28.42</td>\n",
       "      <td>$6.67</td>\n",
       "      <td>https://www.ebay.com/itm/333626723981?nordt=tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33321505766...</td>\n",
       "      <td>Buck 327 Single Plain Edge Blade Folding Pocke...</td>\n",
       "      <td>$15.24</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/1UUA...</td>\n",
       "      <td>Buck USA Model 285 Bantum Folding Pocket Knife...</td>\n",
       "      <td>$22.78</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>https://www.ebay.com/itm/233947075532?nordt=tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/HvwA...</td>\n",
       "      <td>BUCK MINI-BUCK MODEL 425 LOCKBACK FOLDING POCK...</td>\n",
       "      <td>$28.10</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>https://www.ebay.com/itm/333806200723?nordt=tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/AkAA...</td>\n",
       "      <td>Buck USA 283 Bantam Nano Folding Pocket Knife ...</td>\n",
       "      <td>$16.59</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>https://www.ebay.com/itm/234165380399?nordt=tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                              title price_in_US shipping_cost                                                url\n",
       "0  https://i.ebayimg.com/00/s/NTE3WDk5NA==/z/n5cA...  BUCK WHITTAKER MODEL 759 FOLDING POCKET KNIFE ...      $28.42         $6.67  https://www.ebay.com/itm/333626723981?nordt=tr...\n",
       "1  https://thumbs.ebaystatic.com/pict/33321505766...  Buck 327 Single Plain Edge Blade Folding Pocke...      $15.24         $0.00                                                NaN\n",
       "2  https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/1UUA...  Buck USA Model 285 Bantum Folding Pocket Knife...      $22.78         $0.00  https://www.ebay.com/itm/233947075532?nordt=tr...\n",
       "3  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/HvwA...  BUCK MINI-BUCK MODEL 425 LOCKBACK FOLDING POCK...      $28.10         $0.00  https://www.ebay.com/itm/333806200723?nordt=tr...\n",
       "4  https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/AkAA...  Buck USA 283 Bantam Nano Folding Pocket Knife ...      $16.59         $0.00  https://www.ebay.com/itm/234165380399?nordt=tr..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/7WAA...</td>\n",
       "      <td>https://www.ebay.com/itm/334166033231?nordt=tr...</td>\n",
       "      <td>10 Case XX Grey Replacement Knife Boxes for Ca...</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>$18.80</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33334285075...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Case XX USA 6254 2-Blade Folding Plain Edge Tr...</td>\n",
       "      <td>Feb 10, 2022</td>\n",
       "      <td>$42.26</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33411016012...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Case XX Black Replacement Knife Boxes for Ca...</td>\n",
       "      <td>Feb 15, 2022</td>\n",
       "      <td>$14.21</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33411003881...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10 Case XX Grey Replacement Knife Boxes for Ca...</td>\n",
       "      <td>Sep 30, 2021</td>\n",
       "      <td>$19.78</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIyMlgxNjAw/z/6M0A...</td>\n",
       "      <td>https://www.ebay.com/itm/334510870792?nordt=tr...</td>\n",
       "      <td>10 Case XX Replacement Knife Boxes for Case XX...</td>\n",
       "      <td>Aug 9, 2022</td>\n",
       "      <td>$19.71</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                                url                                              title     date_sold price_in_US shipping_cost\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/7WAA...  https://www.ebay.com/itm/334166033231?nordt=tr...  10 Case XX Grey Replacement Knife Boxes for Ca...  Aug 10, 2022      $18.80         $0.00\n",
       "1  https://thumbs.ebaystatic.com/pict/33334285075...                                                NaN  Case XX USA 6254 2-Blade Folding Plain Edge Tr...  Feb 10, 2022      $42.26         $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/33411016012...                                                NaN  5 Case XX Black Replacement Knife Boxes for Ca...  Feb 15, 2022      $14.21         $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/33411003881...                                                NaN  10 Case XX Grey Replacement Knife Boxes for Ca...  Sep 30, 2021      $19.78         $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTIyMlgxNjAw/z/6M0A...  https://www.ebay.com/itm/334510870792?nordt=tr...  10 Case XX Replacement Knife Boxes for Case XX...   Aug 9, 2022      $19.71         $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crkt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>title</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTA4MFgxMDgw/z/ZukA...</td>\n",
       "      <td>Jun 5, 2022</td>\n",
       "      <td>CRKT Crossbones 7530 Folding Knife AUS-8 Steel...</td>\n",
       "      <td>$36.75</td>\n",
       "      <td>$6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/NTMwWDEzMDY=/z/cmMA...</td>\n",
       "      <td>Aug 29, 2022</td>\n",
       "      <td>CRKT M16-10KS Carson Design Folding Pocket Kni...</td>\n",
       "      <td>$27.23</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/25500479326...</td>\n",
       "      <td>Sep 21, 2021</td>\n",
       "      <td>New (no box) CRKT PILAR D2 MICARTA VOXNAES DES...</td>\n",
       "      <td>$39.33</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33410395444...</td>\n",
       "      <td>Jan 18, 2022</td>\n",
       "      <td>CRKT M16-01S Carson Design Folding Pocket Knif...</td>\n",
       "      <td>$31.00</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/zvIA...</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>CRKT Columbia River McGinnis Premonition Blue ...</td>\n",
       "      <td>$39.20</td>\n",
       "      <td>$5.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image     date_sold                                              title price_in_US shipping_cost\n",
       "0  https://i.ebayimg.com/00/s/MTA4MFgxMDgw/z/ZukA...   Jun 5, 2022  CRKT Crossbones 7530 Folding Knife AUS-8 Steel...      $36.75         $6.18\n",
       "1  https://i.ebayimg.com/00/s/NTMwWDEzMDY=/z/cmMA...  Aug 29, 2022  CRKT M16-10KS Carson Design Folding Pocket Kni...      $27.23         $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/25500479326...  Sep 21, 2021  New (no box) CRKT PILAR D2 MICARTA VOXNAES DES...      $39.33         $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/33410395444...  Jan 18, 2022  CRKT M16-01S Carson Design Folding Pocket Knif...      $31.00         $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/zvIA...  Aug 10, 2022  CRKT Columbia River McGinnis Premonition Blue ...      $39.20         $5.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kershaw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/mZoA...</td>\n",
       "      <td>https://www.ebay.com/itm/402910684828?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 5300 Seki Japan Gentleman NS P...</td>\n",
       "      <td>Jul 22, 2022</td>\n",
       "      <td>$27.47</td>\n",
       "      <td>$18.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/liAA...</td>\n",
       "      <td>https://www.ebay.com/itm/363429037003?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 5300 Seki Japan Small Stainles...</td>\n",
       "      <td>Aug 24, 2022</td>\n",
       "      <td>$22.02</td>\n",
       "      <td>$18.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/38472134984...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feb 17, 2022</td>\n",
       "      <td>$25.53</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/40288089696...</td>\n",
       "      <td>https://www.ebay.com/itm/402880896968?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 5100 Seki Japan Lacquer Gentle...</td>\n",
       "      <td>May 19, 2022</td>\n",
       "      <td>$25.95</td>\n",
       "      <td>$11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/4J4A...</td>\n",
       "      <td>https://www.ebay.com/itm/363313999772?nordt=tr...</td>\n",
       "      <td>Vtg Kershaw Kai 2110 Seki Japan Bone Handle 3....</td>\n",
       "      <td>Aug 7, 2022</td>\n",
       "      <td>$53.44</td>\n",
       "      <td>$18.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                                url                                              title     date_sold price_in_US shipping_cost\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/mZoA...  https://www.ebay.com/itm/402910684828?nordt=tr...  Vtg Kershaw Kai 5300 Seki Japan Gentleman NS P...  Jul 22, 2022      $27.47        $18.91\n",
       "1  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/liAA...  https://www.ebay.com/itm/363429037003?nordt=tr...  Vtg Kershaw Kai 5300 Seki Japan Small Stainles...  Aug 24, 2022      $22.02        $18.14\n",
       "2  https://thumbs.ebaystatic.com/pict/38472134984...                                                NaN                                                NaN  Feb 17, 2022      $25.53         $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/40288089696...  https://www.ebay.com/itm/402880896968?nordt=tr...  Vtg Kershaw Kai 5100 Seki Japan Lacquer Gentle...  May 19, 2022      $25.95        $11.32\n",
       "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/4J4A...  https://www.ebay.com/itm/363313999772?nordt=tr...  Vtg Kershaw Kai 2110 Seki Japan Bone Handle 3....   Aug 7, 2022      $53.44        $18.32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leatherman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>title</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/iWgA...</td>\n",
       "      <td>Aug 10, 2022</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Wave Blac...</td>\n",
       "      <td>$20.78</td>\n",
       "      <td>$3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/t2YA...</td>\n",
       "      <td>Aug 21, 2022</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Charge Ti...</td>\n",
       "      <td>$19.49</td>\n",
       "      <td>$4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/RmAA...</td>\n",
       "      <td>Jul 25, 2022</td>\n",
       "      <td>Leatherman \"original\" PST multi tool</td>\n",
       "      <td>$35.24</td>\n",
       "      <td>$8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/LNwA...</td>\n",
       "      <td>Aug 25, 2022</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Wingman  ...</td>\n",
       "      <td>$17.61</td>\n",
       "      <td>$4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/pBEA...</td>\n",
       "      <td>Aug 3, 2022</td>\n",
       "      <td>Leatherman Parts Mod Replacement for Charge Ti...</td>\n",
       "      <td>$19.38</td>\n",
       "      <td>$4.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image     date_sold                                              title price_in_US shipping_cost\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/iWgA...  Aug 10, 2022  Leatherman Parts Mod Replacement for Wave Blac...      $20.78         $3.47\n",
       "1  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/t2YA...  Aug 21, 2022  Leatherman Parts Mod Replacement for Charge Ti...      $19.49         $4.80\n",
       "2  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/RmAA...  Jul 25, 2022               Leatherman \"original\" PST multi tool      $35.24         $8.21\n",
       "3  https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/LNwA...  Aug 25, 2022  Leatherman Parts Mod Replacement for Wingman  ...      $17.61         $4.80\n",
       "4  https://i.ebayimg.com/00/s/MTYwMFgxMjAw/z/pBEA...   Aug 3, 2022  Leatherman Parts Mod Replacement for Charge Ti...      $19.38         $4.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sog\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>title</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/d9UA...</td>\n",
       "      <td>Jun 30, 2022</td>\n",
       "      <td>Vintage SOG M33 Seki Japan Mini Gentleman Stai...</td>\n",
       "      <td>$37.91</td>\n",
       "      <td>$30.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/23336011008...</td>\n",
       "      <td>Mar 5, 2022</td>\n",
       "      <td>SOG Key Small Keychain Folding Pocket Knife (V...</td>\n",
       "      <td>$8.57</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/15497125119...</td>\n",
       "      <td>Jun 1, 2022</td>\n",
       "      <td>SOG Terminus Slip Joint Knife Tan G-10 BD1 Sta...</td>\n",
       "      <td>$22.80</td>\n",
       "      <td>$4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/20358845464...</td>\n",
       "      <td>Oct 24, 2021</td>\n",
       "      <td>5 Black SOG Micron II (2) Folding Pocket Knif...</td>\n",
       "      <td>$10.73</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTA1OVgxNjAw/z/KiQA...</td>\n",
       "      <td>Aug 5, 2022</td>\n",
       "      <td>Group A Choice of Knife Sog Key - Korean 3 Bla...</td>\n",
       "      <td>$5.23</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image     date_sold                                              title price_in_US shipping_cost\n",
       "0  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/d9UA...  Jun 30, 2022  Vintage SOG M33 Seki Japan Mini Gentleman Stai...      $37.91        $30.17\n",
       "1  https://thumbs.ebaystatic.com/pict/23336011008...   Mar 5, 2022  SOG Key Small Keychain Folding Pocket Knife (V...       $8.57         $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/15497125119...   Jun 1, 2022  SOG Terminus Slip Joint Knife Tan G-10 BD1 Sta...      $22.80         $4.25\n",
       "3  https://thumbs.ebaystatic.com/pict/20358845464...  Oct 24, 2021  5 Black SOG Micron II (2) Folding Pocket Knif...      $10.73         $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTA1OVgxNjAw/z/KiQA...   Aug 5, 2022  Group A Choice of Knife Sog Key - Korean 3 Bla...       $5.23         $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spyderco\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>title</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/32466686588...</td>\n",
       "      <td>Apr 11, 2022</td>\n",
       "      <td>New NIB Spyderco Para 3 Lightweight Compressio...</td>\n",
       "      <td>$106.66</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTA2NFgxNjAw/z/dNEA...</td>\n",
       "      <td>Aug 20, 2022</td>\n",
       "      <td>NIB New Spyderco Para 3 Knife C223GPCMO Satin ...</td>\n",
       "      <td>$142.68</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/22457770707...</td>\n",
       "      <td>Jan 25, 2022</td>\n",
       "      <td>New NIB Spyderco Manix 2 Lightweight Transluce...</td>\n",
       "      <td>$93.99</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTYwMFgxNjAw/z/Q1QA...</td>\n",
       "      <td>Aug 8, 2022</td>\n",
       "      <td>NIB NEW Spyderco-LionSTEEL SpyOpera Knife 2.88...</td>\n",
       "      <td>$162.79</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/32475894633...</td>\n",
       "      <td>Feb 27, 2022</td>\n",
       "      <td>New NIB Spyderco Delica 4 Lockback Knife Zome ...</td>\n",
       "      <td>$78.39</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image     date_sold                                              title price_in_US shipping_cost\n",
       "0  https://thumbs.ebaystatic.com/pict/32466686588...  Apr 11, 2022  New NIB Spyderco Para 3 Lightweight Compressio...     $106.66         $0.00\n",
       "1  https://i.ebayimg.com/00/s/MTA2NFgxNjAw/z/dNEA...  Aug 20, 2022  NIB New Spyderco Para 3 Knife C223GPCMO Satin ...     $142.68         $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/22457770707...  Jan 25, 2022  New NIB Spyderco Manix 2 Lightweight Transluce...      $93.99         $0.00\n",
       "3  https://i.ebayimg.com/00/s/MTYwMFgxNjAw/z/Q1QA...   Aug 8, 2022  NIB NEW Spyderco-LionSTEEL SpyOpera Knife 2.88...     $162.79         $0.00\n",
       "4  https://thumbs.ebaystatic.com/pict/32475894633...  Feb 27, 2022  New NIB Spyderco Delica 4 Lockback Knife Zome ...      $78.39         $0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victorinox\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>price_in_US</th>\n",
       "      <th>shipping_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.ebayimg.com/00/s/NTAwWDM3NQ==/z/smEA...</td>\n",
       "      <td>https://www.ebay.com/itm/324946521772?nordt=tr...</td>\n",
       "      <td>Victorinox Classic SD Mini Swiss Army Pocket K...</td>\n",
       "      <td>Aug 15, 2022</td>\n",
       "      <td>$6.59</td>\n",
       "      <td>$3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/SQEA...</td>\n",
       "      <td>https://www.ebay.com/itm/233805693414?nordt=tr...</td>\n",
       "      <td>Victorinox Classic SD Swiss Army Knife 3 Tool ...</td>\n",
       "      <td>Jul 22, 2022</td>\n",
       "      <td>$8.29</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/14392195183...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victorinox Classic SD Swiss Army Knife 3 Tool ...</td>\n",
       "      <td>Apr 7, 2022</td>\n",
       "      <td>$7.32</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thumbs.ebaystatic.com/pict/33381140129...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victorinox Classic SD Swiss Army Knife 3 Tool ...</td>\n",
       "      <td>May 30, 2022</td>\n",
       "      <td>$7.89</td>\n",
       "      <td>$0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/C4cA...</td>\n",
       "      <td>https://www.ebay.com/itm/254705443098?nordt=tr...</td>\n",
       "      <td>Original German army Swiss Victorinox made Poc...</td>\n",
       "      <td>Aug 16, 2022</td>\n",
       "      <td>$33.04</td>\n",
       "      <td>$7.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image                                                url                                              title     date_sold price_in_US shipping_cost\n",
       "0  https://i.ebayimg.com/00/s/NTAwWDM3NQ==/z/smEA...  https://www.ebay.com/itm/324946521772?nordt=tr...  Victorinox Classic SD Mini Swiss Army Pocket K...  Aug 15, 2022       $6.59         $3.54\n",
       "1  https://i.ebayimg.com/00/s/OTAwWDE2MDA=/z/SQEA...  https://www.ebay.com/itm/233805693414?nordt=tr...  Victorinox Classic SD Swiss Army Knife 3 Tool ...  Jul 22, 2022       $8.29         $0.00\n",
       "2  https://thumbs.ebaystatic.com/pict/14392195183...                                                NaN  Victorinox Classic SD Swiss Army Knife 3 Tool ...   Apr 7, 2022       $7.32         $0.00\n",
       "3  https://thumbs.ebaystatic.com/pict/33381140129...                                                NaN  Victorinox Classic SD Swiss Army Knife 3 Tool ...  May 30, 2022       $7.89         $0.00\n",
       "4  https://i.ebayimg.com/00/s/MTIwMFgxNjAw/z/C4cA...  https://www.ebay.com/itm/254705443098?nordt=tr...  Original German army Swiss Victorinox made Poc...  Aug 16, 2022      $33.04         $7.44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dict = {'benchmade': teradf_bench, \n",
    "           'buck': teradf_buck,\n",
    "           'case':teradf_case,\n",
    "           'crkt':teradf_crkt,\n",
    "           'kershaw':teradf_kershaw,\n",
    "           'leatherman':teradf_leath,\n",
    "           'sog':teradf_sog, \n",
    "           'spyderco':teradf_spyd,\n",
    "           'victorinox':teradf_vict}\n",
    "for key,val in df_dict.items():\n",
    "    print(key)\n",
    "    display(val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teradf_bench = prepare_tera_df(teradf_bench, 0)\n",
    "teradf_buck = prepare_tera_df(teradf_buck, 1)\n",
    "teradf_case = prepare_tera_df(teradf_case, 2)\n",
    "teradf_crkt = prepare_tera_df(teradf_crkt, 3)\n",
    "teradf_kershaw = prepare_tera_df(teradf_kershaw, 4)\n",
    "teradf_leath = prepare_tera_df(teradf_leath, 5)\n",
    "teradf_sog = prepare_tera_df(teradf_sog, 6)\n",
    "teradf_spyd = prepare_tera_df(teradf_spyd, 7)\n",
    "teradf_vict = prepare_tera_df(teradf_vict, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tera_df = pd.concat([teradf_bench, teradf_buck,\n",
    "                     teradf_case, teradf_crkt,\n",
    "                     teradf_kershaw, teradf_leath,\n",
    "                     teradf_sog, teradf_spyd,\n",
    "                    teradf_vict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teradf_bench.to_csv(\"teraform_data/tera_bench_prepared.csv\", index=False)\n",
    "# teradf_buck.to_csv(\"teraform_data/tera_buck_prepared.csv\", index=False)\n",
    "# teradf_case.to_csv(\"teraform_data/tera_case_prepared.csv\", index=False)\n",
    "# teradf_crkt.to_csv(\"teraform_data/tera_crkt_prepared.csv\", index=False)\n",
    "# teradf_kershaw.to_csv(\"teraform_data/tera_kershaw_prepared.csv\", index=False)\n",
    "# teradf_leath.to_csv(\"teraform_data/tera_leatherman_prepared.csv\", index=False)\n",
    "# teradf_sog.to_csv(\"teraform_data/tera_sog_prepared.csv\", index=False)\n",
    "# teradf_spyd.to_csv(\"teraform_data/tera_spyd_prepared.csv\", index=False)\n",
    "# teradf_vict.to_csv(\"teraform_data/tera_victorinox_prepared.csv\", index=False)\n",
    "# tera_df.to_csv(\"teraform_data/teraform_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teradf_bench = pd.read_csv(\"teraform_data/tera_bench_prepared.csv\")\n",
    "teradf_buck = pd.read_csv(\"teraform_data/tera_buck_prepared.csv\")\n",
    "teradf_case = pd.read_csv(\"teraform_data/tera_case_prepared.csv\")\n",
    "teradf_crkt = pd.read_csv(\"teraform_data/tera_crkt_prepared.csv\")\n",
    "teradf_kershaw = pd.read_csv(\"teraform_data/tera_kershaw_prepared.csv\")\n",
    "teradf_leath = pd.read_csv(\"teraform_data/tera_leatherman_prepared.csv\")\n",
    "teradf_sog = pd.read_csv(\"teraform_data/tera_sog_prepared.csv\")\n",
    "teradf_spyd = pd.read_csv(\"teraform_data/tera_spyd_prepared.csv\")\n",
    "teradf_vict = pd.read_csv(\"teraform_data/tera_victorinox_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teradf_benchIDs = pd.read_csv(\"teraform_data/tera_benchmade_itemID.csv\")\n",
    "teradf_buckIDs = pd.read_csv(\"teraform_data/tera_buck_ItemIDs.csv\")\n",
    "teradf_caseIDs = pd.read_csv(\"teraform_data/tera_case_itemIDs.csv\")\n",
    "teradf_kershawIDs = pd.read_csv(\"teraform_data/tera_kershaw_ItemIDs.csv\")\n",
    "teradf_sogIDs = pd.read_csv(\"teraform_data/tera_sog_ItemIDs.csv\")\n",
    "teradf_spydIDs = pd.read_csv(\"teraform_data/tera_spyderco_ItemIDs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfID_list = [teradf_benchIDs,teradf_buckIDs,\n",
    "             teradf_caseIDs, teradf_kershawIDs,\n",
    "             teradf_sogIDs, teradf_spydIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in dfID_list:\n",
    "    dataframe.rename({'Field4': 'date_sold',\n",
    "                      'Data_field': 'itemID',\n",
    "                      'Title': 'title'}, \n",
    "                       axis=1, inplace=True)\n",
    "    \n",
    "teradf_kershawIDs.rename({'item': 'title'}, \n",
    "                       axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in dfID_list:\n",
    "    dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in dfID_list:\n",
    "    dataframe['itemID'] = dataframe['itemID'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tera_benchIds = teradf_benchIDs.itemID.values.tolist()\n",
    "tera_buckIds = teradf_buckIDs.itemID.values.tolist()\n",
    "tera_caseIds = teradf_caseIDs.itemID.values.tolist()\n",
    "tera_kershawIds = teradf_kershawIDs.itemID.values.tolist()\n",
    "tera_sogIds = teradf_sogIDs.itemID.values.tolist()\n",
    "tera_spydIds = teradf_spydIDs.itemID.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [teradf_bench,teradf_buck,\n",
    "           teradf_case, teradf_crkt,\n",
    "           teradf_kershaw, teradf_leath,\n",
    "           teradf_sog, teradf_spyd,\n",
    "           teradf_vict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in df_list:\n",
    "    dataframe['title'] = dataframe['title'].str.lower()\n",
    "    dataframe['title'] = dataframe['title'].str.strip()\n",
    "    \n",
    "for dataframe in dfID_list:\n",
    "    dataframe['title'] = dataframe['title'].str.lower()\n",
    "    dataframe['title'] = dataframe['title'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_bench,df_buck,df_case,df_crkt,df_kershaw,df_leatherman,df_spyderco,df_sog,df_victorinox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(, preview full size image)\")\n",
    "teradf_bench['title'] = teradf_bench['title'].apply(lambda x: re.sub(pattern, '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idMerge_bench = teradf_bench.merge(teradf_benchIDs, on='Image')\n",
    "idMerge_buck = teradf_buck.merge(teradf_buckIDs)\n",
    "idMerge_case = teradf_case.merge(teradf_caseIDs)\n",
    "idMerge_kershaw = teradf_kershaw.merge(teradf_kershawIDs)\n",
    "idMerge_spyd = teradf_spyd.merge(teradf_spydIDs)\n",
    "idMerge_sog = teradf_sog.merge(teradf_sogIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bench_spec_t = transform_item_specifics(bench_merged_t, perc=90.0)\n",
    "# buck_spec_t = transform_item_specifics(buck_merged_t, perc=90.0)\n",
    "# case_spec_t = transform_item_specifics(case_merged_t, perc=90.0)\n",
    "# kershaw_spec_t = transform_item_specifics(kershaw_merged_t, perc=90.0)\n",
    "# sog_spec_t = transform_item_specifics(sog_merged_t, perc=90.0)\n",
    "# spyd_spec_t = transform_item_specifics(spyd_merged_t, perc=90.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idMerge_bench.to_csv('teraform_data/tera_bench_idMerge.csv', index=False)\n",
    "idMerge_buck.to_csv('teraform_data/tera_buck_idMerge.csv', index=False)\n",
    "idMerge_case.to_csv('teraform_data/tera_case_idMerge.csv', index=False)\n",
    "idMerge_kershaw.to_csv('teraform_data/tera_kershaw_idMerge.csv', index=False)\n",
    "idMerge_spyd.to_csv('teraform_data/tera_spyd_idMerge.csv', index=False)\n",
    "idMerge_sog.to_csv('teraform_data/tera_sog_idMerge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['blade_type'] = df3.ItemSpecifics.apply(extract_blade_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.ItemSpecifics.sample(10).apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_color(line):\n",
    "#     pattern = re.compile(\"Color\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         match = 'NA'\n",
    "        \n",
    "#     return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['color'] = df3.ItemSpecifics.apply(extract_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_blade_type(line):\n",
    "#     pattern = re.compile(\"Blade Type\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         match = 'NA'\n",
    "        \n",
    "#     return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['blade_type'] = df3.ItemSpecifics.apply(extract_blade_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['blade_type'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_manufacture_region(line):\n",
    "#     pattern = re.compile(\"Country/Region of Manufacture\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['region_of_Manufacture'] = df3.ItemSpecifics.apply(extract_manufacture_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['region_of_Manufacture'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_handle_material(line):\n",
    "#     pattern = re.compile(\"Handle Material\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['handle_material'] = df3.ItemSpecifics.apply(extract_handle_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['handle_material'].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_lock_type(line):\n",
    "#     pattern = re.compile(\"Lock Type\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "\n",
    "# df3['lock_type'] = df3.ItemSpecifics.apply(extract_lock_type)\n",
    "\n",
    "# df3['lock_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_blade_edge(line):\n",
    "#     pattern = re.compile(\"Blade Edge\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n",
    "# df3['blade_edge'] = df3.ItemSpecifics.apply(extract_blade_edge)\n",
    "\n",
    "# df3['blade_edge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_dexterity(line):\n",
    "#     pattern = re.compile(\"Dexterity\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n",
    "# df3['dexterity'] = df3.ItemSpecifics.apply(extract_dexterity)\n",
    "\n",
    "# df3['dexterity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.to_csv('data/item_specifics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root='C:/Users/12108/Documents/GitHub/Neural_Network_Predicting_Reseller_Success_Ebay/nn_images2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pandas as pd\n",
    "# import matplotlib.pyplot  as plt\n",
    "# from PIL import Image\n",
    "# from pathlib import Path\n",
    "# # import imagesize\n",
    "# import numpy as np\n",
    "\n",
    "# # Get the Image Resolutions\n",
    "# imgs = [img.name for img in Path(root).iterdir() if img.suffix == \".jpg\"]\n",
    "# img_meta = {}\n",
    "# for f in imgs: img_meta[str(f)] = imagesize.get(root+f)\n",
    "\n",
    "# # Convert it to Dataframe and compute aspect ratio\n",
    "# img_meta_df = pd.DataFrame.from_dict([img_meta]).T.reset_index().set_axis(['FileName', 'Size'], axis='columns', inplace=False)\n",
    "# img_meta_df[[\"Width\", \"Height\"]] = pd.DataFrame(img_meta_df[\"Size\"].tolist(), index=img_meta_df.index)\n",
    "# img_meta_df[\"Aspect Ratio\"] = round(img_meta_df[\"Width\"] / img_meta_df[\"Height\"], 2)\n",
    "\n",
    "# print(f'Total Nr of Images in the dataset: {len(img_meta_df)}')\n",
    "# img_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize Image Resolutions\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# points = ax.scatter(img_meta_df.Width, img_meta_df.Height, color='blue', alpha=0.5, picker=True)\n",
    "# ax.set_title(\"Image Resolution\")\n",
    "# ax.set_xlabel(\"Width\", size=14)\n",
    "# ax.set_ylabel(\"Height\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize Image Resolutions\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# points = ax.scatter(img_meta_df.Width, img_meta_df.Height, color='blue', alpha=0.5, s=img_meta_df[\"Aspect Ratio\"]*100, picker=True)\n",
    "# ax.set_title(\"Image Resolution\")\n",
    "# ax.set_xlabel(\"Width\", size=14)\n",
    "# ax.set_ylabel(\"Height\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#Create row for converted Price of Knives in US dollars\n",
    "price_list = []\n",
    "for row in full_dataset:\n",
    "    listed_price = np.float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "    price_list.append(listed_price)\n",
    "    \n",
    "df['price_in_US'] = price_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#atttempt to pull shipping cost from json dict\n",
    "shipping_cost_list = []\n",
    "for row in full_dataset:\n",
    "    shipping_cost = np.float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "    shipping_cost_list.append(shipping_cost)\n",
    "    \n",
    "df['shipping_price'] = shipping_cost_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#pull shipping cost from json dict with regex \n",
    "df['shipping_cost'] = df['shippingInfo'].apply(lambda x: re.findall(\"(\\d+\\S+\\d)\", json.dumps(x)))\n",
    "df['shipping_cost'] = df['shipping_cost'].apply(lambda x: ''.join(x))\n",
    "df.drop(df[df['shipping_cost'] == ''].index, inplace=True)\n",
    "df['shipping_cost'] = df['shipping_cost'].apply(lambda x: np.float(x))\n",
    "\n",
    "#create new feature 'converted price'\n",
    "df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "df = df.drop_duplicates(subset=['title', 'galleryURL'], keep='first')\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "\n",
    "df.to_csv('data/full_dataset.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwLbGNr0TbIj"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* Were there variables you dropped or created?\n",
    "* How did you address missing values or outliers?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***\n",
    "\n",
    "\n",
    "# here you run your code to clean the data\n",
    "\n",
    "```\n",
    "import code.data_cleaning as dc\n",
    "\n",
    "full_dataset = dc.full_clean()\n",
    "```\n",
    "\n",
    "## Data Modeling\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How did you analyze or model the data?\n",
    "* How did you iterate on your initial approach to make it better?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***\n",
    "# here you run your code to model the data\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How do you interpret the results?\n",
    "* How well does your model fit your data? How much better is this than your baseline model?\n",
    "* How confident are you that your results would generalize beyond the data you have?\n",
    "* How confident are you that this model would benefit the business if put into use?\n",
    "***\n",
    "\n",
    "\n",
    "## Conclusions\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What would you recommend the business do as a result of this work?\n",
    "* What are some reasons why your analysis might not fully solve the business problem?\n",
    "* What else could you do in the future to improve this project?\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_knife_dir = 'knife_images'\n",
    "# data_profit_dir = 'data/profit'\n",
    "# new_dir = 'split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_folder = os.path.join(new_dir, 'train')\n",
    "# train_profit = os.path.join(train_folder, 'profit')\n",
    "# os.mkdir(train_folder)\n",
    "# os.mkdir(train_profit)\n",
    "\n",
    "# test_folder = os.path.join(new_dir, 'test')\n",
    "# test_profit = os.path.join(test_folder, 'profit')\n",
    "# os.mkdir(test_folder)\n",
    "# os.mkdir(test_profit)\n",
    "\n",
    "\n",
    "# val_folder = os.path.join(new_dir, 'validation')\n",
    "# val_profit = os.path.join(val_folder, 'profit')\n",
    "# os.mkdir(val_folder)\n",
    "# os.mkdir(val_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train knife regression images\n",
    "# #80% of data\n",
    "# imgs = knife_images[:5620]\n",
    "# for img in imgs:\n",
    "#     origin = os.path.join(data_knife_dir, img)\n",
    "#     destination = os.path.join(train_profit, img)\n",
    "#     shutil.copyfile(origin, destination)\n",
    "    \n",
    "# # test knife regression images\n",
    "# #10% of data\n",
    "# imgs = knife_images[5620:6322]\n",
    "# for img in imgs:\n",
    "#     origin = os.path.join(data_knife_dir, img)\n",
    "#     destination = os.path.join(test_profit, img)\n",
    "#     shutil.copyfile(origin, destination)\n",
    "    \n",
    "    \n",
    "# # validation knife regression images\n",
    "# #10% of data\n",
    "# imgs = knife_images[6322:]\n",
    "# for img in imgs:\n",
    "#     origin = os.path.join(data_knife_dir, img)\n",
    "#     destination = os.path.join(val, img)\n",
    "#     shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dropout, Conv2D, Dense, Flatten, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "img_array = cv2.imread('knife_images/918.jpg')  # convert to array\n",
    "\n",
    "img_rgb = cv2.resize(img_array,(256,256),3)\n",
    "plt.imshow(img_rgb)  # graph it\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_checker(index,):\n",
    "    img_array = cv2.imread('knife_images/'+str(index)+'.jpg')  \n",
    "    img_rgb = cv2.resize(img_array,(256,256),3)\n",
    "    plt.imshow(img_rgb)  # graph it\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_benchmade_index[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_checker(6158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_checker(2286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_checker(1879)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_checker(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_checker(6094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final processing steps for images\n",
    "\n",
    "image_list = []\n",
    "for x in range(len(df_CNN_regression)):\n",
    "    \n",
    "    img_array = cv2.imread('knife_images/'+str(x)+'.jpg')  # convert to array\n",
    "    img_rgb = cv2.resize(img_array,(256,256),3)  # resize\n",
    "    img_rgb = np.array(img_rgb).astype(np.float64)/255.0  # scaling\n",
    "    image_list.append(img_rgb)\n",
    "   \n",
    "    # img_rgb = np.expand_dims(img_rgb, axis=0)  # expand dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CNN_regression['mean_profit']= (df_CNN_regression['profit']/df_CNN_regression['profit'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CNN_regression['mean_profit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=  df_CNN_regression['mean_profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, test_size=0.4, random_state=32)# Create the Test and Final Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Xtrain:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Xtrain:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "print(\"X_val:\", X_test.shape)\n",
    "print(\"y_val:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small batch\n",
    "\n",
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "#                         input_shape=(256 ,256, 3)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# model.compile(loss='mean_squared_error',\n",
    "#               optimizer='Adam',\n",
    "#                metrics=['mse'])\n",
    "\n",
    "# history = model.fit(X_train,\n",
    "#                     y_train,\n",
    "#                     epochs=30,\n",
    "#                     batch_size=32,\n",
    "#                     validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrub['profit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.2164 * 41.374303202846974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model learned patterns wells until epoch 20\n",
    "#after that the loss spikes signifcantly before dropping again\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss( mean square error)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_mse', 'val_mse'], loc='upper right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_batch32.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a train set of 60% and a val and test size of 20% each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model showed a lot of indication that it was overfit\n",
    "#need to retry how I split the data \n",
    "#Instead of manul indexing, will use \n",
    "# from sklearn model_selection train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X[:4918]\n",
    "# y_train = y[:4918]\n",
    "\n",
    "# X_train = X[4918:5971]\n",
    "# y_train = y[4918:5971]\n",
    "\n",
    "# X_test = X[5971:]\n",
    "# y_test = y[5971:]\n",
    "\n",
    "\n",
    "# display(len(X_val)/len(X))\n",
    "# display(len(X_train)/len(X))\n",
    "# len(X_test)/len(X)\n",
    "\n",
    "\n",
    "\n",
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "#                         input_shape=(224 ,224,  3)))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# model.compile(loss='mean_squared_error',\n",
    "#               optimizer='Adam',\n",
    "#                metrics=['mse'])\n",
    "# history = model.fit(X_train,\n",
    "#                     y_train,\n",
    "#                     epochs=32,\n",
    "#                     batch_size=300,\n",
    "#                     validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# results_train = model.evaluate(X_test, y_test)\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "# model.save('my_model_batch500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('my_model_batch500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is showing a lot of signs of overfitting \n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss( mean square error)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_mse', 'val_mse'], loc='upper right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_train = model.evaluate(X_test, y_test)\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "# model.save('my_model_batch500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# from ebaysdk.finding import Connection\n",
    "# import requests\n",
    "\n",
    "# from ebaysdk.shopping import Connection as Shopping\n",
    "\n",
    "# import pandas as pd \n",
    "# import  json\n",
    "# import numpy as np\n",
    "# import re\n",
    "# import preprocess_ddey117 as pp\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "# import seaborn as sns \n",
    "\n",
    "# df = pd.read_csv('data/tera_df_prepared.csv', sep=',', error_bad_lines=False, index_col=False, dtype='unicode')\n",
    "\n",
    "# df.info()\n",
    "\n",
    "# api = Shopping(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "# request = {\n",
    "#            'itemID': list(itemIds),\n",
    "#            'IncludeSelector': 'ItemSpecifics'\n",
    "#           }\n",
    "# response = api.execute('GetMultipleItems', request)\n",
    "\n",
    "# response_dict = response.dict()\n",
    "\n",
    "# results_list_of_dicts = response_dict['Item']\n",
    "\n",
    "\n",
    "\n",
    "# response_dict = response.dict()\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "# # results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "# results_list_of_dicts = response_dict['Item']\n",
    "\n",
    "# #create function for organizing API call\n",
    "# def prepare_data(data_list):\n",
    "#     \"\"\"\n",
    "#     This function takes in a list of dictionaries and prepares it\n",
    "#     for analysis\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Make a new list to hold results\n",
    "#     results = []\n",
    "    \n",
    "#     for business_data in data_list:\n",
    "    \n",
    "#         # Make a new dictionary to hold prepared data for this business\n",
    "#         prepared_data = {}\n",
    "        \n",
    "#         # Extract name, review_count, rating, and price key-value pairs\n",
    "#         # from business_data and add to prepared_data\n",
    "#         # If a key is not present in business_data, add it to prepared_data\n",
    "#         # with an associated value of None\n",
    "        \n",
    "#         keys = ['ItemID', 'Title', 'GalleryURL', \n",
    "#                 'ViewItemURLForNaturalSearch', 'ItemSpecifics', \n",
    "#                 'Country', 'Location', 'ConvertedCurrentPrice',\n",
    "#                 'PictureURL']\n",
    "        \n",
    "#         for key in keys:\n",
    "#             prepared_data[key] = business_data.get(key, None)\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "# #         Add to list if all values are present\n",
    "# #         if all(prepared_data.values()):\n",
    "# #             results.append(prepared_data)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# #create function for organizing API call\n",
    "# def prepare_data(data_list):\n",
    "#     \"\"\"\n",
    "#     This function takes in a list of dictionaries and prepares it\n",
    "#     for analysis\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Make a new list to hold results\n",
    "#     results = []\n",
    "    \n",
    "#     for business_data in data_list:\n",
    "    \n",
    "#         # Make a new dictionary to hold prepared data for this business\n",
    "#         prepared_data = {}\n",
    "        \n",
    "#         # Extract name, review_count, rating, and price key-value pairs\n",
    "#         # from business_data and add to prepared_data\n",
    "#         # If a key is not present in business_data, add it to prepared_data\n",
    "#         # with an associated value of None\n",
    "        \n",
    "#         keys = ['ItemID', 'Title', 'GalleryURL', \n",
    "#                 'ViewItemURLForNaturalSearch', 'ItemSpecifics', \n",
    "\n",
    "#                 'PictureURL']\n",
    "        \n",
    "#         for key in keys:\n",
    "#             prepared_data[key] = business_data.get(key, None)\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "# #         Add to list if all values are present\n",
    "# #         if all(prepared_data.values()):\n",
    "# #             results.append(prepared_data)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def process_list(my_list):\n",
    " \n",
    "#     api = Shopping(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "#     request = {\n",
    "#                'itemID': my_list,\n",
    "#                'IncludeSelector': 'ItemSpecifics'\n",
    "#               }\n",
    "#     response = api.execute('GetMultipleItems', request)\n",
    "\n",
    "    \n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['Item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "    \n",
    "#     return full_dataset\n",
    "\n",
    "# full_dataset = []\n",
    "# for i in range(0, len(itemIds), 20):\n",
    "#     process_list(itemIds[i:i+20])\n",
    "\n",
    "# itemIds = list(df.itemId)\n",
    "\n",
    "# full_dataset = []\n",
    "# for i in range(0, len(itemIds), 20):\n",
    "#     process_list(itemIds[i:i+20])\n",
    "\n",
    "# len(full_dataset)\n",
    "\n",
    "# full_dataset[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df2 = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df3 = df2.drop_duplicates(subset='ItemID').copy()\n",
    "\n",
    "# df.info()\n",
    "\n",
    "# df3.ItemSpecifics.sample(5).apply(print)\n",
    "\n",
    "# import re\n",
    "\n",
    "# pattern = re.compile(\"Opening Mechanism\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "\n",
    "# def extract_opening_mech(line):\n",
    "#     pattern = re.compile(\"Opening Mechanism\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "\n",
    "#     if re.findall(pattern,str(line)):\n",
    "\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         match = 'NA'\n",
    "        \n",
    "#     return match\n",
    "\n",
    "# df3['opening_mechanism'] = df3.ItemSpecifics.apply(extract_opening_mech)\n",
    "\n",
    "# df3\n",
    "\n",
    "# pattern = re.compile(\"Blade Material\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "\n",
    "# def extract_blade_type(line):\n",
    "#     pattern = re.compile(\"Blade Material\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         match = 'NA'\n",
    "        \n",
    "#     return match\n",
    "\n",
    "# df3['blade_type'] = df3.ItemSpecifics.apply(extract_blade_type)\n",
    "\n",
    "# df3.ItemSpecifics.sample(10).apply(print)\n",
    "\n",
    "# def extract_color(line):\n",
    "#     pattern = re.compile(\"Color\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         match = 'NA'\n",
    "        \n",
    "#     return match\n",
    "\n",
    "# df3['color'] = df3.ItemSpecifics.apply(extract_color)\n",
    "\n",
    "# def extract_blade_type(line):\n",
    "#     pattern = re.compile(\"Blade Type\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         match = 'NA'\n",
    "        \n",
    "#     return match\n",
    "\n",
    "# df3['blade_type'] = df3.ItemSpecifics.apply(extract_blade_type)\n",
    "\n",
    "# df3['blade_type'].value_counts()[:20]\n",
    "\n",
    "# def extract_manufacture_region(line):\n",
    "#     pattern = re.compile(\"Country/Region of Manufacture\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n",
    "\n",
    "\n",
    "# df3['region_of_Manufacture'] = df3.ItemSpecifics.apply(extract_manufacture_region)\n",
    "\n",
    "# df3['region_of_Manufacture'].value_counts()\n",
    "\n",
    "# def extract_handle_material(line):\n",
    "#     pattern = re.compile(\"Handle Material\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n",
    "\n",
    "\n",
    "# df3['handle_material'] = df3.ItemSpecifics.apply(extract_handle_material)\n",
    "\n",
    "# df3['handle_material'].value_counts()[:50]\n",
    "\n",
    "# def extract_lock_type(line):\n",
    "#     pattern = re.compile(\"Lock Type\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "\n",
    "# df3['lock_type'] = df3.ItemSpecifics.apply(extract_lock_type)\n",
    "\n",
    "# df3['lock_type'].value_counts()\n",
    "\n",
    "# def extract_blade_edge(line):\n",
    "#     pattern = re.compile(\"Blade Edge\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n",
    "# df3['blade_edge'] = df3.ItemSpecifics.apply(extract_blade_edge)\n",
    "\n",
    "# df3['blade_edge'].value_counts()\n",
    "\n",
    "# def extract_dexterity(line):\n",
    "#     pattern = re.compile(\"Dexterity\\s*\\S+\\S+\\s*\\S+\\S+\\s\\S(\\w+)\")\n",
    "#     if re.findall(pattern,str(line)):\n",
    "#         match = re.findall(pattern,str(line))[0]\n",
    "#     else:\n",
    "#         match = 'NA'\n",
    "#     return match\n",
    "        \n",
    "# df3['dexterity'] = df3.ItemSpecifics.apply(extract_dexterity)\n",
    "\n",
    "# df3['dexterity'].value_counts()\n",
    "\n",
    "# df3.to_csv('data/item_specifics_df.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # api = Shopping(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "# # request = {\n",
    "# #            'itemID': list(itemIds),\n",
    "# #            'IncludeSelector': 'ItemSpecifics'\n",
    "# #           }\n",
    "# # response = api.execute('GetMultipleItems', request)\n",
    "# # print(response.dict())\n",
    "\n",
    "# ls\n",
    "\n",
    "# from os import listdir\n",
    "# from PIL import Image\n",
    "\n",
    "# for imageFolder in listdir('./nn_images2'):\n",
    "#     try:\n",
    "#         img = Image.open('./nn_images2/'+imageFolder)\n",
    "#         img.verify()     # to veify if its an img\n",
    "#         img.close()     #to close img and free memory space\n",
    "#     except (IOError, SyntaxError) as e:\n",
    "#         print('Bad file:', imageFolder)\n",
    "\n",
    "# listdir('/nnimages2')\n",
    "\n",
    "# root='C:/Users/12108/Documents/GitHub/Neural_Network_Predicting_Reseller_Success_Ebay/nn_images2/'\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot  as plt\n",
    "# from PIL import Image\n",
    "# from pathlib import Path\n",
    "# import imagesize\n",
    "# import numpy as np\n",
    "\n",
    "# # Get the Image Resolutions\n",
    "# imgs = [img.name for img in Path(root).iterdir() if img.suffix == \".jpg\"]\n",
    "# img_meta = {}\n",
    "# for f in imgs: img_meta[str(f)] = imagesize.get(root+f)\n",
    "\n",
    "# # Convert it to Dataframe and compute aspect ratio\n",
    "# img_meta_df = pd.DataFrame.from_dict([img_meta]).T.reset_index().set_axis(['FileName', 'Size'], axis='columns', inplace=False)\n",
    "# img_meta_df[[\"Width\", \"Height\"]] = pd.DataFrame(img_meta_df[\"Size\"].tolist(), index=img_meta_df.index)\n",
    "# img_meta_df[\"Aspect Ratio\"] = round(img_meta_df[\"Width\"] / img_meta_df[\"Height\"], 2)\n",
    "\n",
    "# print(f'Total Nr of Images in the dataset: {len(img_meta_df)}')\n",
    "# img_meta_df.head()\n",
    "\n",
    "# # Visualize Image Resolutions\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# points = ax.scatter(img_meta_df.Width, img_meta_df.Height, color='blue', alpha=0.5, picker=True)\n",
    "# ax.set_title(\"Image Resolution\")\n",
    "# ax.set_xlabel(\"Width\", size=14)\n",
    "# ax.set_ylabel(\"Height\", size=14)\n",
    "\n",
    "# # Visualize Image Resolutions\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# points = ax.scatter(img_meta_df.Width, img_meta_df.Height, color='blue', alpha=0.5, s=img_meta_df[\"Aspect Ratio\"]*100, picker=True)\n",
    "# ax.set_title(\"Image Resolution\")\n",
    "# ax.set_xlabel(\"Width\", size=14)\n",
    "# ax.set_ylabel(\"Height\", size=14)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #create function for organizing API call\n",
    "# def prepare_data(data_list):\n",
    "#     \"\"\"\n",
    "#     This function takes in a list of dictionaries and prepares it\n",
    "#     for analysis\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Make a new list to hold results\n",
    "#     results = []\n",
    "    \n",
    "#     for business_data in data_list:\n",
    "    \n",
    "#         # Make a new dictionary to hold prepared data for this business\n",
    "#         prepared_data = {}\n",
    "        \n",
    "#         # Extract name, review_count, rating, and price key-value pairs\n",
    "#         # from business_data and add to prepared_data\n",
    "#         # If a key is not present in business_data, add it to prepared_data\n",
    "#         # with an associated value of None\n",
    "        \n",
    "#         keys = ['itemId', 'title', 'galleryURL', \n",
    "#         'viewItemURL', 'autoPay', 'postalCode', \n",
    "#         'sellingStatus', 'shippingInfo', 'listingInfo',\n",
    "#         'returnsAccepted', 'condition', 'topRatedListing',\n",
    "#         'galleryPlusPictureURL', 'subtitle', 'discountPriceInfo',\n",
    "#         'secondaryCategory']\n",
    "        \n",
    "#         for key in keys:\n",
    "#             prepared_data[key] = business_data.get(key, None)\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "#         # Add to list if all values are present\n",
    "# #         if all(prepared_data.values()):\n",
    "# #             results.append(prepared_data)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# # def prepare_df(df):\n",
    "# #     price_list = []\n",
    "# #     for row in full_dataset:\n",
    "# #         listed_price = np.float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "# #         price_list.append(listed_price)\n",
    "\n",
    "# #     df['price_in_US'] = price_list\n",
    "# #     #pull shipping cost from json dict with regex \n",
    "# #     df['shipping_cost'] = df['shippingInfo'].apply(lambda x: re.findall(\"(\\d+\\S+\\d)\", json.dumps(x)))\n",
    "# #     df['shipping_cost'] = df['shipping_cost'].apply(lambda x: ''.join(x))\n",
    "# #     df.drop(df[df['shipping_cost'] == ''].index, inplace=True)\n",
    "# #     df['shipping_cost'] = df['shipping_cost'].apply(lambda x: np.float(x))\n",
    "\n",
    "# #     #create new feature 'converted price'\n",
    "# #     df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "# #     df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "# #     df.reset_index(drop=True, inplace=True)\n",
    "# #     display(df.head())\n",
    "# #     display(df.info())\n",
    "# #     return df\n",
    "\n",
    "# def prepare_df(df):\n",
    "#     price_list = []\n",
    "#     ship_price_list = []\n",
    "#     condition_list = []\n",
    "#     for row in full_dataset:\n",
    "#         listed_price = np.float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "#         price_list.append(listed_price)\n",
    "\n",
    "#         try:\n",
    "#             listed_ship_price = np.float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "#             ship_price_list.append(listed_ship_price)\n",
    "#         except: \n",
    "#             listed_ship_price = 0\n",
    "#             ship_price_list.append(listed_ship_price)\n",
    "\n",
    "#         try:\n",
    "#             condition = None\n",
    "#             condition = np.float(row['condition']['conditionId'])\n",
    "#             condition_list.append(condition)\n",
    "#         except: \n",
    "#             conditon = 0\n",
    "#             condition_list.append(condition)\n",
    "\n",
    "#     df['shipping_cost'] = ship_price_list\n",
    "#     df['price_in_US'] = price_list\n",
    "#     df['condition'] = condition_list\n",
    "    \n",
    "#     #create new feature 'converted price'\n",
    "#     df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "#     df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "#     display(df.head())\n",
    "#     display(df.info())\n",
    "#     return df\n",
    "\n",
    "# overhead_cost = 3\n",
    "# def prepare_brands(df, bucket_dict_position):\n",
    "\n",
    "#     df.title = df.title.apply(str.lower)\n",
    "\n",
    "#     #remove special characters\n",
    "#     df.title.apply(pp.remove_special_chars)\n",
    "\n",
    "#     df[str(list(bucket_dict.keys())[bucket_dict_position])] = float(list(bucket_dict.values())[bucket_dict_position])\n",
    "    \n",
    "#     df['profit'] = (df['converted_price'] - df[list(bucket_dict.keys())[bucket_dict_position]] - overhead_cost)\n",
    "#     df['ROI'] = (df['profit']/(df[list(bucket_dict.keys())[bucket_dict_position]] + overhead_cost))*100.0\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "# from base64 import b64encode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #this function was used at first to check accuracy of calls using ebay API\n",
    "# #the less complex \"prepare_brands\" function seems sufficient enough\n",
    "# #it is redudant to use regex with working ebay API call\n",
    "\n",
    "# def modified_prepare_brands(df, bucket_dict_position):\n",
    "\n",
    "#     df.title = df.title.apply(str.lower)\n",
    "\n",
    "#     #remove special characters\n",
    "#     df.title.apply(pp.remove_special_chars)\n",
    "\n",
    "#     pattern = re.compile(list(bucket_dict.keys())[bucket_dict_position])\n",
    "#     df[list(bucket_dict.keys())[bucket_dict_position]] = df_bench.title.apply(lambda x: re.sub(pattern, x, str(list(bucket_dict.values())[bucket_dict_position])))\n",
    "\n",
    "#     df[list(bucket_dict.keys())[bucket_dict_position]] = df[list(bucket_dict.keys())[bucket_dict_position]].apply(lambda x: np.float(x))\n",
    "    \n",
    "#     df['profit'] = (df['converted_price'] - df[list(bucket_dict.keys())[bucket_dict_position]] - overhead_cost)\n",
    "#     df['ROI'] = (df['profit']/(df[list(bucket_dict.keys())[bucket_dict_position]] + overhead_cost))*100.0\n",
    "\n",
    "#     return df\n",
    "\n",
    "# request = {\n",
    "#            'categoryId': 48818,\n",
    "#             'itemFilter': [\n",
    "#                             {'name': 'Condition', 'value': 'Used'},\n",
    "#                             {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                           ],\n",
    "#             'aspectFilter': [\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Benchmade'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Buck'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Case'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Kershaw'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Victorinox'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'CRKT'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Leatherman'},\n",
    "#                               {'aspectName': 'Brand', 'aspectValueName': 'Spyderco'},\n",
    "#                              ],\n",
    "#             'paginationInput': {\n",
    "#                                 'entriesPerPage': 100,\n",
    "#                                 'pageNumber': 1\n",
    "\n",
    "#                                 }}\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "# #debugger error at page 23\n",
    "\n",
    "\n",
    "# for page in range(1, 22):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'categoryId': 48818,\n",
    "#                 'itemFilter': [\n",
    "# #                                 {'name': 'Condition', 'value': 'Used'},\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "#                                   {'aspectName': 'Brand', 'aspectValueName': 'Benchmade'}],\n",
    "\n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_bench = pd.DataFrame(full_dataset)\n",
    "\n",
    "# bucket_dict = {'benchmade': 45.0,\n",
    "#                'buck': 20.0,\n",
    "#                'case': 20.0,\n",
    "#                'crkt': 15.0,\n",
    "#                'kershaw': 15.0,\n",
    "#                'leatherman': 30.0, \n",
    "#                'spyderco': 30.0,\n",
    "#                'victorinox': 20.0\n",
    "#               }\n",
    "\n",
    "# df_bench = prepare_df(df_bench)\n",
    "\n",
    "# df_bench = prepare_brands(df_bench, 0)\n",
    "\n",
    "# df_bench['benchmade'].value_counts()\n",
    "\n",
    "# df_bench.info()\n",
    "\n",
    "# df_bench[df_bench['galleryPlusPictureURL'].notna()]['galleryPlusPictureURL'].sample(30).apply(print)\n",
    "\n",
    "# df_bench['profit'].describe()\n",
    "\n",
    "# df_bench['ROI'].describe()\n",
    "\n",
    "# df_bench.to_csv('data/df_bench.csv', index=False)\n",
    "\n",
    "# ### Domain Understading: Cost Breakdown\n",
    "# - padded envelopes: \\$0.50 per knife\n",
    "# - flatrate shipping: \\$4.45 per knife\n",
    "# - brand knife at surplus store: 15, 20, 30, or 45 dollars per knife\n",
    "# - overhead expenses (gas, cleaning suplies, sharpening supplies, etc): $7\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "# #debugger error at page 42\n",
    "\n",
    "\n",
    "# for page in range(1, 41):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "#                                  {'aspectName': 'Brand', 'aspectValueName': 'Buck'}],\n",
    "\n",
    "                    \n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_buck = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df_buck = prepare_df(df_buck)\n",
    "\n",
    "# df_buck = prepare_brands(df_buck, 1)\n",
    "\n",
    "# df_buck.info()\n",
    "\n",
    "# df_buck['buck'].value_counts()\n",
    "\n",
    "# df_buck['profit'].describe()\n",
    "\n",
    "# df_buck['ROI'].describe()\n",
    "\n",
    "# df_buck.to_csv('data/df_buck.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "\n",
    "\n",
    "\n",
    "# for page in range(1, 100):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "# #                               \n",
    "#                                    {'aspectName': 'Brand', 'aspectValueName': 'Case XX'},\n",
    "#                                    {'aspectName': 'Brand', 'aspectValueName': 'Case'}\n",
    "#                                  ],\n",
    "\n",
    "                    \n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_case = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df_case = prepare_df(df_case)\n",
    "\n",
    "# df_case = prepare_brands(df_case, 2)\n",
    "\n",
    "# df_case.info()\n",
    "\n",
    "# df_case.to_csv('data/df_case.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "# #debug error page 18\n",
    "\n",
    "\n",
    "# for page in range(1, 17):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "\n",
    "#                                     {'aspectName': 'Brand', 'aspectValueName': 'CRKT'}],\n",
    "                 \n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_crkt = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df_crkt = prepare_df(df_crkt)\n",
    "\n",
    "# bucket_dict \n",
    "\n",
    "# df_crkt = prepare_brands(df_crkt, 3)\n",
    "\n",
    "# display(df_crkt.head())\n",
    "# display(df_crkt.info())\n",
    "\n",
    "# df_crkt.to_csv('data/df_crkt.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "# #debugger threw error at page 70\n",
    "\n",
    "\n",
    "# for page in range(1, 69):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "\n",
    "#                                   {'aspectName': 'Brand', 'aspectValueName': 'Kershaw'}\n",
    "#                                 ],\n",
    "\n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_kershaw = pd.DataFrame(full_dataset)\n",
    "\n",
    "# bucket_dict\n",
    "\n",
    "# df_kershaw = prepare_df(df_kershaw)\n",
    "\n",
    "# df_kershaw = prepare_brands(df_kershaw, 4)\n",
    "\n",
    "# df_kershaw.info()\n",
    "\n",
    "# df_kershaw.to_csv('data/df_kershaw.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "# #debug error page 18\n",
    "\n",
    "\n",
    "# for page in range(1, 17):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "\n",
    "#                                    {'aspectName': 'Brand', 'aspectValueName': 'Leatherman'}],\n",
    "                    \n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_leatherman = pd.DataFrame(full_dataset)\n",
    "\n",
    "# bucket_dict\n",
    "\n",
    "# df_leatherman = prepare_df(df_leatherman)\n",
    "\n",
    "# df_leatherman = prepare_brands(df_leatherman, 5)\n",
    "\n",
    "# df_leatherman.info()\n",
    "\n",
    "# df_leatherman.to_csv('data/df_leatherman.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "# #debug error page 72\n",
    "\n",
    "# for page in range(1, 71):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "\n",
    "#                                    {'aspectName': 'Brand', 'aspectValueName': 'Spyderco'}\n",
    "#                               ],\n",
    "                    \n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "# df_spyderco = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df_spyderco = prepare_df(df_spyderco)\n",
    "\n",
    "# bucket_dict \n",
    "\n",
    "# df_spyderco = prepare_brands(df_spyderco, 6)\n",
    "\n",
    "# df_spyderco.info()\n",
    "\n",
    "# df_spyderco.to_csv('data/df_spyderco.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "\n",
    "\n",
    "# for page in range(1, 21):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "\n",
    "#                                    {'aspectName': 'Brand', 'aspectValueName': 'SOG'}],\n",
    "\n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_sog = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df_sog = prepare_df(df_sog)\n",
    "\n",
    "# bucket_dict['sog'] = 15.0\n",
    "\n",
    "# df_sog = prepare_brands(df_sog, 8)\n",
    "\n",
    "# df_sog.info()\n",
    "\n",
    "# df_sog.to_csv('data/df_sog.csv', index=False)\n",
    "\n",
    "# # Create an empty list for the full prepared dataset\n",
    "# full_dataset = []\n",
    "\n",
    "\n",
    "# for page in range(1, 100):\n",
    "#     # Add or update the \"offset\" key-value pair in url_params\n",
    "#     request['paginationInput']['pageNumber'] = page\n",
    "    \n",
    "#     # Make the query and get the response\n",
    "\n",
    "#     api = Connection(config_file='ebay.yaml', debug=True, siteid=\"EBAY-US\")\n",
    "\n",
    "#     request = {\n",
    "#                 'keywords': 'knife',\n",
    "#                 'itemFilter': [\n",
    "#                                 {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                               ],\n",
    "#                 'aspectFilter': [\n",
    "\n",
    "#                                    {'aspectName': 'Brand', 'aspectValueName': 'Victorinox'}],\n",
    "\n",
    "                    \n",
    "#                 'paginationInput': {\n",
    "#                                     'entriesPerPage': 100,\n",
    "#                                     'pageNumber': page\n",
    "                    \n",
    "#                                     },\n",
    "               \n",
    "#                 }\n",
    "\n",
    "#     response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#     #save the response as a json dict\n",
    "#     response_dict = response.dict()\n",
    "\n",
    "\n",
    "\n",
    "#     #index dict to appropriate index\n",
    "#     results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#     # Call the prepare_data function to get a list of processed data\n",
    "#     prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#     # Extend full_dataset with this list (don't append, or you'll get\n",
    "#     # a list of lists instead of a flat list)\n",
    "#     full_dataset.extend(prepared_knives)\n",
    "\n",
    "# # Check the length of the full dataset. It will be up to `total`,\n",
    "# # potentially less if there were missing values\n",
    "# display(len(full_dataset))\n",
    "\n",
    "\n",
    "# df_victorinox = pd.DataFrame(full_dataset)\n",
    "\n",
    "# df_victorinox = prepare_df(df_victorinox)\n",
    "\n",
    "# bucket_dict\n",
    "\n",
    "# df_victorinox = prepare_brands(df_victorinox, 7)\n",
    "\n",
    "# df_victorinox.info()\n",
    "\n",
    "# df_victorinox.to_csv('data/df_victorinox.csv', index=False)\n",
    "\n",
    "# # df_bench = pd.read_csv(\"data/df_bench.csv\")\n",
    "# # df_buck = pd.read_csv(\"data/df_buck.csv\")\n",
    "# # df_case = pd.read_csv(\"data/df_case.csv\")\n",
    "# # df_crkt = pd.read_csv(\"data/df_crkt.csv\")\n",
    "# # df_kershaw = pd.read_csv(\"data/df_kershaw.csv\")\n",
    "# # df_leatherman = pd.read_csv(\"data/df_leatherman.csv\")\n",
    "# # df_spyderco = pd.read_csv(\"data/df_spyderco.csv\")\n",
    "# # df_victorinox = pd.read_csv(\"data/df_victorinox.csv\")\n",
    "\n",
    "# df = pd.concat([df_bench,df_buck,df_case,df_crkt,df_kershaw,df_leatherman,df_spyderco,df_sog,df_victorinox])\n",
    "\n",
    "# df.info()\n",
    "\n",
    "# df.isna().sum()\n",
    "\n",
    "# df.to_csv(\"data/full_dataset2.csv\", index=False)\n",
    "\n",
    "# After succesfully going through 10,000 items on ebay's website and extracting everything possible, there is still a little bit more extracting to do from the json dictionary before saving the dataframe again. We need to get the price of the knives out of the nested dictionary in the dataframe as well as the shipping cost. After that, I would like to create a new feature called\n",
    "# **\"converted price,\" which is simply the price of the knife listed on the ebay's website plus shipping.**\n",
    "\n",
    "# ```\n",
    "# #Create row for converted Price of Knives in US dollars\n",
    "# price_list = []\n",
    "# for row in full_dataset:\n",
    "#     listed_price = np.float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "#     price_list.append(listed_price)\n",
    "    \n",
    "# df['price_in_US'] = price_list\n",
    "# ```\n",
    "\n",
    "# ```\n",
    "# #atttempt to pull shipping cost from json dict\n",
    "# shipping_cost_list = []\n",
    "# for row in full_dataset:\n",
    "#     shipping_cost = np.float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "#     shipping_cost_list.append(shipping_cost)\n",
    "    \n",
    "# df['shipping_price'] = shipping_cost_list\n",
    "# ```\n",
    "\n",
    "# ```\n",
    "# #pull shipping cost from json dict with regex \n",
    "# df['shipping_cost'] = df['shippingInfo'].apply(lambda x: re.findall(\"(\\d+\\S+\\d)\", json.dumps(x)))\n",
    "# df['shipping_cost'] = df['shipping_cost'].apply(lambda x: ''.join(x))\n",
    "# df.drop(df[df['shipping_cost'] == ''].index, inplace=True)\n",
    "# df['shipping_cost'] = df['shipping_cost'].apply(lambda x: np.float(x))\n",
    "\n",
    "# #create new feature 'converted price'\n",
    "# df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "# df = df.drop_duplicates(subset=['title', 'galleryURL'], keep='first')\n",
    "# display(df.head())\n",
    "# display(df.info())\n",
    "\n",
    "# df.to_csv('data/full_dataset.csv', index=False)\n",
    "# ```\n",
    "\n",
    "# ## Data Preparation\n",
    "\n",
    "# Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "# ***\n",
    "# Questions to consider:\n",
    "# * Were there variables you dropped or created?\n",
    "# * How did you address missing values or outliers?\n",
    "# * Why are these choices appropriate given the data and the business problem?\n",
    "# ***\n",
    "\n",
    "\n",
    "# # here you run your code to clean the data\n",
    "\n",
    "# ```\n",
    "# import code.data_cleaning as dc\n",
    "\n",
    "# full_dataset = dc.full_clean()\n",
    "# ```\n",
    "\n",
    "# ## Data Modeling\n",
    "# Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "# ***\n",
    "# Questions to consider:\n",
    "# * How did you analyze or model the data?\n",
    "# * How did you iterate on your initial approach to make it better?\n",
    "# * Why are these choices appropriate given the data and the business problem?\n",
    "# ***\n",
    "# # here you run your code to model the data\n",
    "\n",
    "\n",
    "# ## Evaluation\n",
    "# Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "# ***\n",
    "# Questions to consider:\n",
    "# * How do you interpret the results?\n",
    "# * How well does your model fit your data? How much better is this than your baseline model?\n",
    "# * How confident are you that your results would generalize beyond the data you have?\n",
    "# * How confident are you that this model would benefit the business if put into use?\n",
    "# ***\n",
    "\n",
    "\n",
    "# ## Conclusions\n",
    "# Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "# ***\n",
    "# Questions to consider:\n",
    "# * What would you recommend the business do as a result of this work?\n",
    "# * What are some reasons why your analysis might not fully solve the business problem?\n",
    "# * What else could you do in the future to improve this project?\n",
    "# ***\n",
    "\n",
    "\n",
    "\n",
    "# # data_knife_dir = 'knife_images'\n",
    "# # data_profit_dir = 'data/profit'\n",
    "# # new_dir = 'split'\n",
    "\n",
    "# # os.mkdir(new_dir)\n",
    "\n",
    "# # train_folder = os.path.join(new_dir, 'train')\n",
    "# # train_profit = os.path.join(train_folder, 'profit')\n",
    "# # os.mkdir(train_folder)\n",
    "# # os.mkdir(train_profit)\n",
    "\n",
    "# # test_folder = os.path.join(new_dir, 'test')\n",
    "# # test_profit = os.path.join(test_folder, 'profit')\n",
    "# # os.mkdir(test_folder)\n",
    "# # os.mkdir(test_profit)\n",
    "\n",
    "\n",
    "# # val_folder = os.path.join(new_dir, 'validation')\n",
    "# # val_profit = os.path.join(val_folder, 'profit')\n",
    "# # os.mkdir(val_folder)\n",
    "# # os.mkdir(val_profit)\n",
    "\n",
    "# # val_profit\n",
    "\n",
    "# # # train knife regression images\n",
    "# # #80% of data\n",
    "# # imgs = knife_images[:5620]\n",
    "# # for img in imgs:\n",
    "# #     origin = os.path.join(data_knife_dir, img)\n",
    "# #     destination = os.path.join(train_profit, img)\n",
    "# #     shutil.copyfile(origin, destination)\n",
    "    \n",
    "# # # test knife regression images\n",
    "# # #10% of data\n",
    "# # imgs = knife_images[5620:6322]\n",
    "# # for img in imgs:\n",
    "# #     origin = os.path.join(data_knife_dir, img)\n",
    "# #     destination = os.path.join(test_profit, img)\n",
    "# #     shutil.copyfile(origin, destination)\n",
    "    \n",
    "    \n",
    "# # # validation knife regression images\n",
    "# # #10% of data\n",
    "# # imgs = knife_images[6322:]\n",
    "# # for img in imgs:\n",
    "# #     origin = os.path.join(data_knife_dir, img)\n",
    "# #     destination = os.path.join(val, img)\n",
    "# #     shutil.copyfile(origin, destination)\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras.models import load_model\n",
    "# from keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Dropout, Conv2D, Dense, Flatten, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "# img_array = cv2.imread('knife_images/918.jpg')  # convert to array\n",
    "\n",
    "# img_rgb = cv2.resize(img_array,(256,256),3)\n",
    "# plt.imshow(img_rgb)  # graph it\n",
    "# plt.show();\n",
    "\n",
    "\n",
    "# def image_checker(index,):\n",
    "#     img_array = cv2.imread('knife_images/'+str(index)+'.jpg')  \n",
    "#     img_rgb = cv2.resize(img_array,(256,256),3)\n",
    "#     plt.imshow(img_rgb)  # graph it\n",
    "#     plt.show();\n",
    "\n",
    "# top_benchmade_index[:50]\n",
    "\n",
    "# image_checker(6158)\n",
    "\n",
    "# image_checker(2286)\n",
    "\n",
    "# image_checker(1879)\n",
    "\n",
    "# image_checker(4326)\n",
    "\n",
    "# image_checker(6094)\n",
    "\n",
    "# #final processing steps for images\n",
    "\n",
    "# image_list = []\n",
    "# for x in range(len(df_CNN_regression)):\n",
    "    \n",
    "#     img_array = cv2.imread('knife_images/'+str(x)+'.jpg')  # convert to array\n",
    "#     img_rgb = cv2.resize(img_array,(256,256),3)  # resize\n",
    "#     img_rgb = np.array(img_rgb).astype(np.float64)/255.0  # scaling\n",
    "#     image_list.append(img_rgb)\n",
    "   \n",
    "#     # img_rgb = np.expand_dims(img_rgb, axis=0)  # expand dimension\n",
    "\n",
    "\n",
    "\n",
    "# df_CNN_regression['mean_profit']= (df_CNN_regression['profit']/df_CNN_regression['profit'].mean())\n",
    "\n",
    "# df_CNN_regression['mean_profit'].describe()\n",
    "\n",
    "# X = np.array(image_list)\n",
    "\n",
    "# y=  df_CNN_regression['mean_profit']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, test_size=0.4, random_state=32)# Create the Test and Final Training Datasets\n",
    "\n",
    "# X.shape\n",
    "\n",
    "# y.shape\n",
    "\n",
    "# print(\"Xtrain:\", X_train.shape)\n",
    "# print(\"y_train:\", y_train.shape)\n",
    "# print(\"X_test:\", X_test.shape)\n",
    "# print(\"y_test:\", y_test.shape)\n",
    "\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# print(\"Xtrain:\", X_train.shape)\n",
    "# print(\"y_train:\", y_train.shape)\n",
    "# print(\"X_test:\", X_test.shape)\n",
    "# print(\"y_test:\", y_test.shape)\n",
    "# print(\"X_val:\", X_test.shape)\n",
    "# print(\"y_val:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #small batch\n",
    "\n",
    "# # model = models.Sequential()\n",
    "\n",
    "# # model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "# #                         input_shape=(256 ,256, 3)))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "\n",
    "# # model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "# # model.add(Dense(256, activation='relu'))\n",
    "# # model.add(Dense(128, activation='relu'))\n",
    "# # model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # model.compile(loss='mean_squared_error',\n",
    "# #               optimizer='Adam',\n",
    "# #                metrics=['mse'])\n",
    "\n",
    "# # history = model.fit(X_train,\n",
    "# #                     y_train,\n",
    "# #                     epochs=30,\n",
    "# #                     batch_size=32,\n",
    "# #                     validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "# results_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "# #model.summary()\n",
    "\n",
    "\n",
    "# df_scrub['profit'].mean()\n",
    "\n",
    "# 2.2164 * 41.374303202846974\n",
    "\n",
    "# df_scrub.head()\n",
    "\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# #The model learned patterns wells until epoch 20\n",
    "# #after that the loss spikes signifcantly before dropping again\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss( mean square error)')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train_mse', 'val_mse'], loc='upper right')\n",
    "# plt.show();\n",
    "\n",
    "# model.save('my_model_batch32.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #a train set of 60% and a val and test size of 20% each \n",
    "\n",
    "# #this model showed a lot of indication that it was overfit\n",
    "# #need to retry how I split the data \n",
    "# #Instead of manul indexing, will use \n",
    "# # from sklearn model_selection train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# # X_train = X[:4918]\n",
    "# # y_train = y[:4918]\n",
    "\n",
    "# # X_train = X[4918:5971]\n",
    "# # y_train = y[4918:5971]\n",
    "\n",
    "# # X_test = X[5971:]\n",
    "# # y_test = y[5971:]\n",
    "\n",
    "\n",
    "# # display(len(X_val)/len(X))\n",
    "# # display(len(X_train)/len(X))\n",
    "# # len(X_test)/len(X)\n",
    "\n",
    "\n",
    "\n",
    "# # model = models.Sequential()\n",
    "\n",
    "# # model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "# #                         input_shape=(224 ,224,  3)))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "\n",
    "# # model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "# # model.add(layers.BatchNormalization())\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # model.add(layers.Flatten())\n",
    "\n",
    "# # model.add(Dense(512, activation='relu'))\n",
    "# # model.add(Dropout(0.1))\n",
    "\n",
    "# # model.add(Dense(256, activation='relu'))\n",
    "# # model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# # model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # model.compile(loss='mean_squared_error',\n",
    "# #               optimizer='Adam',\n",
    "# #                metrics=['mse'])\n",
    "# # history = model.fit(X_train,\n",
    "# #                     y_train,\n",
    "# #                     epochs=32,\n",
    "# #                     batch_size=300,\n",
    "# #                     validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # results_train = model.evaluate(X_test, y_test)\n",
    "\n",
    "# #model.summary()\n",
    "\n",
    "\n",
    "# # model.save('my_model_batch500.h5')\n",
    "\n",
    "# results_train = model.evaluate(X_test, y_test)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# # model.save('my_model_batch500.h5')\n",
    "\n",
    "# history.history.keys()\n",
    "\n",
    "# #The model is showing a lot of signs of overfitting \n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.plot\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss( mean square error)')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train_mse', 'val_mse'], loc='upper right')\n",
    "# plt.show();\n",
    "\n",
    "# X_train.shape\n",
    "\n",
    "# # results_train = model.evaluate(X_test, y_test)\n",
    "\n",
    "# #model.summary()\n",
    "\n",
    "\n",
    "# # model.save('my_model_batch500.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket_dict = {'benchmade': 45.0,\n",
    "#                'buck': 20.0,\n",
    "#                'case': 20.0,\n",
    "#                'crkt': 15.0,\n",
    "#                'kershaw': 15.0,\n",
    "#                'leatherman': 30.0,\n",
    "#                'sog': 15.0,\n",
    "#                'spyderco': 30.0,\n",
    "#                'victorinox': 20.0\n",
    "#               }\n",
    "\n",
    "# overhead_cost = 3\n",
    "# def prepare_brands(df, bucket_dict_position):\n",
    "\n",
    "#     df.title = df.title.apply(str.lower)\n",
    " \n",
    "#     #remove special characters\n",
    "# #     df.title.apply(pp.remove_special_chars)\n",
    "#     df['brand'] = str(list(bucket_dict.keys())[bucket_dict_position])\n",
    "#     df['cost'] = float(list(bucket_dict.values())[bucket_dict_position])\n",
    "#     df['profit'] = (df['converted_price'] -  df['cost'] - overhead_cost)\n",
    "#     df['ROI'] = (df['profit']/( df['cost'] + overhead_cost))*100.0\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def prepare_data(data_list):\n",
    "#     \"\"\"\n",
    "#     This function takes in a list of dictionaries and prepares it\n",
    "#     for analysis\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Make a new list to hold results\n",
    "#     results = []\n",
    "    \n",
    "#     for business_data in data_list:\n",
    "    \n",
    "#         # Make a new dictionary to hold prepared data for this business\n",
    "#         prepared_data = {}\n",
    "        \n",
    "#         # Extract name, review_count, rating, and price key-value pairs\n",
    "#         # from business_data and add to prepared_data\n",
    "#         # If a key is not present in business_data, add it to prepared_data\n",
    "#         # with an associated value of None\n",
    "        \n",
    "#         keys = ['itemId', 'title', 'galleryURL', \n",
    "#         'viewItemURL', 'autoPay', 'postalCode', \n",
    "#         'sellingStatus', 'shippingInfo', 'listingInfo',\n",
    "#         'returnsAccepted', 'condition', 'topRatedListing',\n",
    "#         'galleryPlusPictureURL']\n",
    "        \n",
    "#         for key in keys:\n",
    "#             prepared_data[key] = business_data.get(key, None)\n",
    "#             results.append(prepared_data)\n",
    "    \n",
    "       \n",
    "#         # Add to list if all values are present\n",
    "# #         if all(prepared_data.values()):\n",
    "# #             results.append(prepared_data)\n",
    "    \n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def knife_request(Brand, dict_pos, Lots=False):\n",
    "#     api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "#     full_dataset = []\n",
    "#     price_list = []\n",
    "#     ship_price_list = []\n",
    "#     condition_list = []\n",
    "#     condition = None\n",
    "#     if Lots == True:\n",
    "#         request = {\n",
    "#                     'categoryId': 48818,\n",
    "#                     'itemFilter': [\n",
    "#                                     {'name': 'LotsOnly', 'value': 'True'},\n",
    "#                                     {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                                   ],\n",
    "#                     'aspectFilter': [\n",
    "#                                       {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "\n",
    "#                     'paginationInput': {\n",
    "#                                         'entriesPerPage': 100,\n",
    "#                                         'pageNumber': 1\n",
    "\n",
    "#                                         },\n",
    "\n",
    "#                     }\n",
    "\n",
    "\n",
    "#         response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "\n",
    "#         response_pages = response.dict()\n",
    "\n",
    "    \n",
    "#         total_pages = int(response_pages['paginationOutput']['totalPages'])\n",
    "        \n",
    "#         if total_pages > 100:\n",
    "#             pages_to_request = 100\n",
    "        \n",
    "#         else:\n",
    "#             pages_to_request = total_pages - 1\n",
    "\n",
    "\n",
    "#         for page in range(1, pages_to_request):\n",
    "#         # Add or update the \"offset\" key-value pair in url_params\n",
    "\n",
    "#         # Make the query and get the response\n",
    "\n",
    "#             api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "#             request = {\n",
    "#                         'categoryId': 48818,\n",
    "#                         'itemFilter': [\n",
    "#                                         {'name': 'LotsOnly', 'value': 'True'},\n",
    "#                                         {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                                       ],\n",
    "#                         'aspectFilter': [\n",
    "#                                           {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "\n",
    "#                         'paginationInput': {\n",
    "#                                             'entriesPerPage': 100,\n",
    "#                                             'pageNumber': page\n",
    "\n",
    "#                                             },\n",
    "\n",
    "#                         }\n",
    "\n",
    "\n",
    "#             response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#             #save the response as a json dict\n",
    "#             response_dict = response.dict()\n",
    "\n",
    "\n",
    "#             #index dict to appropriate index\n",
    "#             results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#             # Call the prepare_data function to get a list of processed data\n",
    "#             prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#             # Extend full_dataset with this list (don't append, or you'll get\n",
    "#             # a list of lists instead of a flat list)\n",
    "#             full_dataset.extend(prepared_knives)\n",
    "            \n",
    "#         display(len(full_dataset))\n",
    "    \n",
    "#         df = pd.DataFrame(full_dataset)\n",
    "        \n",
    "#         for row in full_dataset:\n",
    "#             try:\n",
    "#                 listed_price = float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "#                 price_list.append(listed_price)\n",
    "#             except:\n",
    "#                 listed_price = \"Na\"\n",
    "#                 price_list.append(listed_price)\n",
    "#             try:\n",
    "#                 listed_ship_price = float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "#                 ship_price_list.append(listed_ship_price)\n",
    "#             except: \n",
    "#                 listed_ship_price = 0\n",
    "#                 ship_price_list.append(listed_ship_price)\n",
    "#             try:\n",
    "#                 condition = float(row['condition']['conditionId'])\n",
    "#                 condition_list.append(condition)\n",
    "#             except: \n",
    "#                 conditon = 0\n",
    "#                 condition_list.append(condition)\n",
    "\n",
    "#         df['shipping_cost'] = ship_price_list\n",
    "#         df['price_in_US'] = price_list\n",
    "#         df['condition'] = condition_list\n",
    "    \n",
    "#     #create new feature 'converted price'\n",
    "#         df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "#         df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "#         df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#         df = prepare_brands(df, dict_pos)\n",
    "        \n",
    "        \n",
    "#     else: \n",
    "#         request = {\n",
    "#                     'categoryId': 48818,\n",
    "#                     'itemFilter': [\n",
    "#                                     {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                                   ],\n",
    "#                     'aspectFilter': [\n",
    "#                                       {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "\n",
    "#                     'paginationInput': {\n",
    "#                                         'entriesPerPage': 100,\n",
    "#                                         'pageNumber': 1\n",
    "\n",
    "#                                         },\n",
    "\n",
    "#                     }\n",
    "\n",
    "\n",
    "#         response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "\n",
    "#         response_pages = response.dict()\n",
    "\n",
    "    \n",
    "#         total_pages = int(response_pages['paginationOutput']['totalPages'])\n",
    "#         if total_pages > 100:\n",
    "#             pages_to_request = 100\n",
    "        \n",
    "#         else:\n",
    "#             pages_to_request = total_pages - 1\n",
    "        \n",
    "        \n",
    "#         for page in range(1, pages_to_request):\n",
    "#         # Add or update the \"offset\" key-value pair in url_params\n",
    "\n",
    "#         # Make the query and get the response\n",
    "\n",
    "#             api = Connection(config_file='ebay.yaml', debug=False, siteid=\"EBAY-US\")\n",
    "\n",
    "#             request = {\n",
    "#                         'categoryId': 48818,\n",
    "#                         'itemFilter': [\n",
    "#                                         {'name': 'ListingType', 'value': 'FixedPrice'}\n",
    "#                                       ],\n",
    "#                         'aspectFilter': [\n",
    "#                                           {'aspectName': 'Brand', 'aspectValueName': Brand}],\n",
    "\n",
    "\n",
    "#                         'paginationInput': {\n",
    "#                                             'entriesPerPage': 100,\n",
    "#                                             'pageNumber': page\n",
    "\n",
    "#                                             },\n",
    "\n",
    "#                         }\n",
    "\n",
    "\n",
    "#             response = api.execute('findItemsAdvanced', request)\n",
    "\n",
    "#             #save the response as a json dict\n",
    "#             response_dict = response.dict()\n",
    "\n",
    "\n",
    "#             #index dict to appropriate index\n",
    "#             results_list_of_dicts = response_dict['searchResult']['item']\n",
    "\n",
    "#             # Call the prepare_data function to get a list of processed data\n",
    "#             prepared_knives = prepare_data(results_list_of_dicts)\n",
    "\n",
    "#             # Extend full_dataset with this list (don't append, or you'll get\n",
    "#             # a list of lists instead of a flat list)\n",
    "#         full_dataset.extend(prepared_knives)\n",
    "#         display(len(full_dataset))\n",
    "    \n",
    "#         df = pd.DataFrame(full_dataset)\n",
    "        \n",
    "#         for row in full_dataset:\n",
    "#             try:\n",
    "#                 listed_price = float(row['sellingStatus']['convertedCurrentPrice']['value'])\n",
    "#                 price_list.append(listed_price)\n",
    "#             except:\n",
    "#                 listed_price = \"Na\"\n",
    "#                 price_list.append(listed_price)\n",
    "#             try:\n",
    "#                 listed_ship_price = float(row['shippingInfo']['shippingServiceCost']['value'])\n",
    "#                 ship_price_list.append(listed_ship_price)\n",
    "#             except: \n",
    "#                 listed_ship_price = 0\n",
    "#                 ship_price_list.append(listed_ship_price)\n",
    "#             try:\n",
    "#                 condition = float(row['condition']['conditionId'])\n",
    "#                 condition_list.append(condition)\n",
    "#             except: \n",
    "#                 conditon = 0\n",
    "#                 condition_list.append(condition)\n",
    "\n",
    "#         df['shipping_cost'] = ship_price_list\n",
    "#         df['price_in_US'] = price_list\n",
    "#         df['condition'] = condition_list\n",
    "    \n",
    "#     #create new feature 'converted price'\n",
    "#         df['converted_price'] = df['shipping_cost'] + df['price_in_US']\n",
    "#         df.drop_duplicates(subset=['itemId'],  keep='first', inplace=True)\n",
    "#         df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#         df = prepare_brands(df, dict_pos)\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
